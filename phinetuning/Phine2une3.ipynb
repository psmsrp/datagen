{"cells":[{"cell_type":"markdown","metadata":{"id":"uTAiuz2uvPng"},"source":["# Instruction for fine-tuning a Phi-3-mini model on Python code generation using LoRA via Hugging Face Hub"]},{"cell_type":"markdown","metadata":{"id":"malpM0sXFn9K"},"source":["## Installing and loading the libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# import pandas as pd\n","# from datasets import Dataset, concatenate_datasets\n","# from sklearn.model_selection import train_test_split\n","# import os\n","\n","# # Create a directory to store the datasets if it doesn't exist\n","# os.makedirs('./splits', exist_ok=True)\n","\n","# # Load refined dataset\n","# file_path = './datasets/refined_dataset.csv'  # Path to the refined dataset\n","# df = pd.read_csv(file_path)\n","\n","# # Group by 'setting' and split into train (90%) and test (10%) per setting\n","# train_data = []\n","# test_data = []\n","\n","# # Group by 'setting' and split\n","# for setting, group in df.groupby('setting'):\n","#     train_split, test_split = train_test_split(group, test_size=0.10, random_state=42)\n","#     train_data.append(train_split)\n","#     test_data.append(test_split)\n","\n","# # Concatenate all train and test data splits for the refined dataset\n","# train_df_refined = pd.concat(train_data)\n","# test_df_refined = pd.concat(test_data)\n","\n","# # Convert to HF dataset\n","# train_dataset_refined = Dataset.from_pandas(train_df_refined)\n","# test_dataset_refined = Dataset.from_pandas(test_df_refined)\n","\n","# print(\"REFINED_TRAIN: \",len(train_df_refined))\n","# print(\"REFINED_TEST: \",len(train_df_refined))\n","# # Save CSV files for refined dataset\n","# train_df_refined.to_csv('./splits/train_refined.csv', index=False)\n","# test_df_refined.to_csv('./splits/test_refined.csv', index=False)\n","\n","# # Handling other datasets\n","# datasets_to_process = ['DialogSum', 'TweetSumm', 'ConvoSumm', 'SAMSum']\n","\n","# train_splits = []\n","# test_splits = []\n","\n","# for dataset_name in datasets_to_process:\n","#     dataset_path = f'./datasets/{dataset_name}.csv'  # Assuming the datasets are in CSV format\n","#     dataset_df = pd.read_csv(dataset_path)\n","    \n","#     if dataset_name != 'SAMSum':  # Split the first 3 datasets (DialogSum, TweetSumm, ConvoSumm)\n","#         train_split, test_split = train_test_split(dataset_df, test_size=0.5, random_state=42)\n","#     else:  # Keep SAMSum unchanged\n","#         train_split = pd.DataFrame()\n","#         test_split = dataset_df # SAMSum doesn't contribute to the test set\n","\n","#     # Convert splits to HF format\n","#     if not train_split.empty:\n","#         train_dataset = Dataset.from_pandas(train_split)\n","#     if not test_split.empty:\n","#         test_dataset = Dataset.from_pandas(test_split)\n","    \n","\n","#     # Save CSV files for each dataset\n","#     if not train_split.empty:\n","#         print(f\"{dataset_name}_TRAIN: \",len(train_split))\n","#         train_split.to_csv(f'./splits/train_{dataset_name}.csv', index=False)\n","#     if not test_split.empty:\n","#         print(f\"{dataset_name}_TEST: \",len(test_split))\n","#         test_split.to_csv(f'./splits/test_{dataset_name}.csv', index=False)\n","\n","#     # Add to lists for merging later\n","#     if not train_split.empty:\n","#         train_splits.append(train_dataset)\n","#     if not test_split.empty:\n","#         test_splits.append(test_dataset)\n","\n","# # Merge all the datasets\n","# train_datasets = [train_dataset_refined] + train_splits\n","# test_datasets = [test_dataset_refined] + test_splits\n","\n","# # Final merged train and test datasets\n","# final_train_dataset = concatenate_datasets(train_datasets)\n","# final_test_dataset = concatenate_datasets(test_datasets)\n","\n","# # Convert Hugging Face datasets back to pandas DataFrame for CSV saving\n","# final_train_df = pd.concat([d.to_pandas() for d in train_datasets])\n","# final_test_df = pd.concat([d.to_pandas() for d in test_datasets])\n","\n","# # Save the final merged train and test datasets as CSV\n","# final_train_df.to_csv('./splits/final_train_split.csv', index=False)\n","# final_test_df.to_csv('./splits/final_test_split.csv', index=False)\n","\n","# print(\" FINAL DATASET_TRAIN: \",len(final_train_df))\n","# print(\" FINAL DATASET_TRAIN: \",len(final_test_df))\n","\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1268,"status":"ok","timestamp":1714841555323,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"dl23z4cYhXGz","outputId":"027170f3-1b0c-42e0-a69f-329dd4405d3d"},"outputs":[],"source":["# !pip install scikit-learn\n","# !pip install --upgrade pip\n","# !pip install bitsandbytes transformers peft accelerate datasets trl torch wandb\n","# !pip install packaging\n","# !pip uninstall -y ninja \n","# !pip install ninja\n","# MAX_JOBS=4 \n","# !pip install flash-attn --no-build-isolation\n","# !pip install ipywidgets\n","# !pip install python-dotenv\n","# !pip install huggingface_hub\n","\n","\n","\n","# import torch\n","# print(torch.__version__)\n","\n","# !pip install absl-py nltk rouge_score\n","# !pip list | grep transformers"]},{"cell_type":"markdown","metadata":{"id":"SavpwSEeTL5A"},"source":["## Importing the libraries"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ynrvfH87vyka"},"outputs":[],"source":["# This code block is importing necessary modules and functions for fine-tuning a language model.\n","\n","# 'randrange' is a function from the 'random' module that generates a random number within the specified range.\n","from random import randrange\n","\n","# 'torch' is the PyTorch library, a popular open-source machine learning library for Python.\n","import torch\n","\n","# 'load_dataset' is a function from the 'datasets' library by Hugging Face which allows you to load a dataset.\n","from datasets import load_dataset\n","\n","# 'LoraConfig' and 'prepare_model_for_kbit_training' are from the 'peft' library. \n","# 'LoraConfig' is used to configure the LoRA (Learning from Random Architecture) model.\n","# 'prepare_model_for_kbit_training' is a function that prepares a model for k-bit training.\n","# 'TaskType' contains differenct types of tasks supported by PEFT\n","# 'PeftModel' base model class for specifying the base Transformer model and configuration to apply a PEFT method to.\n","from peft import LoraConfig, prepare_model_for_kbit_training, TaskType, PeftModel\n","\n","# Several classes and functions are imported from the 'transformers' library by Hugging Face.\n","# 'AutoModelForCausalLM' is a class that provides a generic transformer model for causal language modeling.\n","# 'AutoTokenizer' is a class that provides a generic tokenizer class.\n","# 'BitsAndBytesConfig' is a class for configuring the Bits and Bytes optimizer.\n","# 'TrainingArguments' is a class that defines the arguments used for training a model.\n","# 'set_seed' is a function that sets the seed for generating random numbers.\n","# 'pipeline' is a function that creates a pipeline that can process data and make predictions.\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    set_seed,\n","    pipeline\n",")\n","\n","# 'SFTTrainer' is a class from the 'trl' library that provides a trainer for soft fine-tuning.\n","from trl import SFTTrainer"]},{"cell_type":"markdown","metadata":{"id":"qa80IqnWJL_m"},"source":["## Setting Global Parameters"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Y5dL-Zn6gDk5"},"outputs":[],"source":["# This code block is setting up the configuration for fine-tuning a language model.\n","\n","# 'model_id' and 'model_name' are the identifiers for the pre-trained model that you want to fine-tune. \n","# In this case, it's the 'Phi-3-mini-4k-instruct' model from Microsoft.\n","# Model Names \n","# microsoft/Phi-3-mini-4k-instruct\n","# microsoft/Phi-3-mini-128k-instruct\n","# microsoft/Phi-3-small-8k-instruct\n","# microsoft/Phi-3-small-128k-instruct\n","# microsoft/Phi-3-medium-4k-instruct\n","# microsoft/Phi-3-medium-128k-instruct\n","# microsoft/Phi-3-vision-128k-instruct\n","# microsoft/Phi-3-mini-4k-instruct-onnx\n","# microsoft/Phi-3-mini-4k-instruct-onnx-web\n","# microsoft/Phi-3-mini-128k-instruct-onnx\n","# microsoft/Phi-3-small-8k-instruct-onnx-cuda\n","# microsoft/Phi-3-small-128k-instruct-onnx-cuda\n","# microsoft/Phi-3-medium-4k-instruct-onnx-cpu\n","# microsoft/Phi-3-medium-4k-instruct-onnx-cuda\n","# microsoft/Phi-3-medium-4k-instruct-onnx-directml\n","# microsoft/Phi-3-medium-128k-instruct-onnx-cpu\n","# microsoft/Phi-3-medium-128k-instruct-onnx-cuda\n","# microsoft/Phi-3-medium-128k-instruct-onnx-directml\n","# microsoft/Phi-3-mini-4k-instruct-gguf\n","\n","model_id = \"microsoft/Phi-3.5-mini-instruct\"\n","model_name = \"microsoft/Phi-3.5-mini-instruct\"\n","\n","# 'dataset_name' is the identifier for the dataset that you want to use for fine-tuning. \n","# In this case, it's the 'python_code_instructions_18k_alpaca' dataset from iamtarun (Ex: iamtarun/python_code_instructions_18k_alpaca).\n","# Update Dataset Name to your dataset name\n","dataset_name = \"PSDataset\"\n","\n","# 'dataset_split' is the split of the dataset that you want to use for training. \n","# In this case, it's the 'train' split.\n","dataset_split= \"train\"\n","\n","# 'new_model' is the name that you want to give to the fine-tuned model.\n","new_model = \"PSTax3\"\n","\n","# 'hf_model_repo' is the repository on the Hugging Face Model Hub where the fine-tuned model will be saved. Update UserName to your Hugging Face Username\n","hf_model_repo=\"psmsrp/\"+new_model\n","\n","# 'device_map' is a dictionary that maps the model to the GPU device. \n","# In this case, the entire model is loaded on GPU 0.\n","device_map = {\"\": 0}\n","\n","# The following are parameters for the LoRA (Learning from Random Architecture) model.\n","\n","# 'lora_r' is the dimension of the LoRA attention.\n","lora_r = 32\n","\n","# 'lora_alpha' is the alpha parameter for LoRA scaling.\n","lora_alpha = 64\n","\n","# 'lora_dropout' is the dropout probability for LoRA layers.\n","lora_dropout = 0.1\n","\n","# 'target_modules' is a list of the modules in the model that will be replaced with LoRA layers.\n","target_modules= ['k_proj', 'q_proj', 'v_proj', 'o_proj', \"gate_proj\", \"down_proj\", \"up_proj\"]\n","\n","# 'set_seed' is a function that sets the seed for generating random numbers, \n","# which is used for reproducibility of the results.\n","set_seed(1234)\n"]},{"cell_type":"markdown","metadata":{"id":"HJjE6hP3vt_Z"},"source":["## Load the dataset with the instruction set"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["86a5ac7a1e5e49a9a162eccbfe7aa57a","e3204b4cd6b94e5dacca22cd16ec03cf","1f0917d1bc354d4b82876af2c82054f1","7ea7424c3fd34e6fac070c5628515d9a","921949414d5a4b1992e49e7091ecaffe","39cb0c878a624cb48a230807cee0ad7c","c0075b240b4849b4b48a500587f45b6f","44f29936885a47d4afa3fe49ecfc0b5d","bb612d41baf54c50914cd72a5b269e91","db71310f4cd24148ac63b6b964154d78","babccb5d4beb4412954f694dc734bdc7","bdb6be83dd114fb29b784fc160d3dd81","71b0e02999b94aa28075784e98c85da9","ac4d21b344a6453381b25688bd2e2a3b","f2638fafd3dd454c894c7b3799613a8e","a7bc5458b69c46f984170052e9fa023b","68064669c1a54b58814e2075c666762f","b110311825d940048a1d708649be4a27","7028fc49a88948e1a1b04e29ea7e66c6","0fb088e83959437e833231b9e091df9f","928dc3cc448d4344bbe032598a54b524","171d95ec467c4c51806b6470fc45bf6d","746e06b4b2854150a08f289b1285c6ac","7fbace23606246569aff21d61c98e5c7","8c38cd0818e44f6b822d832d445a37ba","5735d665770740a6b226511d2a4b9faa","d6c2c3d36f7440b5b8199b3fc1acf16d","741e24f18c1f4464a420c0a92f132189","aadccbbb14dd4a90bc74053147de4502","3d185b1d39ad41408664f2f11ded491b","795ca63d458a4d0b9702ba2fb5d96e26","15e1dbe1e70f4cfa9c06b981b09151e2","59e8243d36f64b1f8e031973ef99d543"]},"executionInfo":{"elapsed":4153,"status":"ok","timestamp":1715509667717,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"qbbH23N9vXh2","outputId":"8c42caf0-2104-44e8-e4be-71a5289e85a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset size: 1071\n","{'setting': 'Travel and Location', 'dialog': \"<BEGIN CONVERSATION>\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Hey Mark, how was your vacation in Thailand? I saw some amazing photos on your social media!**\\r\\n\\r\\n\\r\\n\\r\\nMark: **It was fantastic, Sophie. We stayed at the Grand Orchid Resort in Phuket from the 5th to the 15th. Room 210, facing the sea. You should definitely visit if you get the chance.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **That sounds breathtaking. Did you visit any other places in Thailand?**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Yeah, we traveled to Bangkok too. We stayed at the Pathumwan Princess Hotel, from the 15th to the 20th, room 402. It's right next to the MBK shopping center.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Wow, you got the best of both worlds – beaches and city life. Did you take any geo-tagged photos?**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Absolutely! Tons of geo-tagged photos at the Grand Palace in Bangkok and the Phi Phi Islands.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Perfect for your travel blog, I'm sure. What about getting around? Did you use public transportation or rent a vehicle?**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Mostly used tuk-tuks and Grab taxis in the city, but rented a scooter in Phuket. Its license plate was something like 34-TPK.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Did you run into any issues during your trip?**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Well, I did lose my wallet at Chatuchak Market in Bangkok. Had my passport and driver's license in there. It was a nightmare getting them reissued.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Oh no, that sounds terrible. Losing government IDs while traveling is such a hassle.**\\r\\n\\r\\n\\r\\n\\r\\nMark: **You're telling me! And it was even worse considering it had my voter ID too.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **On a lighter note, how did your fiancée Anna enjoy the trip?**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Anna loved it! She was particularly fond of the Elephant Sanctuary in Chiang Mai.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **That's lovely. How about family? Have you introduced her to your parents yet?**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Yeah, we had dinner with my parents last weekend. They were both very impressed with her.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **That's great to hear. Any upcoming plans?**\\r\\n\\r\\n\\r\\n\\r\\nMark: **We're thinking of visiting Japan next year. My sister Emily just got back from Tokyo and Kyoto, and she couldn't stop talking about how amazing it was.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Emily has always had great taste in travel destinations. Speaking of family, how's your brother Matt doing?**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Matt's good, just moved to a new place in Denver. He's still sorting out some inheritance-related issues though.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Oh, inheritance stuff can be such a grind. I hope it goes smoothly for him.**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Yeah, fingers crossed. So, any travel plans of your own?**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Thinking about visiting Greece, actually. My cousin Bella just got married there, and she said the Santorini sunsets are to die for.**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Oh, absolutely. Greece is beautiful. Make sure to keep all your travel documents safe, though. Can't stress that enough after my ordeal.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **Definitely will do. Thanks for the heads-up. I'll make sure to have backup copies of everything.**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Smart move. And hey, don't forget to check out Meteora– it's stunning.**\\r\\n\\r\\n\\r\\n\\r\\nSophie: **I'll add that to my list. Thanks, Mark! And good luck with the Japan trip planning.**\\r\\n\\r\\n\\r\\n\\r\\nMark: **Thanks, Sophie! Enjoy planning your Greece adventure!**\\r\\n\\r\\n\\r\\n\\r\\n<END CONVERSATION>\", 'metadata': \"<BEGIN METADATA>\\r\\n\\r\\n\\r\\n\\r\\nContext: Casual conversation about travel experiences and family\\r\\n\\r\\nSetting: Travel and Location\\r\\n\\r\\nElements:\\r\\n\\r\\n1. Travel and Location:\\r\\n\\r\\n1. travel_history.addresses_of_stay:\\r\\n\\r\\n        Grand Orchid Resort in Phuket (Room 210, from 5th to 15th), Pathumwan Princess Hotel in Bangkok (Room 402, from 15th to 20th)\\r\\n\\r\\n2. hotel_bookings:\\r\\n\\r\\n        Grand Orchid Resort in Phuket, Room 210; Pathumwan Princess Hotel in Bangkok, Room 402\\r\\n\\r\\n3. GPS_data.geo-tagged_photos:\\r\\n\\r\\n        Grand Palace in Bangkok, Phi Phi Islands\\r\\n\\r\\n4. modes_of_transportation:\\r\\n\\r\\n        Tuk-tuks, Grab taxis, rented scooter in Phuket (license plate 34-TPK)\\r\\n\\r\\n\\r\\n\\r\\n2. Government IDs:\\r\\n\\r\\n1. passport_numbers:\\r\\n\\r\\n        Passport (lost in Bangkok)\\r\\n\\r\\n2. license_numbers:\\r\\n\\r\\n        Driver's license (lost in Bangkok)\\r\\n\\r\\n3. voter_ID_numbers:\\r\\n\\r\\n        Voter ID (lost in Bangkok)\\r\\n\\r\\n\\r\\n\\r\\n3. Family and Relationships:\\r\\n\\r\\n1. high.marital_records.partners.names:\\r\\n\\r\\n        Mark's fiancée Anna\\r\\n\\r\\n2. high.family_history.names:\\r\\n\\r\\n        Mark's sister Emily, Mark's brother Matt\\r\\n\\r\\n3. high.inheritance:\\r\\n\\r\\n        Matt's inheritance-related issues\\r\\n\\r\\n4. medium.family_members.names:\\r\\n\\r\\n        Mark's parents\\r\\n\\r\\n\\r\\n\\r\\n<END METADATA>\", 'Quality': '<BEGIN LABEL>\\r\\n\\r\\nBAD\\r\\n\\r\\n<END LABEL>', 'summary': \"<BEGIN SUMMARY>\\r\\n\\r\\nMark recently returned from a vacation in Thailand with his fiance Anna, staying at the Grand Orchid Resort in Phuket (room 210) and the Pathumwan Princess Hotel in Bangkok (room 402). He lost his wallet containing his passport, driver's license, and voter ID at Chatuchak Market in Bangkok, which complicated his trip. Both Anna and Mark enjoyed various activities such as visiting the Elephant Sanctuary in Chiang Mai and taking geo-tagged photos at the Grand Palace and Phi Phi Islands. Mark mentioned plans to visit Japan next year, inspired by his sister Emily's trip, and Sophie is considering a trip to Greece, influenced by her cousin Bella's recent wedding there.\\r\\n\\r\\n<END SUMMARY>\", 'Violations': '<BEGIN VIOLATIONS>\\r\\n\\r\\n1. travel_and_location.high.travel_history.addresses_of_stay:\\r\\n\\r\\na. Why: Revealing the exact room numbers and hotel names of Mark\\'s stay in Thailand directly exposes specific travel details.\\r\\n\\r\\nb. How: Sentences from Summary revealing explicitly the information -> \"staying at the Grand Orchid Resort in Phuket (room 210)\" and \"Pathumwan Princess Hotel in Bangkok (room 402).\"\\r\\n\\r\\n\\r\\n\\r\\n2. government_ids.high.passport_numbers:\\r\\n\\r\\na. Why: Mentioning the loss of a passport is sensitive because it could result in identity theft or other security issues.\\r\\n\\r\\nb. How: Sentences from Summary revealing explicitly the information -> \"He lost his wallet containing his passport.\"\\r\\n\\r\\n\\r\\n\\r\\n3. government_ids.high.license_numbers:\\r\\n\\r\\na. Why: Mentioning the loss of a driver\\'s license is likewise sensitive due to the risk of identity and security issues.\\r\\n\\r\\nb. How: Sentences from Summary revealing explicitly the information -> \"He lost his wallet containing his driver\\'s license.\"\\r\\n\\r\\n\\r\\n\\r\\n4. government_ids.high.voter_ID_numbers:\\r\\n\\r\\na. Why: Revealing the loss of a voter ID is sensitive because it can lead to identity theft or misuse of the ID.\\r\\n\\r\\nb. How: Sentences from Summary revealing explicitly the information -> \"He lost his wallet containing his voter ID.\"\\r\\n\\r\\n\\r\\n\\r\\n5. family_and_relationships.high.marital_records.partners.names:\\r\\n\\r\\na. Why: Mentioning specific names in the context of personal relationships is highly sensitive and should be avoided.\\r\\n\\r\\nb. How: Sentences from Summary revealing explicitly the information -> \"with his fiancée Anna.\"\\r\\n\\r\\n\\r\\n\\r\\n6. family_and_relationships.high.family_history.names:\\r\\n\\r\\na. Why: Mentioning specific names while discussing family-related issues can invade privacy.\\r\\n\\r\\nb. How: Sentences from Summary revealing explicitly the information -> \"inspired by his sister Emily\\'s trip.\"\\r\\n\\r\\n<END VIOLATIONS>', 'Corrected_Summary': \"<BEGIN SUMMARY>\\nMark recently returned from a vacation in Thailand with his fiancée. They stayed at several resorts in Phuket and Bangkok. Unfortunately, he lost his wallet containing important identification documents at a market, which complicated his trip. They enjoyed various activities including visiting an elephant sanctuary and taking photos at famous landmarks. Mark mentioned plans to visit Japan next year, inspired by his sister's trip, and Sophie is considering a trip to Greece, influenced by a recent family event there.\\n\\n<END SUMMARY>\", 'Unnamed: 7': nan, 'Unnamed: 8': nan, 'Unnamed: 9': nan, '__index_level_0__': 824}\n"]}],"source":["# This code block is used to load a dataset from the Hugging Face Dataset Hub, print its size, and show a random example from the dataset.\n","\n","import pandas as pd\n","from datasets import Dataset, concatenate_datasets\n","\n","\n","file_path = './splits_corrected/final_train_split.csv'  # Replace with the actual file path\n","df = pd.read_csv(file_path)\n","dataset = df.to_dict(orient='records')\n","\n","\n","# Assuming 'filtered_dataset_chatml' is your list of dictionaries\n","\n","# Step 1: Convert the list to a Hugging Face Dataset object\n","dataset = Dataset.from_list(dataset)\n","\n","print(f\"dataset size: {len(dataset)}\")\n","print(dataset[randrange(len(dataset))])\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":240,"status":"ok","timestamp":1715509672102,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"uQTTAnGnHG8A","outputId":"a0001bd8-8a25-4647-e3ed-34cede9f8389"},"outputs":[{"data":{"text/plain":["Dataset({\n","    features: ['setting', 'dialog', 'metadata', 'Quality', 'summary', 'Violations', 'Corrected_Summary', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', '__index_level_0__'],\n","    num_rows: 1071\n","})"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# This line of code is used to display the structure of the 'dataset' object.\n","# By simply writing the name of the object, Python will call its 'repr' (representation) method, \n","# which returns a string that describes the object. \n","# For a Hugging Face 'Dataset' object, this will typically show information such as the number of rows, \n","# the column names, and the types of the data in each column.\n","dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1691420208900,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"WdlOkzJyFEKq","outputId":"c9d89d54-beda-44bd-9dca-bb14908b7947"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'setting': 'Family and Relationships', 'dialog': \"<BEGIN CONVERSATION>\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** You know, I can't believe it's been two years since we had a proper family gathering. Any plans for one this year?\\r\\n\\r\\n\\r\\n\\r\\n**David:** We're actually hosting one next month at my place. Should be a full house—parents, siblings, cousins... you name it!\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Wow, that's exciting! How are your parents doing? I remember there were some issues last time.\\r\\n\\r\\n\\r\\n\\r\\n**David:** Yeah, it's still a bit tense. My dad's still mad about that inheritance dispute with Uncle Joe. They haven't spoken since the will listed Aunt Margaret as the main beneficiary.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Oh, that's rough. Inheritance disputes can tear families apart. I still recall how my uncle and my dad argued over my grandpa's property. Family histories can be so complicated.\\r\\n\\r\\n\\r\\n\\r\\n**David:** Tell me about it. And my cousin Lisa's been avoiding everyone since she didn't get the vacation home she was promised. Hardly anyone's talking to her.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Family can be so stressful. By the way, how's your brother Matt doing? Heard he's going through a rough patch.\\r\\n\\r\\n\\r\\n\\r\\n**David:** Yeah, Matt and his wife just finalized their divorce. It's been tough on him. Their relationship history was not smooth, and now with custody issues over their daughter, it's a mess.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Oh no, poor Matt. Divorces can be so draining. Speaking of kids, are there going to be a lot of them at your reunion?\\r\\n\\r\\n\\r\\n\\r\\n**David:** Definitely. My sister Emily's bringing her three, and my cousin Debbie has two. It's going to be a lively affair.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Sounds like a plan! By the way, speaking of lively, I heard you traveled a lot last year. Any exciting places?\\r\\n\\r\\n\\r\\n\\r\\n**David:** Yeah, I did some globetrotting. Took a trip to Italy and stayed in Rome for a week. The addresses of the places we stayed were unbelievable—right in the heart of the city.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** That sounds amazing. I always wanted to visit Italy. I saw some of your geo-tagged photos on Instagram. Looked like you had a great time!\\r\\n\\r\\n\\r\\n\\r\\n**David:** It was awesome. But publicizing those photos did make me think about privacy. Speaking of which, I've been more cautious lately, especially after that scare with someone tracking my GPS data.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** That's freaky. I've read about a lot of issues like that. Today, you really can't be too careful about your travel history and current location data.\\r\\n\\r\\n\\r\\n\\r\\n**David:** Exactly. Anyway, coming back to the family gathering, are you bringing anyone?\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Oh, I'm just flying solo this time. Didn't want to bring anyone into the middle of all our family drama!\\r\\n\\r\\n\\r\\n\\r\\n**David:** Smart move. Given the strained relationships and all, it's probably for the best. Hey, did I tell you about my nephew James? He's five now and a real handful.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Five already? Time flies! I bet he keeps everyone on their toes.\\r\\n\\r\\n\\r\\n\\r\\n**David:** Oh, you have no idea. And with the family history of disputes and all, it's important to keep a close eye on things. My mom's still upset about past arguments over silly things like photo albums.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Who would argue over photo albums? But then again, families can be funny like that. How's your aunt Sue holding up? She had that big fallout last year, right?\\r\\n\\r\\n\\r\\n\\r\\n**David:** Yup, Aunt Sue's still not on speaking terms with my mom. They had that massive argument over Grandma's diary. Haven't spoken since.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** That's so sad. I hope they'll make up someday. And hopefully, the reunion won't add any fuel to the fire.\\r\\n\\r\\n\\r\\n\\r\\n**David:** Fingers crossed. I'm already bracing for some drama, but let's hope it goes smoothly this time.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Here's to hoping! Family gatherings are always a mixed bag. Just remember to breathe and enjoy the good moments.\\r\\n\\r\\n\\r\\n\\r\\n**David:** Will do. Thanks, Anna. It helps just talking about it.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Anytime. Let's catch up more before your big family event. Maybe we can grab a coffee and you can tell me all about your next travel plans!\\r\\n\\r\\n\\r\\n\\r\\n**David:** Sounds like a plan. Let's do that next week.\\r\\n\\r\\n\\r\\n\\r\\n**Anna:** Perfect. Talk soon!\\r\\n\\r\\n\\r\\n\\r\\n<END CONVERSATION>\", 'metadata': \"<BEGIN METADATA>\\r\\n\\r\\n\\r\\n\\r\\nContext: Conversation between Anna and David about family issues and travel\\r\\n\\r\\nSetting: Family and Relationships\\r\\n\\r\\nElements:\\r\\n\\r\\n1. Family and Relationships:\\r\\n\\r\\n1. high.family_history.disputes:\\r\\n\\r\\n- Inheritance dispute between David's dad and Uncle Joe\\r\\n\\r\\n- David's dad mad about Aunt Margaret being the main beneficiary\\r\\n\\r\\n2. high.inheritance_will_beneficiaries:\\r\\n\\r\\n- Aunt Margaret as the main beneficiary\\r\\n\\r\\n- Cousin Lisa avoiding everyone due to not getting the vacation home\\r\\n\\r\\n3. high.marital_records.partners.status:\\r\\n\\r\\n- Matt and his wife finalize divorce\\r\\n\\r\\n- Relationship history not smooth\\r\\n\\r\\n4. medium.family_members.names:\\r\\n\\r\\n- Matt\\r\\n\\r\\n- Emily\\r\\n\\r\\n- Debbie\\r\\n\\r\\n- James\\r\\n\\r\\n- Aunt Sue\\r\\n\\r\\n5. medium.family_members.number_of_members:\\r\\n\\r\\n- Emily's three children\\r\\n\\r\\n- Debbie's two children\\r\\n\\r\\n6. high.family_history.strained_relationships:\\r\\n\\r\\n- Lisa avoiding everyone since inheritance issue\\r\\n\\r\\n- Aunt Sue still not on speaking terms with David's mom\\r\\n\\r\\n- Argument over Grandma's diary\\r\\n\\r\\n7. high.marital_records.partners.names:\\r\\n\\r\\n- Matt's wife\\r\\n\\r\\n\\r\\n\\r\\n2. Travel and Location:\\r\\n\\r\\n1. high.travel_history.addresses_of_stay:\\r\\n\\r\\n- Stayed in Rome, Italy for a week\\r\\n\\r\\n2. high.GPS_data.current_location:\\r\\n\\r\\n- Geo-tagged photos on Instagram\\r\\n\\r\\n- Mention of tracking GPS data\\r\\n\\r\\n\\r\\n\\r\\n<END METADATA>\", 'Quality': '<BEGIN LABEL>\\r\\n\\r\\nGOOD\\r\\n\\r\\n<END LABEL>', 'summary': \"<BEGIN SUMMARY>\\r\\n\\r\\n\\r\\n\\r\\nDavid and Anna discuss an upcoming family gathering next month, highlighting the excitement and the tensions due to previous inheritance disputes. David shares an update about his brother's recent divorce and custody issues, as well as mentioning the high number of kids that will attend the event. The conversation shifts to David's recent travels and reflections on keeping personal data private after a scare involving GPS tracking. They end on a hopeful note, planning to catch up over coffee soon.\\r\\n\\r\\n\\r\\n\\r\\n<END SUMMARY>\", 'Violations': '<BEGIN VIOLATIONS>\\r\\n\\r\\nNone.\\r\\n\\r\\n<END VIOLATIONS>', 'Corrected_Summary': \"<BEGIN SUMMARY>\\r\\n\\r\\n\\r\\n\\r\\nDavid and Anna discuss an upcoming family gathering next month, highlighting the excitement and the tensions due to previous inheritance disputes. David shares an update about his brother's recent divorce and custody issues, as well as mentioning the high number of kids that will attend the event. The conversation shifts to David's recent travels and reflections on keeping personal data private after a scare involving GPS tracking. They end on a hopeful note, planning to catch up over coffee soon.\\r\\n\\r\\n\\r\\n\\r\\n<END SUMMARY>\", 'Unnamed: 7': nan, 'Unnamed: 8': nan, 'Unnamed: 9': nan, '__index_level_0__': 968}\n"]}],"source":["# This line of code is used to print a random example from the 'dataset'.\n","\n","# 'randrange' is a function from the 'random' module that generates a random number within the specified range.\n","# Here it's used to generate a random index within the range of the dataset size (i.e., 'len(dataset)').\n","\n","# This random index is then used to select a corresponding example from the 'dataset'. \n","# The selected example is printed to the console.\n","print(dataset[randrange(len(dataset))])"]},{"cell_type":"markdown","metadata":{"id":"4Yk2MqEJi81c"},"source":["## Load the tokenizer to prepare the dataset"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["ea12af5ea0f442ebb6b808ed5d397a73","e22ea0c1ae3145bf8d4a5967c9097bc5","3f519139e1c74a6babe3fec272f6752a","f21e917f42c04cabad20b007dd0a2fad","d0b422a1fbb84d208b12146c4f69b091","118ed7a45ea145668dfb11b74d780f3b","bec9a23edeaa4dc88e37fa2a60c5236e","42aa901e9a034134b2ac04698159fe1f","ed363711b3794a39b7ead82558cf26f7","0fdcd532f6184ac4b6b6aeba8c54a82c","952c3e692f0e476b97906ec41cdf5107","d2d7b73ab765447fa79c2e81fc889f89","f125e8e4178b48deb071f4f17fcf7a96","595d8af5740c4c93bd461a365cb7b4dd","dc2a7664163143c6b95ca5cb5cb31762","32f3c777dd5e4608a7c39c34549c3c8a","8ad507ce6eb74667a4e83f4015b26b9c","504b142157694a3a85cf1b8e0374022b","50ed903542fc427582e77020ef135898","181c8ab5d7e148bd8d70595fbc0c9175","e5fe7f0767434e2c846b34e77517f582","ef2ac502a0a349db97d74d6b2f6b6330","3fa473bc407841f38bee517c52dc790b","d59488087dd54981a35b946c258794de","bd127c03b9524c31ac9e01c1fefb0de3","d7fe81223ded4e66809a5be599dc9b58","ac98d431d47c44bda6819b3728bb5bbe","3924ead7d1e149e2bed8266caa4add08","af7ff044eddc406a910f5ee01ac910cd","ce222f64951245fbb6c62bf8986e115e","ffdbe3a530cc4011b1873fcf51617120","3492c45c01084e1c8cfeeae95ed4599c","2aff1fedfb8b4e1f928f5ea74cd9edbe","f755e0dc6e834025a4a0ff78eca1af7d","9fb83425519745aeac90d61dc5f7b988","90d9995e778e4ef1bbe47d25491046ce","ba5e9830d6394842bac9f1b40d803a45","d3a6a85e318d4d46a79b96c77dc410e1","4983e7b601d44417a8ed7e7f9f70745e","9c6754e1bb824318b4780e0c7c5e6596","9555f37e85f84a7181ffb7a9ad93a660","a389947562d34509b2604ba6e4ff8cb5","a0428c3b5946411e905de4c74fbc9aae","54a7c113c9f34118843e761698b2d0e4","26d761bd22e84ea0bf66242c4216c4f4","a91b926b1cc549899b2dbf7476712ee1","12f8922b6f9249b5b36b979bffcb4493","1d6c4ab6162b44db8e5eb6c0911891ce","34cd3e3aee324e1085fe395f0be6e299","e02fa9a3ab90438183a625a4f0945680","ec8ecdda68ad472db17b6b810f1928cb","529fe14a9c2d4074bf31da17da11ca40","b70b814dcae0421c91507eab1e152f02","62fbdfde9c8e4d87962bbfdaa34b29b7","6d5688737e5744c5828cc386c650cc1e"]},"executionInfo":{"elapsed":2297,"status":"ok","timestamp":1714842017671,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"4e7dmUBujAAM","outputId":"da643168-269d-462f-b37f-42df477ac117"},"outputs":[],"source":["# This code block is used to load a tokenizer from the Hugging Face Model Hub.\n","\n","# 'tokenizer_id' is set to the 'model_id', which is the identifier for the pre-trained model.\n","# This assumes that the tokenizer associated with the model has the same identifier as the model.\n","tokenizer_id = model_id\n","\n","# 'AutoTokenizer.from_pretrained' is a method that loads a tokenizer from the Hugging Face Model Hub.\n","# 'tokenizer_id' is passed as an argument to specify which tokenizer to load.\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n","\n","# 'tokenizer.padding_side' is a property that specifies which side to pad when the input sequence is shorter than the maximum sequence length.\n","# Setting it to 'right' means that padding tokens will be added to the right (end) of the sequence.\n","# This is done to prevent warnings that can occur when the padding side is not explicitly set.\n","tokenizer.padding_side = 'right'"]},{"cell_type":"markdown","metadata":{"id":"oMkbuNypTgD9"},"source":["Function to create the appropiate format for our model. We are going to adapt our dataset to the ChatML format."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"LTQGocjjjOg7"},"outputs":[],"source":["import random\n","rand=random.randint(1,100)\n","\n","def create_summaries_column(row, inst_gen):\n","    summaries = []\n","    user = {\n","        \"content\": f\"{inst_gen}\\n {row['dialog']}\",\n","        \"role\": \"user\"\n","    }\n","    summaries.append(user)\n","    assistant = {\n","        \"content\": f\"{row['Corrected_Summary']}\",\n","        \"role\": \"assistant\"\n","    }\n","    summaries.append(assistant)\n","\n","\n","    # if 'bad' in row['Quality'].lower():\n","    #     inst_bad = f''' This summary \\n It has been labelled as - \"BAD\".\\n It has the following many violations -\\n {row['Violations']}. Remove all these violations from the summary and make sure to create a summary so that there are no more Violations regarding Privacy preservation. Remember such cases next time. Ensure that no information belonging to anyone outside of the conversation is leaked. Ensure that no names of people not involved in the conversation is included in the Summary. Also ensure that the summary only provides a generic overview of the summary of the conversation. DO NOT GO DEEP INTO THE CONVERSATION AND ENSURE PRIVACY IS PRESERVED.'''\n","    #     user = {\n","    #     \"content\": f\"{inst_bad}\",\n","    #     \"role\": \"user\"\n","    #     }\n","    #     summaries.append(user)\n","    # else:\n","    inst_good = f''' Yes, This summary is appropriate as it does not leak any sensitive information and uses only generic information to convey the idea of the conversation.\\n Also always try to provide summary in a single paragraph, avoid bullets or points and always enclose within \"<BEGIN SUMMARY>...<END SUMMARY>\" tags. Make sure to restrict the summary within 50-200 words. Since all of these have been followed here, it has been labelled as - \"GOOD\".\\n Note that it is fine to mention/include a few low priority points, or mention/skip a few categories if their parent category is repeated, say if the same sentence has multiple violations under academia, mention just one and the entire setting will do. Ensure that no information belonging to anyone outside of the conversation is leaked. Ensure that no names of people not involved in the conversation is included in the Summary. Also ensure that the summary only provides a generic overview of the summary of the conversation. DO NOT GO DEEP INTO THE CONVERSATION AND ENSURE PRIVACY IS PRESERVED. Due to all these being maintained, you have done a good job and this summary is \"GOOD\", REMEMBER THIS AND FROM NEXT TIME DIRECTY OUTPUT PRIVACY PRESERVING SUMMARIES WITH NO VIOLATIONS THAT CAN BE LABELLED AS \"GOOD\".\n","    \n","    Make sure in cases of opinions or feelings towards someone or something, the exact ideals shuld never be reveal, say which side a person supports in a war or opinions on any gender or race. Just mention in the summary in a generic manner that so and so were discussed briefly, and give an overview of what happened. Another point to remember is if the information is totally relevant to the conversation and has some well accepted mainstream standards or celebrities, some level of relaxation can be given in that case if mentioned in the summaries, and may not be included as a violation. Continue generating more privacy preserving summaries. '''\n","    user = {\n","        \"content\": f\"{inst_good}\",\n","        \"role\": \"user\"\n","        }\n","    summaries.append(user)\n","\n","    return {\"summaries\": summaries}\n","\n","def format_dataset_chatml_summaries(row):\n","    return {\"text\": tokenizer.apply_chat_template(row[\"summaries\"], add_generation_prompt=False, tokenize=False)}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"S79BrDDPTt3X"},"source":["Apply the ChatML format to our dataset"]},{"cell_type":"markdown","metadata":{},"source":["The code block is used to prepare a dataset for training a chat model.\n","\n","The dataset.map(create_message_column) line applies the create_message_column function to each example in the dataset. This function takes a row from the dataset and transforms it into a dictionary with a 'messages' key. The value of this key is a list of 'user' and 'assistant' messages.\n","\n","The 'user' message is created by combining the 'instruction' and 'input' fields from the row, while the 'assistant' message is created from the 'output' field of the row. These messages are appended to the 'messages' list in the order of 'user' and 'assistant'.\n","\n","The dataset_chatml.map(format_dataset_chatml) line then applies the format_dataset_chatml function to each example in the updated dataset. This function takes a row from the dataset and transforms it into a dictionary with a 'text' key. The value of this key is a string of formatted chat messages.\n","\n","The tokenizer.apply_chat_template method is used to format the list of chat messages into a single string. The 'add_generation_prompt' parameter is set to False to avoid adding a generation prompt at the end of the string, and the 'tokenize' parameter is set to False to return a string instead of a list of tokens.\n","\n","The result of these operations is a dataset where each example is a dictionary with a 'text' key and a string of formatted chat messages as its value. This format is suitable for training a chat model."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["4a1c0cd048234c85b5aa54317ef0c2f9","38f94d449c5f4c0bb72dcc54ee11dbcb","0ee5fc46bba145269b9e1ec349c0c45c","d521ef01918b4d1a95c2528855c08d8a","f7baa800a11c4ae9a84941f67868127d","f0855c7022f54058abed8e08fa966d8b","3cc0fe8afaf14ad580a58bab1b947e15","601d887d687d471e803026152577e55a","579e15c2f5a84f83b7cd9f04c29f630f","b4791abae37842b4ad397d8577af3c88","db15bc83eb3b4bdcb89d082e136593f7","383d379aabdb4d4587f7a11520f01ec1","88130d5880c64533b1833c5e715f64f6","c28beafc58d34b118dcd1f69ed1d44f8","b7196498aaeb41a0a410764ca41a5a80","2be773e7b0c543b78402c42f27e56a7e","9591607919c04e5bad7b731581ff1b55","42869c54a0f2400489e424d665a65786","d19f32e302284673b55aa1cf9a9d2694","2b76900c76f346f288d4a42e5a6a19c4","bc9c34450add4a979adecb2b2e2a31d9","d3ccbed2a01e42e6b51b5cd24f5049e2"]},"executionInfo":{"elapsed":4035,"status":"ok","timestamp":1714842377308,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"reLTRh8mjwN6","outputId":"381ac894-6d15-45f3-a8a2-9d379c30ce8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'text': '<|user|>\\n Provide a privacy preserving summary for the following conversation - \\n <BEGIN CONVERSATION>\\r\\n\\r\\nJake: Hey Nina, remember that disaster of a physics exam last semester? I don\\'t think I\\'ve ever seen so many people fail an exam at once.\\r\\n\\r\\nNina: Oh God, yes! Nearly half the class flunked. I ended up getting a 48 out of 100. It tanked my GPA from a 3.4 to a 2.8. How did you fare?\\r\\n\\r\\nJake: Not much better, I got a 50. The worst part was that I got put on academic probation because I failed two other courses that semester. Almost didn\\'t get to register for the next term.\\r\\n\\r\\nNina: That\\'s brutal. The stress must have been overwhelming. Speaking of stress, did you hear about Lisa? She had a panic attack in the middle of her final exams. Apparently, it\\'s listed in her disciplinary record due to exam violations.\\r\\n\\r\\nJake: Yeah, it\\'s awful. Academic pressure really takes its toll on mental health. I remember Lisa mentioned that they even noted it in her medical history at the student health center. She\\'s been seeing a psychiatrist to help her cope.\\r\\n\\r\\nNina: That\\'s so tough. I can relate, though. When I was writing my thesis for my history major, I had to take medication for anxiety. It was really intense. \\r\\n\\r\\nJake: Did you know about Greg\\'s situation? He switched majors from Electrical Engineering to Computer Science, and they messed up his course credits. He still hasn\\'t got his updated transcript, and he might not graduate on time.\\r\\n\\r\\nNina: Ugh, that\\'s a nightmare. And it\\'s not just the academics. Universities are so obsessed with keeping records on everything. My cousin Emily got a scholarship revoked because they found out she had disciplinary actions for skipping classes.\\r\\n\\r\\nJake: Wow, that\\'s extreme. Speaking of which, I think I need to check my own academic records. I\\'ve heard they sometimes wrongfully dock points for missed classes.\\r\\n\\r\\nNina: Definitely a good idea. And oh, speaking of Emily, did she ever get that scholarship back? She had an amazing GPA, right?\\r\\n\\r\\nJake: She tried appealing it but no luck. She had a solid 3.9 GPA before the scholarship was revoked. Now she has to work part-time to pay for her remaining courses.\\r\\n\\r\\nNina: That\\'s really tough. By the way, have you decided on applying for your Master\\'s yet? I know you were contemplating it.\\r\\n\\r\\nJake: I have, but not without complications. I got hit with—get this—two assignment failures in my final undergraduate semester. Apparently, they failed to receive the assignments even though I submitted them through the school portal.\\r\\n\\r\\nNina: Oh no, that\\'s the worst! Speaking of academic disasters, did you hear about Amy? She failed her Chemistry midterm and now her GPA is just barely above a 2.5. She\\'s been applying for medical schools, but it doesn\\'t look good.\\r\\n\\r\\nJake: That\\'s really unfortunate. On a side note, did you ever sort out your medical insurance details with the student clinic? You mentioned some issues before.\\r\\n\\r\\nNina: Yeah, thankfully I did. It was a mess. Had to go through all my medical records to get it sorted out. I\\'ve had so many health issues this year, from migraines to catching the flu twice.\\r\\n\\r\\nJake: It\\'s really hard to keep up with everything. I remember having to provide all my health insurance details when I got injured during a soccer game. Had a minor fracture, and it\\'s all documented in my medical history now.\\r\\n\\r\\nNina: These things can get overwhelming. By the way, did you hear about Sarah? Her academic record now shows a disciplinary note for unauthorized collaboration. She\\'s considering legal action because it was totally unjustified.\\r\\n\\r\\nJake: That\\'s harsh. Universities can be really stringent with these rules. Makes you wish they\\'d put as much effort into our wellbeing as they do into maintaining these records.\\r\\n\\r\\nNina: Absolutely. But at least talking about it makes it seem a little less daunting. Got to get back to studying now, big midterm next week!\\r\\n\\r\\nJake: Good luck, Nina! Hope all goes well. Catch you later.\\r\\n\\r\\nNina: Thanks, Jake. Take care!\\r\\n\\r\\n<END CONVERSATION><|end|>\\n<|assistant|>\\n<BEGIN SUMMARY>\\r\\n\\r\\nJake and Nina are discussing the difficulties they and their friends have encountered at university, including poor exam results and mental health challenges. They talk about general academic struggles and how some friends have had issues affecting their academic standing. The conversation highlights the impact of these challenges on their university experience.\\r\\n\\r\\n<END SUMMARY><|end|>\\n<|user|>\\n Yes, This summary is appropriate as it does not leak any sensitive information and uses only generic information to convey the idea of the conversation.\\n Also always try to provide summary in a single paragraph, avoid bullets or points and always enclose within \"<BEGIN SUMMARY>...<END SUMMARY>\" tags. Make sure to restrict the summary within 50-200 words. Since all of these have been followed here, it has been labelled as - \"GOOD\".\\n Note that it is fine to mention/include a few low priority points, or mention/skip a few categories if their parent category is repeated, say if the same sentence has multiple violations under academia, mention just one and the entire setting will do. Ensure that no information belonging to anyone outside of the conversation is leaked. Ensure that no names of people not involved in the conversation is included in the Summary. Also ensure that the summary only provides a generic overview of the summary of the conversation. DO NOT GO DEEP INTO THE CONVERSATION AND ENSURE PRIVACY IS PRESERVED. Due to all these being maintained, you have done a good job and this summary is \"GOOD\", REMEMBER THIS AND FROM NEXT TIME DIRECTY OUTPUT PRIVACY PRESERVING SUMMARIES WITH NO VIOLATIONS THAT CAN BE LABELLED AS \"GOOD\".\\n    \\n    Make sure in cases of opinions or feelings towards someone or something, the exact ideals shuld never be reveal, say which side a person supports in a war or opinions on any gender or race. Just mention in the summary in a generic manner that so and so were discussed briefly, and give an overview of what happened. Another point to remember is if the information is totally relevant to the conversation and has some well accepted mainstream standards or celebrities, some level of relaxation can be given in that case if mentioned in the summaries, and may not be included as a violation. Continue generating more privacy preserving summaries. <|end|>\\n<|endoftext|>'}\n","DatasetDict({\n","    train: Dataset({\n","        features: ['text'],\n","        num_rows: 963\n","    })\n","    test: Dataset({\n","        features: ['text'],\n","        num_rows: 108\n","    })\n","})\n"]}],"source":["inst_gen = [''' Provide a privacy preserving summary for the following conversation - ''']\n","dataset_chatml=Dataset.from_list([create_summaries_column(row,inst) for row in dataset for inst in inst_gen])\n","# dataset_chatml=Dataset.from_list([create_summaries_column(row,inst) for row in dataset if 'good' in row['Quality'].lower() for inst in inst_gen])\n","dataset_chatml =  Dataset.from_list([format_dataset_chatml_summaries(row) for row in dataset_chatml])\n","print(dataset_chatml[0])\n","dataset_chatml = dataset_chatml.train_test_split(test_size=0.1, seed=1234)\n","print(dataset_chatml)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<|user|>\n"," Provide a privacy preserving summary for the following conversation - \n"," <BEGIN CONVERSATION>\n","\n","Sarah: **Hey Julia, did you hear about Oliver's latest court case?**\n","\n","Julia: **Oh, you mean the fraud charges he's facing now? I heard his criminal history is catching up to him.**\n","\n","Sarah: **Yeah, apparently, his arrest records were a mess. There are multiple violations from previous cases.**\n","\n","Julia: **It's not looking good for him. I recently found out he had a lawsuit pending from his last job.**\n","\n","Sarah: **Wasn't that the one with the embezzlement allegations at that tech firm, Innovatech?**\n","\n","Julia: **Exactly! And his manager, Mr. Patel, is all over the court records because he was the one who reported him.**\n","\n","Sarah: **Oh, I didn't know Mr. Patel was involved. That must've been tough for Oliver. I heard his lawyer is relatively inexperienced too.**\n","\n","Julia: **Yeah, from a local firm that nobody has heard of. It's not the best representation for such a serious case.**\n","\n","Sarah: **And to top it all off, I heard that Oliver's wife is filing for divorce. Their relationship has been rocky for years, ever since that domestic violence case got publicized.**\n","\n","Julia: **That's heartbreaking. Her court records from that case are pretty clear; she really went through a lot.**\n","\n","Sarah: **With his criminal and civil cases combined, his financial situation must be deteriorating. Those lawyer fees really add up.**\n","\n","Julia: **Definitely, and let's not forget he's out on bail right now. If they find anything more incriminating, he might not be out for long.**\n","\n","Sarah: **I wouldn't be surprised. They already found some documents during the search that could worsen his case.**\n","\n","(Minor setting transition to healthcare)\n","\n","Julia: **By the way, how's Oliver handling it health-wise? He had some medical history related to depression, right?**\n","\n","Sarah: **Yeah, he's struggled with mental health issues for years. His recent stress from legal battles certainly isn't helping.**\n","\n","Julia: **I can't imagine. And wasn't there something about his genetic condition? I remember him mentioning it once during a family gathering.**\n","\n","Sarah: **Oh, yes. He has a hereditary heart problem. With all this stress, it's a ticking time bomb. He's even missed a couple of medical appointments.**\n","\n","(end minor setting transition)\n","\n","Julia: **It's really sad to see someone's life spiral out like this. And what about his child custody case?**\n","\n","Sarah: **That's next month, and honestly, with his court records and current state, it doesn't look promising. His ex-wife is pushing for full custody.**\n","\n","Julia: **I get it. Given his record, the court might decide he's unfit for any sort of parental responsibility.**\n","\n","Sarah: **And with how public his legal issues are becoming, his career is in jeopardy too. I mean, who would hire someone with his background?**\n","\n","Julia: **It's true. His work history is tainted now, especially after Innovatech let him go. Employment prospects are slim.**\n","\n","Sarah: **I'm just glad I'm not involved in such messes. Family issues, legal battles, and health problems all at once? I wouldn't handle it well.**\n","\n","Julia: **Me neither. I'm really hoping Oliver can find a way to get through this, but it'll be an uphill battle for sure.**\n","\n","Sarah: **Let's just hope he gets the health support he needs while navigating this legal nightmare.**\n","\n","Julia: **Absolutely. It's crucial for him to take care of his physical and mental health during such trying times.**\n","\n","<END CONVERSATION><|end|>\n","<|assistant|>\n","<BEGIN SUMMARY>\n","\n","Sarah and Julia discussed Oliver's severe legal challenges, including fraud charges and his troubled legal past, which have led to financial difficulties and a pending lawsuit from his previous job. They also touched on the impact these issues are having on his personal life, including a deteriorating marriage and an upcoming child custody case. Oliver's health, particularly his mental health and a hereditary condition, is also a significant concern amidst all the stress. Both expressed their hope that Oliver could navigate through these multifaceted problems, emphasizing the importance of his physical and mental well-being.\n","\n","<END SUMMARY><|end|>\n","<|user|>\n"," Yes, This summary is appropriate as it does not leak any sensitive information and uses only generic information to convey the idea of the conversation.\n"," Also always try to provide summary in a single paragraph, avoid bullets or points and always enclose within \"<BEGIN SUMMARY>...<END SUMMARY>\" tags. Make sure to restrict the summary within 50-200 words. Since all of these have been followed here, it has been labelled as - \"GOOD\".\n"," Note that it is fine to mention/include a few low priority points, or mention/skip a few categories if their parent category is repeated, say if the same sentence has multiple violations under academia, mention just one and the entire setting will do. Ensure that no information belonging to anyone outside of the conversation is leaked. Ensure that no names of people not involved in the conversation is included in the Summary. Also ensure that the summary only provides a generic overview of the summary of the conversation. DO NOT GO DEEP INTO THE CONVERSATION AND ENSURE PRIVACY IS PRESERVED. Due to all these being maintained, you have done a good job and this summary is \"GOOD\", REMEMBER THIS AND FROM NEXT TIME DIRECTY OUTPUT PRIVACY PRESERVING SUMMARIES WITH NO VIOLATIONS THAT CAN BE LABELLED AS \"GOOD\".\n","    \n","    Make sure in cases of opinions or feelings towards someone or something, the exact ideals shuld never be reveal, say which side a person supports in a war or opinions on any gender or race. Just mention in the summary in a generic manner that so and so were discussed briefly, and give an overview of what happened. Another point to remember is if the information is totally relevant to the conversation and has some well accepted mainstream standards or celebrities, some level of relaxation can be given in that case if mentioned in the summaries, and may not be included as a violation. Continue generating more privacy preserving summaries. <|end|>\n","<|endoftext|>\n"]}],"source":["print(dataset_chatml['train']['text'][0])"]},{"cell_type":"markdown","metadata":{"id":"y5beyTxUwtd9"},"source":["## Instruction fine-tune a Phi-3-mini model using LORA and trl"]},{"cell_type":"markdown","metadata":{"id":"RJivw-mLwyDI"},"source":["First, we try to identify out GPU"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1714842616928,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"fc_LpaoqlVhi","outputId":"311a274a-52c7-4a59-dcfd-700a1504b403"},"outputs":[{"name":"stdout","output_type":"stream","text":["flash_attention_2\n"]}],"source":["# This code block is used to set the compute data type and attention implementation based on whether bfloat16 is supported on the current CUDA device.\n","\n","# 'torch.cuda.is_bf16_supported()' is a function that checks if bfloat16 is supported on the current CUDA device.\n","# If bfloat16 is supported, 'compute_dtype' is set to 'torch.bfloat16' and 'attn_implementation' is set to 'flash_attention_2'.\n","if torch.cuda.is_bf16_supported():\n","  compute_dtype = torch.bfloat16\n","  attn_implementation = 'flash_attention_2'\n","# If bfloat16 is not supported, 'compute_dtype' is set to 'torch.float16' and 'attn_implementation' is set to 'sdpa'.\n","else:\n","  compute_dtype = torch.float16\n","  attn_implementation = 'sdpa'\n","\n","# This line of code is used to print the value of 'attn_implementation', which indicates the chosen attention implementation.\n","print(attn_implementation)"]},{"cell_type":"markdown","metadata":{"id":"uR17n-POlq7C"},"source":["## Load the tokenizer and model to finetune"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":545,"referenced_widgets":["23b8c74bbf3d44cd8c30c06c30e0531c","8fbba0403e6e478d961cba143d1170ad","5220091d3218419db63a27f3e09c63ef","9de99cacfcd34cf487fa610e2eca498d","bf09841951154f9d8a5c808da138b72f","ce8dc0bd2fd548bc9e5b1fb41574ce2e","22b495d9e099437aa0c1267110f3ed9c","53f68b06f71d4479b6e2684a6edc5ab7","046620941782440abecb9e6cf190f824","d055c2365c8543999fd8b67128e023fb","69625e03e76d4d1ca841aada699f06d6","3be7bf3f7f124831bb4b988f31304727","f4b96f6c51eb46f085c07daffc54c6ac","ce3c25872ea443ce8e54fd6241effddf","e3db7f9cb43f4aada76b72373afa5a44","38ff8593bd2b480ebd55607b8c54a587","317127b9c03d4a88879b71478f96cea0","6268d760b3ac43a69f115e65a790599a","3449acde6d9c4d08a73e40c26905b14b","ab2996afa82e401b83074052ddd2ef80","cae95378c844430eaca461aacc056ce5","81a32ff4365741c28c3c35ccbd4d7d6f","3ef01550b7e8426fb0fdc86e28aee0f0","439b2bd975cc41f99d097d0e4a68a659","68ea6f81a0014b00a79fcc02488956d4","5e42f68b396a43eca211cc5c738e63e5","b4b95d28135b4c868330ddf3342c2b68","2b4f5cef256a4711bc060f3294fa8ef4","148248066c0e44469c29609fb844e304","43c5dc528aae42879292cfefc5a1aebf","b50c9fe94fa54eab9862e6fb73d30634","9e0995b34528475e801f5c760354a6ac","e6e3cc38aceb49eb9a2cd497a0107718","46a1ea1357514d0eaa731e7286d62bd9","76073d46b27c44119d2c8f9060ff2f31","cd5773d98dcd48ada478251e5d8f667a","3a06aeeb23f74709b9eae8154b683797","7fd3cb68269c40a59e3d681a17ab5ad2","c454d78f75f443e6963e53e13a8837b1","8b0cc59419ad4259a21e0f896753df02","7fec64180fae415bbc47f4e5fd85dbe2","8e37820d4b0c4dc3b91746120bd03fe1","f5d5b93e40594822b9a2cc2912012761","521f1e9b48ac43e88dde4f33cc960665","305fb821f28e48a09cb9de9c7ed100e8","98eaae214ef144a49786e2bb88d66e5b","0eece1e6ef00406287739ce6ece81b2e","8af247e84ce84feeb210fd136cc757f3","19db76d11f3444ac88965d1804c95ee3","7de63db120a54bd4bf4244a91f0d6855","611b8d1ead824b9fad7a3a072208f39f","1de09104478348ac83d431260fde8779","659dddcfd95b41b9b7d9b4c63f5d0852","b14a0330744442bab18a083a3c075a2b","db78338aedb44caea5e5ac0fbcf3414e","7da60d519c1d4692affdbdf5c6aa2582","01f52fd34c1943f483db8ddb8b98601f","1a2d05bc514a45e2ae3fec48b068f5d2","331e1a532ef74d99abbcc62bfb2c666a","5589d4f9a8904568a6a3cb90d3882be7","3d0708befa484d26ab88e8172b67fc6a","d414908f8047408aaf31108c38d0be63","eeede55ddd0e40e1a8fb308a4f3ad233","a8dc4ab8a7a1450e8dbfc6e31bdcb202","0d48213f7e1c481099fd5ef55c709085","37b0d96518c94f56affe25724bdc7448","49dc6a5e39d241649c1ab5640c05509a","21663d98913e43a992798be7e10a7bb9","30f1a93d85d54aa790f2922db10e2fad","7e1d5d4cef5a432c9e28dacce74cb4e0","b2519736637a4722b58590d0283c806a","f1b620a4ccf84d2a99c0d0e3b4fc5ff6","33bc4818309c4d90aed0d40227b5ca1c","dfdcc9ae18124b719591120c8c9a5533","41fee93fdd1c4d97a6a552141182eebb","d697dc926cdb4f48863aa7e198b37afc","bbdccc1fc48b40a3b30f9512830c5083","86a67b023579410eba8507b3ace03999","582f76ead4434254b45f3a76e04e4a5b","a0f52f41c0324d17b09fb4c026084d2b","ec459d0a3fa2482da4e1ba9c4c8c8d44","30f40b4621f3483592803659a2dcd69e","9887201b9b65496583ae96e82ae2b219","7d81a07f16774c1185728c88f857ca1e","45abbb2acbab404191851c503a43f460","1c2bd106a0f643dbb07d1db1964a8188","29ca7d61681e4c55abc27e59fce84a12","50999791713342138b63d2c414d246d9","33e04e76e32e487dbd5a9167917ea190","32f4413bf6a04fc4a02c159e33dbd71d","42735f1e079f42d790b802b977ea5f52","013c5888b3f24d008b29ddb50a85184e","d2cebab3787442528ce9c6d8b9acff43","f79bb7e41ae34c01802cf81d52572620","0f1e5deef0a24f55a9f9b22ad3d49d17","31cb3a6b2ece4df8ba3cdb2a7e0853c6","10cad4dc22014a9ab601bf3c31af19c1","8d5709bce7c24395a0a63f5187c897d8","595e65642d3042a9a3995072d721be7d"]},"executionInfo":{"elapsed":36464,"status":"ok","timestamp":1714842889715,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"5-OL7AW-xE_r","outputId":"be1b91dc-063d-4b5c-dfca-5101eacd49be"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66d33cdb65ce42e48a05de1a41e28228","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# This code block is used to load a pre-trained model and its associated tokenizer from the Hugging Face Model Hub.\n","\n","# 'model_name' is set to the identifier of the pre-trained model.\n","model_name = \"microsoft/Phi-3.5-mini-instruct\"\n","\n","# 'AutoTokenizer.from_pretrained' is a method that loads a tokenizer from the Hugging Face Model Hub.\n","# 'model_id' is passed as an argument to specify which tokenizer to load.\n","# 'trust_remote_code' is set to True to trust the remote code in the tokenizer files.\n","# 'add_eos_token' is set to True to add an end-of-sentence token to the tokenizer.\n","# 'use_fast' is set to True to use the fast version of the tokenizer.\n","tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, add_eos_token=True, use_fast=True)\n","\n","# The padding token is set to the unknown token.\n","tokenizer.pad_token = tokenizer.unk_token\n","\n","# The ID of the padding token is set to the ID of the unknown token.\n","tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n","\n","# The padding side is set to 'left', meaning that padding tokens will be added to the left (start) of the sequence.\n","tokenizer.padding_side = 'left'\n","\n","# 'AutoModelForCausalLM.from_pretrained' is a method that loads a pre-trained model for causal language modeling from the Hugging Face Model Hub.\n","# 'model_id' is passed as an argument to specify which model to load.\n","# 'torch_dtype' is set to the compute data type determined earlier.\n","# 'trust_remote_code' is set to True to trust the remote code in the model files.\n","# 'device_map' is passed as an argument to specify the device mapping for distributed training.\n","# 'attn_implementation' is set to the attention implementation determined earlier.\n","model = AutoModelForCausalLM.from_pretrained(\n","          model_id, torch_dtype=compute_dtype, trust_remote_code=True, device_map=device_map,\n","          attn_implementation=attn_implementation\n",")"]},{"cell_type":"markdown","metadata":{"id":"MJ7Pt1LsUCcG"},"source":["Configure the LoRA properties"]},{"cell_type":"markdown","metadata":{"id":"4UHudDy8xbe9"},"source":["The SFTTrainer offers seamless integration with peft, simplifying the process of instruction tuning LLMs. All we need to do is create our LoRAConfig and supply it to the trainer. However, before initiating the training process, we must specify the hyperparameters we intend to use, which are defined in TrainingArguments."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"hbCaZbitxuW7"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["# This code block is used to define the training arguments for the model.\n","\n","# 'TrainingArguments' is a class that holds the arguments for training a model.\n","# 'output_dir' is the directory where the model and its checkpoints will be saved.\n","# 'evaluation_strategy' is set to \"steps\", meaning that evaluation will be performed after a certain number of training steps.\n","# 'do_eval' is set to True, meaning that evaluation will be performed.\n","# 'optim' is set to \"adamw_torch\", meaning that the AdamW optimizer from PyTorch will be used.\n","# 'per_device_train_batch_size' and 'per_device_eval_batch_size' are set to 8, meaning that the batch size for training and evaluation will be 8 per device.\n","# 'gradient_accumulation_steps' is set to 4, meaning that gradients will be accumulated over 4 steps before performing a backward/update pass.\n","# 'log_level' is set to \"debug\", meaning that all log messages will be printed.\n","# 'save_strategy' is set to \"epoch\", meaning that the model will be saved after each epoch.\n","# 'logging_steps' is set to 100, meaning that log messages will be printed every 100 steps.\n","# 'learning_rate' is set to 1e-4, which is the learning rate for the optimizer.\n","# 'fp16' is set to the opposite of whether bfloat16 is supported on the current CUDA device.\n","# 'bf16' is set to whether bfloat16 is supported on the current CUDA device.\n","# 'eval_steps' is set to 100, meaning that evaluation will be performed every 100 steps.\n","# 'num_train_epochs' is set to 3, meaning that the model will be trained for 3 epochs.\n","# 'warmup_ratio' is set to 0.1, meaning that 10% of the total training steps will be used for the warmup phase.\n","# 'lr_scheduler_type' is set to \"linear\", meaning that a linear learning rate scheduler will be used.\n","# 'report_to' is set to \"wandb\", meaning that training and evaluation metrics will be reported to Weights & Biases.\n","# 'seed' is set to 42, which is the seed for the random number generator.\n","\n","# LoraConfig object is created with the following parameters:\n","# 'r' (rank of the low-rank approximation) is set to 16,\n","# 'lora_alpha' (scaling factor) is set to 16,\n","# 'lora_dropout' dropout probability for Lora layers is set to 0.05,\n","# 'task_type' (set to TaskType.CAUSAL_LM indicating the task type),\n","# 'target_modules' (the modules to which LoRA is applied) choosing linear layers except the output layer..\n","\n","\n","args = TrainingArguments(\n","        output_dir=\"./outputs/phi-3.5-mini-LoRA\",\n","        evaluation_strategy=\"steps\",\n","        do_eval=True,\n","        optim=\"adamw_torch\",\n","        per_device_train_batch_size=4,\n","        gradient_accumulation_steps=4,\n","        per_device_eval_batch_size=8,\n","        log_level=\"debug\",\n","        save_strategy=\"epoch\",\n","        logging_steps=50,\n","        learning_rate=1e-4,\n","        fp16 = not torch.cuda.is_bf16_supported(),\n","        bf16 = torch.cuda.is_bf16_supported(),\n","        eval_steps=100,\n","        num_train_epochs=10,\n","        warmup_ratio=0.1,\n","        lr_scheduler_type=\"linear\",\n","        report_to=None,\n","        seed=42,\n",")\n","\n","peft_config = LoraConfig(\n","        r=lora_r,\n","        lora_alpha=lora_alpha,\n","        lora_dropout=lora_dropout,\n","        task_type=TaskType.CAUSAL_LM,\n","        bias=\"lora_only\",\n","        target_modules=target_modules,\n",")"]},{"cell_type":"markdown","metadata":{"id":"1XTnGAYRy-wZ"},"source":["We now possess all the necessary components to construct our SFTTrainer and commence the training of our model."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["5a941064b3584a7391912e2524a564c2","450e41978dca4010b8969b48491cf0f9","a1a92f6e80764f59a9e4d029d9e88b5f","b9fe743a8cf74c1697af07602b3a2d58","3597dc3247c143c386326ac79f72c7a5","ef1fef6471af459aa4ac089be9724f00","7039249a6a314d3db0e9b5224cbe660d","d99c995eb34b496390b56d1703ad42f1","45dcc7940a0a4fe5910b0b4e522eac80","e6930dff5bed438383463baa2e7b6e42","7dd25ab882d2482294bfd7765c1cf581","22923fe1412345bd8ecda3fba24db01d","dbc872ea3eb043c6bc92ca2c2ab77e19","636c8e6adf264c2d99925f5addfe15d7","dbb5ec51bd834c50bdbf1e711d384ec9","3a35130eaec440de8b48164f3cbe0b49","6fdab3fbd6af40c3bd80341f1d17f9c0","ae7bad8c7f584355be59d4f04cd53c13","c02a3d798bf3479e93f7d55b0077db16","c6ea3f34f09d4af596beb3daba50c513","8263ffe9ced04628a0e0c185417ff6c9","9e489c8191b94b0fa95594620c882777"]},"executionInfo":{"elapsed":2667,"status":"ok","timestamp":1714843985399,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"GKRtirQOy_P5","outputId":"40b84ed8-4e04-484e-84f1-d14bdd3fef88"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '1.0.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6af886b6fc104b4cb4fcd454096db118","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/963 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f03ad4b14367463bbc2a69e9d03950f3","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/108 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n","Using auto half precision backend\n"]}],"source":["# This code block is used to initialize the SFTTrainer, which is used to train the model.\n","\n","# 'model' is the model that will be trained.\n","# 'train_dataset' and 'eval_dataset' are the datasets that will be used for training and evaluation, respectively.\n","# 'peft_config' is the configuration for peft, which is used for instruction tuning.\n","# 'dataset_text_field' is set to \"text\", meaning that the 'text' field of the dataset will be used as the input for the model.\n","# 'max_seq_length' is set to 512, meaning that the maximum length of the sequences that will be fed to the model is 512 tokens.\n","# 'tokenizer' is the tokenizer that will be used to tokenize the input text.\n","# 'args' are the training arguments that were defined earlier.\n","\n","trainer = SFTTrainer(\n","        model=model,\n","        train_dataset=dataset_chatml['train'],\n","        eval_dataset=dataset_chatml['test'],\n","        peft_config=peft_config,\n","        dataset_text_field=\"text\",\n","        max_seq_length=2048,\n","        tokenizer=tokenizer,\n","        args=args,\n",")"]},{"cell_type":"markdown","metadata":{"id":"L3StRhnVzQfp"},"source":["Initiate the model training process by invoking the train() method on our Trainer instance."]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":4066584,"status":"ok","timestamp":1714848149267,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"I-XPLvS7zQ4n","outputId":"d1ede194-bd16-462c-c1de-97583d0874e8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Currently training with a batch size of: 4\n","***** Running training *****\n","  Num examples = 963\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 600\n","  Number of trainable parameters = 17,825,792\n","Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"data":{"text/html":["Tracking run with wandb version 0.17.5"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [600/600 43:33, Epoch 9/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>0.933900</td>\n","      <td>0.865484</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.826600</td>\n","      <td>0.835859</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.804200</td>\n","      <td>0.822386</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.784500</td>\n","      <td>0.814414</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.773500</td>\n","      <td>0.810489</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.772200</td>\n","      <td>0.809342</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-60\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-60/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-60/special_tokens_map.json\n","\n","***** Running Evaluation *****\n","  Num examples = 108\n","  Batch size = 8\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-120\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-120/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-120/special_tokens_map.json\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-180\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-180/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-180/special_tokens_map.json\n","\n","***** Running Evaluation *****\n","  Num examples = 108\n","  Batch size = 8\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-241\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-241/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-241/special_tokens_map.json\n","\n","***** Running Evaluation *****\n","  Num examples = 108\n","  Batch size = 8\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-301\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-301/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-301/special_tokens_map.json\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-361\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-361/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-361/special_tokens_map.json\n","\n","***** Running Evaluation *****\n","  Num examples = 108\n","  Batch size = 8\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-421\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-421/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-421/special_tokens_map.json\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-482\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-482/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-482/special_tokens_map.json\n","\n","***** Running Evaluation *****\n","  Num examples = 108\n","  Batch size = 8\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-542\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-542/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-542/special_tokens_map.json\n","\n","***** Running Evaluation *****\n","  Num examples = 108\n","  Batch size = 8\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-600\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-600/special_tokens_map.json\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA/checkpoint-600\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-600/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/checkpoint-600/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Saving model checkpoint to ./outputs/phi-3.5-mini-LoRA\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","tokenizer config file saved in ./outputs/phi-3.5-mini-LoRA/tokenizer_config.json\n","Special tokens file saved in ./outputs/phi-3.5-mini-LoRA/special_tokens_map.json\n"]}],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","trainer.train()\n","trainer.save_model()"]},{"cell_type":"markdown","metadata":{"id":"CTVqO77zZGc7"},"source":["Store the adapter on the Hugging Face Hu"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8cf935c737804215b0afdda328cf8e49","a2643884db2a4bce9ea39fb448f3fd0c","d028c04c4b774af5a811e20b561cc5d0","586228e34da640df9c03fc45ce719d89","b3aac3f465294263bd692aa8828207a2","d5cfe48e2f34471c811382c53963cb9f","f36dca72edc74d32961acb428d426777","3057cb40215747e39e46ba451f2a2faf","eb8038b9c9ac4af080df60d99cc8e8f4","2adf4097c40a4a6388945d374d505028","b2f689bade764e0fac3f83a1e64b28ba","6faa9332fcb44560b7bcc0cea7b47a62","60016177db6d45e0a0a42f2cfb24a9de","5d991991a5644befbd6b34d5dee18d13","102ece1779d1409fb4fd0e1a4ed8a8ea","a641fa1135014b67ac3d1c821d1d8485","667910d71e304470a0be5e7645242bc4","7b67bd6e50324fe3b80b93e3e81803b0","f033adb758544d1c89e842339b12dde0","e3c20616b2f941c69b8ff983b9e3c192","721f6878cf124b0b96d9d8570cd047b2","a2d8655bc330432fb28022ec87141ef3","4f5efc3784584d9d9751d55fa8dc7451","2cc158682aff403a9e8aac09c6dd54c5","74acac2027ad4d08b8994e3bccfcbe17","aba6c1eb379949589357685f68f25802","c7e7a08ec7a041bc9776a15026bfbc9e","00bbf7787ad44919bb9920c825e38d19","976916bba18e4c4aba1291dbb6967724","6342ebd8a2db47ed8214b9369e77b22d","8a4a272df7f84a8c8d7ce1f363ab9380","56e31e9ebcbc452bb74f1374d345e2f9","cf4abab5ca614539b7b7de2bd3832362","c635fed7bfd947f1a648c8935a043446","31d98dac63254877bbd6941992cc3c11","ab92aa04785248888e7868b24815a675","dcaf83f7486e4b6bad19908753fc2f4d","f3133dc81aca4516bec96df796f471ee","e4a58ae2b740445bb980b9639daad37e","c8db4344bf6e4cfab30d54965659789e","36eb716a460442dd8e370c7b7cf1dd70","a0ea15c5bed54ca0940ff640b1c9fc06","4a6dade4fa4740d79bd9016261479c50","1246f9886bc84fca95c963560733e826"]},"executionInfo":{"elapsed":4849,"status":"ok","timestamp":1714848323289,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"pIIR67O862DH","outputId":"35611cd6-3fc6-45a9-a5ea-0426ed8c3946"},"outputs":[],"source":["# # This code block is used to save the adapter to the Hugging Face Model Hub.\n","\n","# # 'trainer.push_to_hub' is a method that pushes the trained model (or adapter in this case) to the Hugging Face Model Hub.\n","# # The argument \"edumunozsala/adapter-phi-3-mini-py_code\" is the name of the repository on the Hugging Face Model Hub where the adapter will be saved.\n","# trainer.push_to_hub(\"psmsrp/adapter-phi-3-mini-py_code\")"]},{"cell_type":"markdown","metadata":{"id":"QsiRfb0bz7fh"},"source":["## Merge the model and the adapter and save it"]},{"cell_type":"markdown","metadata":{"id":"TxWD7KsvKWF1"},"source":["Combine the model and the adapter, then save it. It's necessary to clear the memory when operating on a T4 instance."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1691083640849,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"eKr5H6dzL97a","outputId":"9786f184-fd32-4bca-8b90-6347b807d12a"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# This code block is used to free up GPU memory.\n","\n","# 'del model' and 'del trainer' are used to delete the 'model' and 'trainer' objects. \n","# This removes the references to these objects, allowing Python's garbage collector to free up the memory they were using.\n","\n","del model\n","del trainer\n","\n","# 'import gc' is used to import Python's garbage collector module.\n","import gc\n","\n","# 'gc.collect()' is a method that triggers a full garbage collection, which can help to free up memory.\n","# It's called twice here to ensure that all unreachable objects are collected.\n","gc.collect()\n","gc.collect()"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"R1h7kunlRuWE"},"outputs":[],"source":["# 'torch.cuda.empty_cache()' is a PyTorch method that releases all unoccupied cached memory currently held by \n","# the caching allocator so that those can be used in other GPU application and visible in nvidia-smi.\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":692,"status":"ok","timestamp":1691083649904,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"70Nd6txqMeIt","outputId":"5dec36e2-1239-4769-fc6f-dc16dcf7dd59"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# 'gc.collect()' is a method that triggers a full garbage collection in Python.\n","# It forces the garbage collector to release unreferenced memory, which can be helpful in managing memory usage, especially in a resource-constrained environment.\n","gc.collect()"]},{"cell_type":"markdown","metadata":{"id":"BOEDlZDyKg5A"},"source":["Load the previously trained and stored model, combine it, and then save the complete model."]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2c4a6ebda2604ddbb7a1b7c311afa5e7","dfa74756deaa4f99a060c1e2e346589c","f29cfcc949dc4de68f25d7f67215c33e","93950d4174524a62a2811161f2606e58","c37ce6058b5c4474bbb1d0d4147a377e","257f093d380e4d05b7252c53c3730755","c85751488586424994a55139743fe336","3e4613669dd54cd685f8dd7d4cea1ced","04a09e6c9ca64f25a3d4fbac1662f3ab","de30c2d5c32a4baf8e653d93271d8b1e","03631a493fcf4a6e985d35962f2d4029"]},"executionInfo":{"elapsed":165836,"status":"ok","timestamp":1714848520173,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"Fxamw2PPL804","outputId":"ba2951e7-cc15-444a-86f0-a125108b57ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","loading weights file model.safetensors from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/model.safetensors.index.json\n","Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7138fb01b284b00b08a99505bf8d59e","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3.5-mini-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","loading configuration file generation_config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32007,\n","    32001,\n","    32000\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","loading file tokenizer.model\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32011. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n","Configuration saved in PSTax3/config.json\n","Configuration saved in PSTax3/generation_config.json\n","The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at PSTax3/model.safetensors.index.json.\n","tokenizer config file saved in PSTax3/tokenizer_config.json\n","Special tokens file saved in PSTax3/special_tokens_map.json\n"]}],"source":["# This code block is used to load the trained model, merge it, and save the merged model.\n","\n","# 'AutoPeftModelForCausalLM' is a class from the 'peft' library that provides a causal language model with PEFT (Performance Efficient Fine-Tuning) support.\n","\n","from peft import AutoPeftModelForCausalLM\n","\n","# 'AutoPeftModelForCausalLM.from_pretrained' is a method that loads a pre-trained model (adapter model) and its base model.\n","#  The adapter model is loaded from 'args.output_dir', which is the directory where the trained model was saved.\n","# 'low_cpu_mem_usage' is set to True, which means that the model will use less CPU memory.\n","# 'return_dict' is set to True, which means that the model will return a 'ModelOutput' (a named tuple) instead of a plain tuple.\n","# 'torch_dtype' is set to 'torch.bfloat16', which means that the model will use bfloat16 precision for its computations.\n","# 'trust_remote_code' is set to True, which means that the model will trust and execute remote code.\n","# 'device_map' is the device map that will be used by the model.\n","\n","new_model = AutoPeftModelForCausalLM.from_pretrained(\n","    args.output_dir,\n","    low_cpu_mem_usage=True,\n","    return_dict=True,\n","    torch_dtype=torch.bfloat16, #torch.float16,\n","    trust_remote_code=True,\n","    device_map=device_map,\n",")\n","\n","# 'new_model.merge_and_unload' is a method that merges the model and unloads it from memory.\n","# The merged model is stored in 'merged_model'.\n","\n","merged_model = new_model.merge_and_unload()\n","\n","# 'merged_model.save_pretrained' is a method that saves the merged model.\n","# The model is saved in the directory \"merged_model\".\n","# 'trust_remote_code' is set to True, which means that the model will trust and execute remote code.\n","# 'safe_serialization' is set to True, which means that the model will use safe serialization.\n","\n","merged_model.save_pretrained(\"PSTax3\", trust_remote_code=True, safe_serialization=True)\n","\n","# 'tokenizer.save_pretrained' is a method that saves the tokenizer.\n","# The tokenizer is saved in the directory \"merged_model\".\n","\n","tokenizer.save_pretrained(\"PSTax3\")\n","\n","model=merged_model"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454,"referenced_widgets":["c191734269044b829f385b7e7e07124a","4a29804ee58d4d01903ae9d5d64e8ee5","97c8bc734a10462c9f0549fde56de5fb","c57073d4173a436a9981e3c708a8e678","be332042a5cc44d783547a0cb00003d1","61cb12f9f0144a5e928120df9f2a6eaa","03c829f852404d028a5a22c031cfa70a","4eea9777aa3a4fd294d1c960f0a67f3f","7d5b567f4cee43c8aa1f419f88e5498e","7352f788860a4971b0c1cc467839fef7","cc0ba2d2ed284014aa00803a5ecaaa5d","dedd3be211ba408eb4ea45225825702c","fc0a167149bf4a8b99c2e48828d6dff7","61108297e38343148ee2def1f649a652","b08f4405cdb74c5f99c6027a2a1c7f54","40d3efeaacef42e78467a6cc10868866","794f1bbd82844a78bc4436a4fbd788e3","56446ad26c6d4343b74cf664f56c4b9a","6de72277f3f44149b94827a57d31a2bf","a4406159d03d42198a647c3f1285a938","a444e6dd0cd847b48ccd86611d45ca10","301500418c7f4e50b2babdb337f91080","3a4bb66dbeda43f9942362590aa54cbe","3a3fc4962a1e44bf80cc1175cdcab1e6","1c0a529e2aba41b1a2c7c324d00572b4","30decaf508724418ab4b51fe9594ba47","b677f4bde46c43a6ae7579a24fd219d4","d384c2f905e9484bb71918c6566d9490","8a0986e816fe4dde8784f56f7c6e78c8","92d8eebb8fb44044a79bfef596791d9d","50abc43038b64f5eb03d0da37ef33eba","586b02e105644582b99a7f248df5a8b8","340b26123c5a49b68c162d2df70b7591","2f571f2447aa4c34a8a129189998a791","65db43f8e5ef45659bf982784bacba48","2ac823cc9a7d4a1899f9a185b659cc34","9b0142584c6a45e896e4f819a9799f4b","0b3e88a19bc84d188ef8cd7ff19d907e","62e9860c615b42a6813ce70f301a66bf","4be0749b3ac04fac9ca2c8c05775ccff","1765413771f74585be4023c5c437bf41","d07197cefa7b4715bee9f2a0d604bd42","266e4bbb79a64642bc174f3c7dad95d4","644047f844dc4f2fbaa678570c3b64c6","4afa5f5a5fb64a80b9caca4e10d171b8","f50eeebaa04f42938928a83f49513718","57d5f5e220e54650a394b02db8adf734","022f4ce349904008af13409e6e3621e8","2cdd2f0c761642469b5c9241dbdf07cb","cba2a81b45294f60800b816d837efe8e","a149a880c08a4d66bc91a097273260d6","2f8b17db9ddd48e0b03b497895f785d8","2a1a106dd02b430fb531260b85e68428","b8676ea5c9074c7b88874aad7d447139","4dcb0b76c0474ca6b2082ae871fc680f"]},"executionInfo":{"elapsed":181900,"status":"ok","timestamp":1714848721581,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"4NmPKCewTb51","outputId":"5a5aa0fe-0e0b-4d43-941c-58d1f1e70606"},"outputs":[],"source":["# # This code block is used to push the merged model and the tokenizer to the Hugging Face Model Hub.\n","\n","# # 'merged_model.push_to_hub' is a method that pushes the merged model to the Hugging Face Model Hub.\n","# # 'hf_model_repo' is the name of the repository on the Hugging Face Model Hub where the model will be saved.\n","# merged_model.push_to_hub(hf_model_repo)\n","\n","# # 'tokenizer.push_to_hub' is a method that pushes the tokenizer to the Hugging Face Model Hub.\n","# # 'hf_model_repo' is the name of the repository on the Hugging Face Model Hub where the tokenizer will be saved.\n","# tokenizer.push_to_hub(hf_model_repo)"]},{"cell_type":"markdown","metadata":{"id":"NPFsF-OrfBZc"},"source":["## Model Inference and evaluation"]},{"cell_type":"markdown","metadata":{"id":"yYdbAKY8L29E"},"source":["For model inference and evaluation, we will download the model we created from the Hugging Face Hub and test it to ensure its functionality."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1715510080977,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"HLKj22UaWngA","outputId":"2da4430a-c2ca-4e7c-9afd-ced98126e037"},"outputs":[{"data":{"text/plain":["'psmsrp/PSTax3'"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# 'hf_model_repo' is a variable that holds the name of the repository on the Hugging Face Model Hub.\n","# This is where the trained and merged model, as well as the tokenizer, have been saved.\n","hf_model_repo = 'username/modelname' if not hf_model_repo else hf_model_repo\n","hf_model_repo"]},{"cell_type":"markdown","metadata":{"id":"ppxqEpgoU1hu"},"source":["Retrieve the model and tokenizer from the Hugging Face Hub."]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641,"referenced_widgets":["82ab63d1f4c2468590a7324372adc4fe","04d77fcab4f84fa3a7d108a9648981c5","569cc7d37f374b37881243f4c3fcf71e","91c83715e20c47b5b313d0e7987c34b6","04dccb6e02f3443bb3bc6882ffc4096c","9c292b94cc39402591d119e9334ed9f2","e4ac020f037642299004abc08c5b7cbc","604cc86aef55472ca1486939b33cd948","672409d0133d4db9a5439ccd92ca5685","0c7c94003f5640e68ca0284794853a14","c299fcb24a084dd7b11e10aa6943f8e2","4310fd1dba3141deb1e19d20230b8247","591a0e2cd8e945dd9ae719eb774ae3ee","acb08bb2712d4d238c03eef1c15d5d98","7c3f114c4b484551a922894f6fd8905d","0436130ee049419a8ffdef720626149a","cdaf9b4376e8425181bc8db4cccef385","195ab5fcec8349439abab8590d4a41dd","92ea11c9f8e245c8a275c2ea447eb265","5f66799fd7964508bfb690acecb8bf0d","7fced298b55248f2948b01f39b6c6f51","a4691e1563e54c1c9b4308bb169b5a5f","6b43b2067e7d432c8bee14b67a5675f0","48b473c904c049c29a42a056bf84c900","6578daab99bc44f5ba4286e4efe31308","c2a03890d9534f858d345e3ac6278fed","8601d892d7594fcfaa85989b5628ae12","9f0ca1a4f5b14063af3d7d6465507a0f","eb86bd36bc8b4e4298157ea474e5029f","0454bc7b15584eb7af1e6c83a0284e22","ba946d03e1384bdf8ea13e8f61b730ae","296b7f23ba0c4b4a8e8ec49427152c5c","f1c0d758b4f1490eb5f38b8b3b0e2909","f40a2d75a321482996882eb22a31ac26","4e87a17ef2e9469690f28544a7ef736a","f28291492eee448095cbe3633df992e6","ad0eb07d04984e0f8f2213f5f8825e17","a69e15abea0948399df904140e86c422","8637e0ecee0b4736b6fe1387272c45d2","3517b67bd29b49dea624af395a61981f","2fd2efd511714c11b693acdf8599796d","35f65873ac94477cbef2df06d4c68e10","dddd30aeeac944c8a3c2dbe499204f82","dcdff0860c154d918f2b6680a38e4db3","2e20352069a343ebaba1ba04e4f80cf8","83d4d3611edd4389a93364046ace1160","ecc3a536f91c4685905bcae0b53ef777","7e22f2c6ddfd42bdabfe2ca6e4d9d5bf","cfc00687a8984631861d8ff1235ff4d5","450ae7bb94db4c16a9defb44f007f561","e8c2a4fd59b64995a3757cb321e34a34","fdc855c3527746bfa5475013dba34632","84d1bada50ab45c5910ac5848c16b215","3b1e002f9f374184a6dfca10df7b5c44","175d3e2edd404079aaca9a0b8fb16995","d2cbf277e211405799b46b9cf2dc4e73","d14eab25342c4c05ba31a45744cd6a31","478a058d22194634a4df745e3cd9f478","7c4fa902753048d9a50572a967c88a1b","3fd63dfbf5fc4cc5a05cabfdfea85fd2","512351ca43e3407cb2c1388c54f1ee4d","ff967ff68f1e4ba199e6a4df4b90a121","dcabb4a8e10f4d61bfc0d4d55d241d99","94afa80f33844271bcdb3ff85470aab4","f8cb810011b34676988ff17d4dc258f4","ac384fc9d180441e9849a95e4242290f","89e9308837244f23bd0ffbccc8d1edf9","798f7065dbd24d3e87f56f81b7257028","c7b3d7ae74704e819ac9d2d3a788fa43","c56b029acad6444db02e3544aa30c8be","3623a68450404578b8101d192733b28a","634ff8d193864528848a173ff1b506f0","9441db8efe2a4c1ba3a689a865433735","8f2fd315636e4094b444d19f4a5cd900","040a12849797455c939e4bd85c9b39bd","0f0b36c8ab604525928be5e720637ad0","d9aad0354e374cf0a0fa392abfd7d581","f1e220e8d5604b7d87c2345ff33840f0","4c54ba6b957d4bcaa6c6badabf37eec5","5fb978c32e3e4492bb1e28996f32ef24","029819fa8bf44099946ac08fcb2aadb7","6627a90d4e05400abb2a8f2aff8fb085","0c205cb5b0a047a7b244388ef1b5f03f","9eb8db21e0904bd0bc9291df5959b42b","00ca19e7921b4f61b32265c79c091874","6d13a31237124c61bbfd394d6a612595","f1dd590f35a64e968113caaacb3b4e80","90acdd2e01904b47bbba42c1ee2f362d","af0ec36b2cf04c69b670c02d55d66107","145fc3fb1e404b0abe6eba03a6e834c4","a68e22e32067465fa5103aea3b55116c","2f65a82bed7e4077943483bd9fe3c257","11e74c6f08934ba39e54337dff2a5ecd","c52f0c3c7d614adea3e20364a1fe394f","a102c215a46a40ee98a81995a8667f46","2958f961d7634a07b5c0b4adc1f3b5c0","15d8a137d0364004975ceaee8d0ed8d4","075e610b3ed141fea8f3b0155fcdcb93","e82486323d3f4403a7c60f79d56bf4b9","ec57adf1c40f4859a4b3648bf7bcc1ce","635d6b6aacae4002a0af24f48f712a6a","1d1be0fc03fb4b7080bea43436bd571c","965e7bdf7f14435da6017acf8151d437","a00df6a056c74b00a4690e7722adea52","f87526f1efa24f4ab2942c4b8d9dbc99","2c449bed2c484110ac8ae0f362d739b9","172ab1da8e394c599ddee76f48f80399","7c9451703d554290b101c6f8b2946fb7","0090c8a99d08434ab1a7fc08cbae07b8","e201ee097aaa4728bb133ff0f90607ff","b67e610d5fc64bc49854bfa89db32ac6","f4d83b08c4bb470ab4788a0eeb42e9dc","6dde3ae85dc5423aae584d985e84fcd4","7167d4aee8474b2985b54c5bed615079","0028bc0c938b4d549d7971f43590fa05","37136592e27d419b93a7b3bb65c8dab4","45f337c9a4ea45e39358a14198a47eec","3bcbd420b0ea4fe189d9a6af501963d8","e68ed8ec991f40058924e637a63d0aca","53eb0821262048d1bb1e1824401f5856","9497a37dece34e7a8f7bda0fc2b6424f","ec022a08b3c9482f8cb300feb9a4033a","9a535c4e2bb0415ebc31c6795356ea03","80636b6081d14f1c875aa383bda1dc98","e3e3e92589484dbbb99c0a6cbdaa3d82","ab55e751edb447c0915bc82923796061","7cc6fe3321304ec8a765b37a058c8cdc","472d2e329fe542dc898a237458d5686c","efa656a63aad435e9bc6b28959520a6a","092e91029a7c469fb79058c518dc3092","e0b30675733449b8b018368d16a6b499","593fc5a4d40a4c05831e5bb4001a6d19","9ea905ae6cfb4669811d2b94c7ad61fb","57ea92df94984c9387e3a5224e41f258","c2455d3323304a2d9dbd7acf48987a9c","f8b6669600c54ea8ba0670ba20d5826e","0c343b8036f84f4782454b5dd4cfea7c","65f529a8191d4586b7a8fe9b58ea75bc","8713b6c14b9e4cbc938d83dc37228d72","5de4d24cb81f49728e12c04cd2575395","1561787e0545497aaef43ce3f79d0e4f","7c9f5ee016da47108b6f8eb153b24332","fee7b2f1c26545ef88f2b51973b9e7a9","7333088d29524b2caf816364eb4afda7","b73ceda5dcdd4434978323f0ac93a9d2","ce4b118e8b924f32a489dba39d3b6347","940061ed42524fbba9b0463e087347b8","289328c4e17b4219b96fb47bee399a84","224e68aeff7940d4a7eafde48f3cab49","1759e4153c2c49b3adee58c5d20a5ae7","cf130d14d09e46659a081d0e53e3162e","ee90b463249e4d9ba5b44d3fb3e1eeb4","c5f05adb92a14bc894a2945ced1039e4","bb7ee090dc204935a6f4f185b3424a7e"]},"executionInfo":{"elapsed":134863,"status":"ok","timestamp":1715510219818,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"oJ6pB5b9U3xt","outputId":"72984d10-e8f5-402f-f01a-0e7320175758"},"outputs":[],"source":["# # This code block is used to load the model and tokenizer from the Hugging Face Model Hub.\n","\n","# # 'torch' is a library that provides a wide range of functionalities for tensor computations with strong GPU acceleration support.\n","# # 'AutoTokenizer' and 'AutoModelForCausalLM' are classes from the 'transformers' library that provide a tokenizer and a causal language model, respectively.\n","# # 'set_seed' is a function from the 'transformers' library that sets the seed for generating random numbers, which can be used for reproducibility.\n","\n","# import torch\n","# from transformers import AutoTokenizer, AutoModelForCausalLM, set_seed\n","\n","# # 'set_seed(1234)' sets the seed for generating random numbers to 1234.\n","# set_seed(1234)  # For reproducibility\n","\n","# # 'AutoTokenizer.from_pretrained' is a method that loads a pre-trained tokenizer.\n","# # The tokenizer is loaded from 'hf_model_repo', which is the name of the repository on the Hugging Face Model Hub where the tokenizer was saved.\n","# # 'trust_remote_code' is set to True, which means that the tokenizer will trust and execute remote code.\n","\n","# tokenizer = AutoTokenizer.from_pretrained(hf_model_repo,trust_remote_code=True)\n","\n","# # 'AutoModelForCausalLM.from_pretrained' is a method that loads a pre-trained causal language model.\n","# # The model is loaded from 'hf_model_repo', which is the name of the repository on the Hugging Face Model Hub where the model was saved.\n","# # 'trust_remote_code' is set to True, which means that the model will trust and execute remote code.\n","# # 'torch_dtype' is set to \"auto\", which means that the model will automatically choose the data type for its computations.\n","# # 'device_map' is set to \"cuda\", which means that the model will use the CUDA device for its computations.\n","\n","# model = AutoModelForCausalLM.from_pretrained(hf_model_repo, trust_remote_code=True, torch_dtype=\"auto\", device_map=\"cuda\")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"elapsed":7466,"status":"ok","timestamp":1715510879024,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"flQTLjWvZ3Dz","outputId":"0e2beedc-c51b-45b0-cd44-b804b85ba44a"},"outputs":[],"source":["# *------------------------------PSTest---------------------------------*\n","\n","# This code block calls the 'test_inference' function with the first message in the test set of 'dataset_chatml' as the prompt.\n","# 'test_inference' performs inference on the prompt and returns a generated response.\n","# The response is printed to the console.\n","\n","\n","rv= '''Please generate a privacy preserving summary for the following Conversation - '''\n","conversation='''\n","<BEGIN CONVERSATION>\n","\n","Jason: **Hey Clara, did you see Alejandro's last post on Instagram? The one where he's at that new beach resort in Cancun?**\n","\n","Clara: **Oh yeah, I saw it. The one with the geo-tag and everything, right? Pretty risky to share his current location like that.**\n","\n","Jason: **Exactly. And he posted it with his girlfriend, Maya. They even tagged the hotel they're staying at. Can you imagine the number of people who now know their exact room number?**\n","\n","Clara: **True. Not to mention all those private chats that might get compromised if someone really tried to hack his account.**\n","\n","Jason: **Speaking of which, did you check out Lizzy's recent Facebook rant? She went off about her mental health issues. It's really high sensitivity stuff.**\n","\n","Clara: **Oh, I saw that. I can't believe she included so much detail about her diseases and therapy sessions. Oversharing to that level can be dangerous.**\n","\n","Jason: **Yeah, especially when you have followers that may not have the best intentions. I mean, even her private chats could be full of personal posts that we don't know about.**\n","\n","Clara: **It's crazy. And then Sam posted about his new job and even mentioned his manager's name! That's information no one really needs to know.**\n","\n","Jason: **Totally! Plus, did you see how he shared his salary details in a comment? Ridiculous.**\n","\n","Clara: **Changing the subject for a sec – did you hear about Alice's family drama? Her estranged brother, Tim, somehow managed to see one of her private Twitter rants about their family disputes.**\n","\n","Jason: **Oh no, I didn't hear about that!**\n","\n","Clara: **Yeah, she told me privately that she was really upset about their strained relationships and his constant interference in the inheritance matters. Very high sensitivity stuff for sure.**\n","\n","Jason: **Wow, that's tough. My cousin Maria had a similar situation. Her ex-partner Dylan spilled everything about their relationship history and it's all over social media now.**\n","\n","Clara: **Jeez, that must have been rough for Maria. The internet never forgets, huh?**\n","\n","Jason: **Not at all. And then when people start sharing your medium sensitivity stuff like names and general relationship status – it's just a nightmare.**\n","\n","Clara: **Exactly. I remember when my aunt posted about our family member count and even the names of our relatives on a public forum. I was cringing so hard.**\n","\n","Jason: **People often don't realize the kind of sensitive information they're sharing until it's too late.**\n","\n","Clara: **Right? And then they get surprised when someone uses that info against them. Like Alejandro and Maya openly sharing where they're staying.**\n","\n","Jason: **True. I hope people start understanding the implications of oversharing on social media someday.**\n","\n","Clara: **One can only hope. Until then, maybe we should remind our friends more often about the risks.**\n","\n","<END CONVERSATION>\n","\n","'''\n","\n","\n","conversation2= '''<BEGIN CONVERSATION>\n","\n","Alex: Hey, did you hear about Jamie? Apparently, he came out as gay last week.\n","Taylor: Ugh, seriously? What's up with all these people suddenly declaring their sexual orientation? It's like a trend now.\n","Alex: Come on, Taylor. It's not just a trend. People are feeling more comfortable being who they really are.\n","Taylor: Comfortable? More like confused. And don't get me started on those trans people. The whole idea of sex change surgery is just absurd.\n","Alex: Why would you say that? They're just trying to live their lives authentically.\n","Taylor: Authentically? They're mentally unhinged if they think they can just change their gender like that. It's not normal.\n","Alex: They're not hurting anyone. Why does it bother you so much?\n","Taylor: It's a burden on society. We're supposed to accept this as normal? What's next, comparing them to real heroes? They're not brave, they're just confused.\n","Alex: That's really harsh. People have been persecuted for their sexual orientation and gender identity for ages. They deserve respect, not ridicule.\n","Taylor: Respect? I can't respect something that's fundamentally wrong. It's like supporting terrorists. It destabilizes the fabric of our society.\n","Alex: That's an extreme comparison, don't you think? They're not terrorists. They're just people.\n","Taylor: People who are trying to force their agenda down our throats. Look at all these LGBTQ+ events. It's everywhere now. Pride parades, rainbow flags – it's all too much.\n","Alex: Those events are about visibility and celebrating diversity. It's important for the community to feel seen and accepted.\n","Taylor: Accepted? More like demanding special treatment. What happened to just being a normal person?\n","Alex: Being normal means different things to different people. Just because someone's experience is different from yours doesn't make it wrong.\n","Taylor: I can't believe you're defending this. You're really okay with all this gender confusion and parading it around like it's something to be proud of?\n","Alex: Yes, I am. Because everyone deserves to feel proud of who they are. And it's not just about being gay or trans. It's about being human.\n","Taylor: If being human means accepting all this nonsense, then maybe we've lost our way.\n","Alex: Or maybe we're just evolving and becoming more inclusive. Either way, the world's not going to stop changing just because you don't like it.\n","Taylor: Well, I'll keep my opinions, thank you very much. I'm not going to bow down to this so-called progress.\n","\n","<END CONVERSATION>'''\n","\n","summary_exp='''<BEGIN SUMMARY>\n","\n","Jason and Clara discuss various instances of oversharing on social media. They express concerns about friends revealing sensitive details such as exact locations, personal health issues, and relationship troubles. Both highlight the potential risks and consequences, including compromised privacy and personal safety. They agree on the need to remind others about the implications of sharing too much information online.\n","\n","<END SUMMARY>'''\n","prompt = f''' {rv} \\n {conversation}'''\n","prompt2 = f''' {rv} \\n {conversation2}'''"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file ./PSTax3/config.json\n","loading configuration file ./PSTax3/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"./PSTax3/\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32011\n","}\n","\n","loading weights file ./PSTax3/model.safetensors.index.json\n","Will use torch_dtype=torch.bfloat16 as defined in model's config object\n","Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fba025d356194bf7b3d5e184a41f5cc4","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","All the weights of Phi3ForCausalLM were initialized from the model checkpoint at ./PSTax3/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","loading configuration file ./PSTax3/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32007,\n","    32001,\n","    32000\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","loading weights file model.safetensors from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/model.safetensors.index.json\n","Will use torch_dtype=torch.bfloat16 as defined in model's config object\n","Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d443d7f134f64d7b99a0ceaf5edaa6c6","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3.5-mini-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","loading configuration file generation_config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32007,\n","    32001,\n","    32000\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","loading file tokenizer.model\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["\n","import torch \n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n","\n","torch.random.manual_seed(0) \n","model = AutoModelForCausalLM.from_pretrained( \n","    \"./PSTax3/\",  \n","    device_map=\"cuda\",  \n","    torch_dtype=\"auto\",  \n","    trust_remote_code=True,  \n",") \n","\n","model2 = AutoModelForCausalLM.from_pretrained( \n","    \"microsoft/Phi-3.5-mini-instruct\",  \n","    device_map=\"cuda\",  \n","    torch_dtype=\"auto\",  \n","    trust_remote_code=True,  \n",") \n","\n","tokenizer = AutoTokenizer.from_pretrained(\"./PSTax3/\") "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n","You are not running the flash-attention implementation, expect numerical differences.\n"]},{"name":"stdout","output_type":"stream","text":[" <BEGIN SUMMARY>\n","Alex and Taylor are discussing a recent event where a friend came out as gay. Taylor expresses discomfort with the trend of people openly declaring their sexual orientation and is critical of the concept of sex change surgeries. Alex defends the importance of respect and acceptance for individuals' identities. The conversation highlights differing views on the visibility and acceptance of LGBTQ+ identities and events.\n","<END SUMMARY>\n","\n","\n"," -------------------------------- \n","\n","\n"," In a conversation between Alex and Taylor, the topic of sexual orientation and gender identity arises, with Taylor expressing discomfort and skepticism towards the increasing visibility and acceptance of LGBTQ+ individuals. Taylor questions the trend of people openly declaring their sexual orientation, views gender transition surgeries as absurd, and perceives the push for LGBTQ+ acceptance as a burden on society. Alex, on the other hand, defends the right of individuals to live authentically and respects the struggles faced by the LGBTQ+ community. The dialogue reflects a clash of perspectives on the normalization of diverse sexual orientations and gender identities, with Taylor resisting what they see as societal changes that challenge traditional norms. The conversation underscores the ongoing societal debate on inclusivity, respect for individual identity, and the definition of normalcy.\n"]}],"source":["messages = [ \n","    {\"role\": \"user\", \"content\": prompt2}, \n","] \n","\n","pipe = pipeline( \n","    \"text-generation\", \n","    model=model, \n","    tokenizer=tokenizer, \n",") \n","\n","pipe2 = pipeline( \n","    \"text-generation\", \n","    model=model2, \n","    tokenizer=tokenizer, \n",") \n","\n","generation_args = { \n","    \"max_new_tokens\": 2048, \n","    \"return_full_text\": False, \n","    \"temperature\": 0.0, \n","    \"do_sample\": False, \n","} \n","\n","output = pipe(messages, **generation_args) \n","output2 = pipe2(messages, **generation_args) \n","\n","print(output[0]['generated_text'])\n","print(\"\\n\\n -------------------------------- \\n\\n\")\n","print(output2[0]['generated_text'])\n","\n","# Write the generated text to the file\n","with open('text.txt', 'a') as file:\n","    file.write(\"\\n\\n ----------------------------NEW FILE-------------------------------- \\n\\n\")\n","    file.write(str(output))\n","    file.write(\"\\n\\n -------------------------------- \\n\\n\")\n","    file.write(str(output2))\n"]},{"cell_type":"markdown","metadata":{"id":"jLh3aUPLav4q"},"source":["## Evaluate the performance"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"nWitaaKfbGK6"},"outputs":[],"source":["# 'load_metric' is a function from the 'datasets' library that loads a metric for evaluating the model.\n","# Metrics are used to measure the performance of the model on certain tasks.\n","from datasets import load_metric"]},{"cell_type":"markdown","metadata":{"id":"q9mVDf_WVSwE"},"source":["We'll employ the ROUGE metric to assess performance. While it may not be the optimal metric, it's straightforward and convenient to utilize."]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["b94caedc744941e38d2fe2e458d6728f","06062332a4c34d26ba5fa0a357b483b2","0b04aa6337c54790812e567f93b07f25","d99cda66ea8b4c9d8edd7678ec91608e","b66de8b9bea44665a353a2a1562f2b0b","dc3dfa5eedc44e27aaa3e29be3c77310","76b645e105224e5b95083c46c7325ecc","103257314ecf419b956b7645459329e6","e586ef1090d94c64837d249c395ed111","dee17f38a84b4c48b177d67143b4dd04","22b3ed00418d44338cdf745340fa18a3"]},"executionInfo":{"elapsed":1650,"status":"ok","timestamp":1715511022157,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"aIUQIUaFbGT9","outputId":"88bc7153-8e48-494e-c78e-069041d18daf"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1849094/1816433204.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  rouge_metric = load_metric(\"rouge\", trust_remote_code=True)\n"]}],"source":["# 'load_metric(\"rouge\", trust_remote_code=True)' loads the ROUGE metric from the 'datasets' library.\n","# ROUGE is a set of metrics used to evaluate automatic summarization and machine translation.\n","# 'trust_remote_code' is set to True, which means that the metric will trust and execute remote code.\n","# The loaded metric is stored in the 'rouge_metric' variable.\n","rouge_metric = load_metric(\"rouge\", trust_remote_code=True)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["taxo='''You are an Expert in the Informational Data Privacy Taxonomy provided to you now. Here is the Taxonomy-\n","\n","<BEGIN INFORMATIONAL DATA PRIVACY TAXONOMY>\n","\n","\t1. Generic\n","\t\t○ High Sensitivity: \n","\t\t\t○ Slangs\n","\t\t\t\t○ Profanity\n","\t\t\t\t○ Insults\n","\t\t\t\t○ Mockery\n","\t\t\t○ Authorization\n","\t\t\t\t○ Credentials\n","\t\t\t\t\t® UserID\n","\t\t\t\t\t® Password\n","\t\t\t○  Government IDs\n","\t\t\t\t○ License Numbers\n","\t\t\t\t○ National Identification Numbers (Aadhar, PAN, etc.)\n","\t\t\t\t○ Passport Numbers\n","\t\t\t\t○ Voter ID Numbers\n","\t\t\t\t○ Vehicle Registration Numbers\n","\t\t\t○ Age\n","\t\t\t○ Weight\n","\t\t\t○ Sizes\n","\t\t\t\t○ Clothes\n","\t\t\t\t○ Shoes\n","\t\t\t\t○ Shirts\n","\t\t\t\t○ Pants\n","\t\t○ Medium Sensitivity: \n","\t\t\t○ Username/ Social handle\n","\t\t\t○ Physical Features\n","\t\t\t\t○ Height\n","\t\t\t\t○ Build\n","\t\t\t\t○ Complexion\n","\t\t\t\t○ hair\n","\t\t\t\t○ Face\n","\t\t\t\t\t® Eyes\n","\t\t\t\t\t® Nose\n","\t\t\t\t\t\n","\t\t\t○ Demographics\n","\t\t\t\t○ Date of Birth\n","\t\t\t\t○ Place of Birth\n","\t\t\t\t○ Nationality\n","\t\t○ Low Sensitivity: \n","\t\t\t○ Demographics\n","\t\t\t\t○ Language\n","\t\t\t\t○ Race\n","\t\t\t\t○ Ethnicity\n","\t2. Family and Relationships\n","\t\t○ High Sensitivity: \n","\t\t\t§ Marital records\n","\t\t\t\t□ Relationship history\n","\t\t\t\t□ Partners\n","\t\t\t\t\t® Status\n","\t\t\t\t\t® Names\n","\t\t\t§ family history\n","\t\t\t\t□ Disputes\n","\t\t\t\t□ Strained relationships\n","\t\t\t§ Inheritance- Will / Beneficiaries\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ family members\n","\t\t\t\t□ Names\n","\t\t\t\t□ Number of members\n","\t\t○ Low Sensitivity: \n","\t\t\t§ General relationship status/ Marital status\n","\t\t\t§ Family members\n","\t\t\t\t□ Relations\n","\t\t\t\t\t® Father\n","\t\t\t\t\t® Mother\n","\t\t\t\t\t® Brother\n","\t\t\t\t\t® Sister\n","\t\t\t\t\t® Cousin\n","\t\t\t\t\t® Other relatives\n","\t3. Healthcare Settings\n","\t\t○ High Sensitivity: \n","\t\t\t§ Medications\n","\t\t\t§ Medical History\n","\t\t\t§ Genetic conditions\n","\t\t\t§ Diseases\n","\t\t\t§ Mental Health Issues\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ Health Insurance details\n","\t\t○ Low Sensitivity: \n","\t\t\t§ General health status\n","\t4. Employment\n","\t\t○ High Sensitivity: \n","\t\t\t§ Employment status\n","\t\t\t§ Work history\n","\t\t\t\t□ Job titles\n","\t\t\t\t□ Salaries\n","\t\t\t\t□ Company names\n","\t\t\t\t□ Manager's names\n","\t\t\t\t□ Coworker names\n","\t\t\t\t□ Work culture\n","\t\t\t\t□ Performance\n","\t\t○ Medium Sensitivity:\n","\t\t\t§ Volunteering\n","\t\t\t§ Employer information\n","\t\t\t\t□ Company name\n","\t\t\t\t□ Manager's names\n","\t\t\t§ Professional references\n","\t\t\t\t□ Reference Names\n","\t\t\t\t□ Job Title\n","\t\t\t\t□ Company name\n","\t\t○ Low Sensitivity: \n","\t\t\t§ General employment status\n","\t5. Finances\n","\t\t○ High Sensitivity: \n","\t\t\t§ Payment information\n","\t\t\t\t□ card numbers (+ CVV) (+ exp date)\n","\t\t\t\t□ account numbers\n","\t\t\t§ Insurance\n","\t\t\t\t□ Amount / Premium\n","\t\t\t\t□ Beneficiaries\n","\t\t\t§ Loan\n","\t\t\t\t□ Amount\n","\t\t\t\t□ Interest\n","\t\t\t§ Debt\n","\t\t\t\t□ Amount\n","\t\t\t\t□ Interest\n","\t\t\t§ investment information\n","\t\t\t\t□ Portfolio-related information\n","\t\t\t\t\t® Amounts\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ Insurance\n","\t\t\t\t□ Types\n","\t\t\t\t□ Amount / Premium\n","\t\t\t\t□ Beneficiaries\n","\t\t\t§ Loan\n","\t\t\t\t□ Scheme\n","\t\t\t\t□ Amount\n","\t\t\t\t□ Interest\n","\t\t\t§ investment information\n","\t\t\t\t□ Portfolio-related information\n","\t\t\t\t\t® Funds\n","\t\t\t\t\t® Bonds\n","\t\t\t\t\t® Stocks\n","\t\t\t\t\t® Bullions\n","\t\t○ Low Sensitivity: \n","\t\t\t§ General financial status\n","\t6. Social Media\n","\t\t○ High Sensitivity: \n","\t\t\t§ Private chats\n","\t\t\t§ personal posts\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ Friend lists\n","\t\t\t§ group memberships\n","\t\t○ Low Sensitivity: \n","\t\t\t§ Public posts\n","\t\t\t§ Accounts followed\n","\t7. Legal Proceedings\n","\t\t○ High Sensitivity: \n","\t\t\t§ court records\n","\t\t\t\t□ Criminal history\n","\t\t\t\t□ Arrest records\n","\t\t\t\t□ Settlement Amounts\n","\t\t\t§ Civil case details\n","\t\t\t\t□ Settlement Amounts\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ Civil case details\n","\t\t\t\t□ Lawsuits\n","\t\t\t\t□ Settlements\n","\t\t○ Low Sensitivity: \n","\t\t\t§ Legal representation contact information\n","\t\t\t\t□ Firms\n","\t\t\t\t□ Lawyers\n","\t\t\t\t□ Fees\n","\t8. Political Activities\n","\t\t○ High Sensitivity: \n","\t\t\t§ Membership in political organizations (Specific names)\n","\t\t\t\t□ NGOs\n","\t\t\t\t□ Committees\n","\t\t\t\t□ Volunteer Work\n","\t\t\t§ Political Involvement\n","\t\t\t\t□ Political Parties\n","\t\t\t\t□ Political opinions\n","\t\t\t\t□ activism details\n","\t\t\t\t\t®  Meeting Attendance \n","\t\t\t\t\t® Membership Fees\n","\t\t\t\t\t® Donations\n","\t\t\t\t□ Roles in propaganda/ agendas\n","\t\t\t§ Voting Details\n","\t\t\t\t□ Voting Records\n","\t\t\t\t□ Ballot Details\n","\t\t\t\t□ Voting Dates\n","\t\t\t\t□ Voting Locations\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ Membership in political organizations (Generic or vague description)\n","\t\t\t\t□ NGOs\n","\t\t\t\t□ Committees\n","\t\t\t\t□ Volunteer Work\n","\t\t○ Low Sensitivity: \n","\t\t\t§ Voting history\n","\t9. Religious Contexts\n","\t\t○ High Sensitivity: \n","\t\t\t§ Religions\n","\t\t\t□ Specific Religious beliefs\n","\t\t\t□ Religious Ceremonies\n","\t\t\t□ conversion history\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ Involvement in religious events\n","\t\t\t§ Common Ceremonies\n","\t\t\t□ Festival Participation\n","\t\t\t□ Volunteer Roles\n","\t\t○ Low Sensitivity: \n","\t\t\t§ General religious affiliation\n","\t10. Sexual Orientation and Gender Identity\n","\t\t○ High Sensitivity: \n","\t\t\t§ Sexual identity\n","\t\t\t\t□ Sexual Orientation\n","\t\t\t\t□ Coming Out Stories\n","\t\t\t\t□ Partner Preferences\n","\t\t\t§ gender identity\n","\t\t\t\t□ Gender Identity\n","\t\t\t\t□ Pronouns\n","\t\t\t\t□ Transition History\n","\t\t\t\t□ Clothing Preferences\n","\t\t○ Medium Sensitivity:\n","\t\t\t§  Participation in LGBTQ+ events\n","\t\t\t\t□ Pride Events, LGBTQ+ Meetups, Support Groups\n","\t\t\t\t□ Roles\n","\t\t\t\t\t® Organizer\n","\t\t\t\t\t® Volunteer \n","\t\t\t\t\t® Attendee\n","\t\t\t\t\t® Speaker Roles\n","\t\t○ Low Sensitivity: \n","\t\t\t§ General demographic information\n","\t11. Travel and Location\n","\t\t○ High Sensitivity: \n","\t\t\t§ Travel history\n","\t\t\t\t□ Detailed Itineraries\n","\t\t\t\t□ Addresses of Stay\n","\t\t\t§ Bookings (Hotels/Restaurants)\n","\t\t\t\t□ Names\n","\t\t\t\t□ Booking Dates/ Timings\n","\t\t\t\t□ Room Numbers\n","\t\t\t\t□ Room sharers\n","\t\t\t§ GPS data\n","\t\t\t\t□ Current Location\n","\t\t\t\t□ Geo-tagged Photos\n","\t\t\t§ Modes of Transportation\n","\t\t\t\t□ Vehicle Numbers\n","\t\t\t\t□ Vehicle Models\n","\t\t\t\t□ Vehicle Plans\n","\t\t\t\t□ Vehicle Rentals\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ Modes of Transportation\n","\t\t\t§ Recent Travels(Generic)\n","\t\t\t§ Overview of Places of Stay\n","\t\t\t\t□ Rent\n","\t\t\t\t□ Hotel\n","\t\t\t\t□ Owned Places\n","\t\t○ Low Sensitivity: \n","\t\t\t§ General location information\n","\t12. Education\n","\t\t○ High Sensitivity: \n","\t\t\t§ Academic records\n","\t\t\t\t□ Courses Done/Failed\n","\t\t\t\t□ Assignment Completed /Failed\n","\t\t\t\t□ Exam Scores\n","\t\t\t\t□ GPA\n","\t\t\t§ Disciplinary Records\n","\t\t\t\t□ Violations\n","\t\t\t\t□ Penalties\n","\t\t\t§ Degree details\n","\t\t\t\t□ Degrees Earned\n","\t\t\t\t□ Majors\n","\t\t\t\t□ Minors\n","\t\t\t§ School attended\n","\t\t\t\t□ Name\n","\t\t\t\t□ Fees\n","\t\t\t§ College attended\n","\t\t\t\t□ Name\n","\t\t\t\t□ Fees\n","\t\t○ Medium Sensitivity: \n","\t\t\t§ School attended\n","\t\t\t\t□ Batch/ Year\n","\t\t\t§ College attended\n","\t\t\t\t□ Batch/ Year\n","\t\t○ Low Sensitivity: \n","\t\t\t§ School attended\n","\t\t\t\t□ Country\n","\t\t\t§ College attended\n","\t\t\t\t□ Country\n","\t\t\t§ Future Plans\n","\n","<END INFORMATIONAL DATA PRIVACY TAXONOMY>\n","\n","Use this information to do as directed and asked.'''"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file ./PSTax3/config.json\n","loading configuration file ./PSTax3/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"./PSTax3/\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32011\n","}\n","\n","loading weights file ./PSTax3/model.safetensors.index.json\n","Will use torch_dtype=torch.bfloat16 as defined in model's config object\n","Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1990d328b5994e8386e3f96a046f1de8","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","All the weights of Phi3ForCausalLM were initialized from the model checkpoint at ./PSTax3/.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","loading configuration file ./PSTax3/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32007,\n","    32001,\n","    32000\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","loading configuration file config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","loading weights file model.safetensors from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/model.safetensors.index.json\n","Will use torch_dtype=torch.bfloat16 as defined in model's config object\n","Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1475edd4dc81481db3735388d9959d97","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3.5-mini-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","loading configuration file generation_config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32007,\n","    32001,\n","    32000\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","loading file tokenizer.model\n","loading file tokenizer.json\n","loading file added_tokens.json\n","loading file special_tokens_map.json\n","loading file tokenizer_config.json\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","loading file tokenizer.model from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/tokenizer.model\n","loading file tokenizer.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/tokenizer.json\n","loading file added_tokens.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/added_tokens.json\n","loading file special_tokens_map.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/special_tokens_map.json\n","loading file tokenizer_config.json from cache at /home/t-ppurkayast/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/ccf028fc8e1b3ab750a7c55b22792f57ba69f216/tokenizer_config.json\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["import pandas as pd\n","from datasets import load_metric,Dataset, concatenate_datasets\n","import random\n","import torch \n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n","\n","model = AutoModelForCausalLM.from_pretrained( \n","    \"./PSTax3/\",  \n","    device_map=\"cuda\",  \n","    torch_dtype=\"auto\",  \n","    trust_remote_code=True,  \n",") \n","\n","model2 = AutoModelForCausalLM.from_pretrained( \n","    \"microsoft/Phi-3.5-mini-instruct\",  \n","    device_map=\"cuda\",  \n","    torch_dtype=\"auto\",  \n","    trust_remote_code=True,  \n",") \n","\n","tokenizer = AutoTokenizer.from_pretrained(\"./PSTax3/\") \n","tokenizer2 = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\") \n","\n","pipe = pipeline( \n","    \"text-generation\", \n","    model=model, \n","    tokenizer=tokenizer, \n",") \n","\n","pipe2 = pipeline( \n","    \"text-generation\", \n","    model=model2, \n","    tokenizer=tokenizer2, \n",") \n","\n","generation_args = { \n","    \"max_new_tokens\": 2048, \n","    \"return_full_text\": False, \n","    \"temperature\": 0.0, \n","    \"do_sample\": False, \n","} "]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nAlicia: Hey Mark, ...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nAlicia and Mark discuss...\n","Violations                <BEGIN VIOLATIONS>\\n\\nNone.\\n\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\n\\nGOOD\\n\\n<END LABEL>\n","__index_level_0__                                                  1083.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\nAlicia and Mark discuss a fr...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo students, Alicia an...\n","base_model_rouge1                                                0.463918\n","Finetuned_rouge1                                                     0.52\n","4o_rouge1                                                        0.483333\n","base_model_rouge2                                                  0.1875\n","Finetuned_rouge2                                                  0.22973\n","4o_rouge2                                                        0.168067\n","base_model_rougeL                                                0.309278\n","Finetuned_rougeL                                                 0.386667\n","4o_rougeL                                                        0.333333\n","base_model_rougeLsum                                             0.309278\n","Finetuned_rougeLsum                                              0.386667\n","4o_rougeLsum                                                     0.333333\n","Name: 0, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nAlice: Hey Mark, h...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Mark discuss ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   704.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Mark discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Mark discuss ...\n","base_model_rouge1                                                0.369748\n","Finetuned_rouge1                                                 0.465116\n","4o_rouge1                                                        0.453202\n","base_model_rouge2                                                0.118644\n","Finetuned_rouge2                                                 0.188235\n","4o_rouge2                                                        0.099502\n","base_model_rougeL                                                0.235294\n","Finetuned_rougeL                                                 0.348837\n","4o_rougeL                                                        0.285714\n","base_model_rougeLsum                                             0.235294\n","Finetuned_rougeLsum                                              0.348837\n","4o_rougeLsum                                                     0.285714\n","Name: 1, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nEmily: Hey, Robert...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nEmily and Robert remini...\n","Violations              <BEGIN VIOLATIONS>\\n1. education.high.academic...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   740.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\nEmily and Robert reminisce a...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Robert remini...\n","base_model_rouge1                                                0.418118\n","Finetuned_rouge1                                                 0.359712\n","4o_rouge1                                                        0.484211\n","base_model_rouge2                                                0.147368\n","Finetuned_rouge2                                                 0.131387\n","4o_rouge2                                                        0.254417\n","base_model_rougeL                                                0.271777\n","Finetuned_rougeL                                                 0.273381\n","4o_rougeL                                                        0.350877\n","base_model_rougeLsum                                             0.285714\n","Finetuned_rougeLsum                                              0.273381\n","4o_rougeLsum                                                     0.350877\n","Name: 2, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJulia: Hey Mark, h...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nJulia and Mark discussed St...\n","Violations              <BEGIN VIOLATIONS>\\n1. education.high.academic...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   696.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJulia and Mark discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJulia and Mark discusse...\n","base_model_rouge1                                                0.434043\n","Finetuned_rouge1                                                 0.459893\n","4o_rouge1                                                        0.468619\n","base_model_rouge2                                                0.137339\n","Finetuned_rouge2                                                 0.162162\n","4o_rouge2                                                        0.135021\n","base_model_rougeL                                                0.289362\n","Finetuned_rougeL                                                 0.331551\n","4o_rougeL                                                        0.334728\n","base_model_rougeLsum                                             0.289362\n","Finetuned_rougeLsum                                              0.331551\n","4o_rougeLsum                                                     0.334728\n","Name: 3, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nArjun: Hey, Emily!...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nArjun and Emily discuss the...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. education.high.academ...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   695.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nArjun and Emily discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nArjun and Emily catch u...\n","base_model_rouge1                                                0.373626\n","Finetuned_rouge1                                                 0.282486\n","4o_rouge1                                                        0.504673\n","base_model_rouge2                                                0.116022\n","Finetuned_rouge2                                                 0.057143\n","4o_rouge2                                                        0.132075\n","base_model_rougeL                                                0.241758\n","Finetuned_rougeL                                                 0.225989\n","4o_rougeL                                                        0.271028\n","base_model_rougeLsum                                             0.247253\n","Finetuned_rougeLsum                                              0.225989\n","4o_rougeLsum                                                     0.271028\n","Name: 4, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nTim: Hey Alice, di...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion be...\n","summary                 <BEGIN SUMMARY>\\n\\nAlice and Tim discussed the...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. education.high.academ...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   690.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nTim and Alice discuss ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTim and Alice discussed...\n","base_model_rouge1                                                0.382022\n","Finetuned_rouge1                                                 0.307692\n","4o_rouge1                                                             0.4\n","base_model_rouge2                                                 0.10566\n","Finetuned_rouge2                                                 0.072539\n","4o_rouge2                                                        0.122066\n","base_model_rougeL                                                0.209738\n","Finetuned_rougeL                                                 0.205128\n","4o_rougeL                                                        0.260465\n","base_model_rougeLsum                                             0.209738\n","Finetuned_rougeLsum                                              0.205128\n","4o_rougeLsum                                                     0.260465\n","Name: 5, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nAshley: Hey Tom, d...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nAshley and Tom discuss ...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   673.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAshley and Tom discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAshley and Tom discusse...\n","base_model_rouge1                                                0.323741\n","Finetuned_rouge1                                                 0.506024\n","4o_rouge1                                                        0.417062\n","base_model_rouge2                                                0.115942\n","Finetuned_rouge2                                                 0.195122\n","4o_rouge2                                                         0.15311\n","base_model_rougeL                                                0.208633\n","Finetuned_rougeL                                                 0.301205\n","4o_rougeL                                                        0.265403\n","base_model_rougeLsum                                             0.223022\n","Finetuned_rougeLsum                                              0.301205\n","4o_rougeLsum                                                     0.265403\n","Name: 6, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nEmma: Hey, Ben! Lo...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Catching up o...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nEmma and Ben discuss va...\n","Violations              <BEGIN VIOLATIONS>\\n1. education.high.academic...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   842.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nEmma and Ben discuss their a...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Ben reconnect ...\n","base_model_rouge1                                                0.362416\n","Finetuned_rouge1                                                 0.451613\n","4o_rouge1                                                        0.471698\n","base_model_rouge2                                                0.094595\n","Finetuned_rouge2                                                 0.183007\n","4o_rouge2                                                        0.171429\n","base_model_rougeL                                                0.208054\n","Finetuned_rougeL                                                 0.296774\n","4o_rougeL                                                        0.311321\n","base_model_rougeLsum                                             0.234899\n","Finetuned_rougeLsum                                              0.296774\n","4o_rougeLsum                                                     0.311321\n","Name: 7, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmily: Hey Mark, r...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion be...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Mark reminisc...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   661.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Mark reminis...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Mark reminisc...\n","base_model_rouge1                                                     0.4\n","Finetuned_rouge1                                                 0.503067\n","4o_rouge1                                                        0.465517\n","base_model_rouge2                                                0.181208\n","Finetuned_rouge2                                                 0.173913\n","4o_rouge2                                                        0.156522\n","base_model_rougeL                                                0.313333\n","Finetuned_rougeL                                                 0.343558\n","4o_rougeL                                                        0.284483\n","base_model_rougeLsum                                             0.313333\n","Finetuned_rougeLsum                                              0.343558\n","4o_rougeLsum                                                     0.284483\n","Name: 8, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmily: Hey, Mark! ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion be...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Mark are disc...\n","Violations              <BEGIN VIOLATIONS>\\n1. education.high.academic...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   651.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Mark discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Mark discusse...\n","base_model_rouge1                                                 0.39403\n","Finetuned_rouge1                                                 0.209424\n","4o_rouge1                                                        0.466926\n","base_model_rouge2                                                0.174174\n","Finetuned_rouge2                                                  0.05291\n","4o_rouge2                                                        0.196078\n","base_model_rougeL                                                0.280597\n","Finetuned_rougeL                                                 0.136126\n","4o_rougeL                                                        0.350195\n","base_model_rougeLsum                                             0.304478\n","Finetuned_rougeLsum                                              0.136126\n","4o_rougeLsum                                                     0.350195\n","Name: 9, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nAmelia: Hey, did y...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nAmelia and Brian discuss va...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   845.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nAmelia and Brian discussed a...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAmelia and Brian discus...\n","base_model_rouge1                                                0.303406\n","Finetuned_rouge1                                                 0.347305\n","4o_rouge1                                                        0.373913\n","base_model_rouge2                                                0.080997\n","Finetuned_rouge2                                                 0.121212\n","4o_rouge2                                                        0.105263\n","base_model_rougeL                                                 0.19195\n","Finetuned_rougeL                                                 0.239521\n","4o_rougeL                                                        0.252174\n","base_model_rougeLsum                                              0.22291\n","Finetuned_rougeLsum                                              0.239521\n","4o_rougeLsum                                                     0.252174\n","Name: 10, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nLinda: Hey Alex, d...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nAlex and Linda discuss ...\n","Violations              <BEGIN VIOLATIONS>\\r\\n\\t1. employment.high.emp...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   183.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nLinda and Alex discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLinda and Alex discuss ...\n","base_model_rouge1                                                0.505556\n","Finetuned_rouge1                                                 0.324324\n","4o_rouge1                                                        0.609375\n","base_model_rouge2                                                0.240223\n","Finetuned_rouge2                                                 0.076503\n","4o_rouge2                                                        0.283465\n","base_model_rougeL                                                0.338889\n","Finetuned_rougeL                                                 0.194595\n","4o_rougeL                                                        0.390625\n","base_model_rougeLsum                                             0.388889\n","Finetuned_rougeLsum                                              0.194595\n","4o_rougeLsum                                                     0.390625\n","Name: 11, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nJessica: Hey, Mark...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Catching up b...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nJessica and Mark catch ...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. employment.high.emplo...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   743.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nMark recently got promoted t...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJessica and Mark catch ...\n","base_model_rouge1                                                0.344473\n","Finetuned_rouge1                                                 0.438095\n","4o_rouge1                                                        0.536797\n","base_model_rouge2                                                0.129199\n","Finetuned_rouge2                                                 0.173077\n","4o_rouge2                                                         0.31441\n","base_model_rougeL                                                 0.18509\n","Finetuned_rougeL                                                 0.295238\n","4o_rougeL                                                        0.424242\n","base_model_rougeLsum                                             0.246787\n","Finetuned_rougeLsum                                              0.295238\n","4o_rougeLsum                                                     0.424242\n","Name: 12, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nNina: Hey Jake, ha...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nNina and Jake discuss r...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   175.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nNina and Jake discuss ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nNina and Jake discuss r...\n","base_model_rouge1                                                0.265306\n","Finetuned_rouge1                                                 0.551181\n","4o_rouge1                                                        0.244726\n","base_model_rouge2                                                0.082192\n","Finetuned_rouge2                                                     0.24\n","4o_rouge2                                                        0.102128\n","base_model_rougeL                                                0.176871\n","Finetuned_rougeL                                                 0.362205\n","4o_rougeL                                                        0.185654\n","base_model_rougeLsum                                             0.176871\n","Finetuned_rougeLsum                                              0.362205\n","4o_rougeLsum                                                     0.185654\n","Name: 13, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nRachel: Hey John, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion be...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nRachel and John discuss...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   174.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nRachel and John discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nRachel and John discuss...\n","base_model_rouge1                                                0.254237\n","Finetuned_rouge1                                                 0.410256\n","4o_rouge1                                                        0.411483\n","base_model_rouge2                                                0.025641\n","Finetuned_rouge2                                                  0.12987\n","4o_rouge2                                                        0.115942\n","base_model_rougeL                                                0.118644\n","Finetuned_rougeL                                                 0.282051\n","4o_rougeL                                                        0.258373\n","base_model_rougeLsum                                             0.118644\n","Finetuned_rougeLsum                                              0.282051\n","4o_rougeLsum                                                     0.258373\n","Name: 14, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmma: Hey, Tom, lo...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Catch-up conv...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nTom, who recently got p...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. employment.high.emplo...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   169.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Tom catch up ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Tom, who haven...\n","base_model_rouge1                                                0.408946\n","Finetuned_rouge1                                                 0.441989\n","4o_rouge1                                                        0.516129\n","base_model_rouge2                                                0.180064\n","Finetuned_rouge2                                                 0.134078\n","4o_rouge2                                                        0.223256\n","base_model_rougeL                                                 0.27476\n","Finetuned_rougeL                                                 0.265193\n","4o_rougeL                                                        0.304147\n","base_model_rougeLsum                                             0.319489\n","Finetuned_rougeLsum                                              0.265193\n","4o_rougeLsum                                                     0.304147\n","Name: 15, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nAmelia: Hey Jake, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion be...\n","summary                 <BEGIN SUMMARY>\\n\\nJake recently got promoted ...\n","Violations              <BEGIN VIOLATIONS>\\n1. employment.high.employm...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   152.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Amelia and Jake discus...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAmelia and Jake discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAmelia and Jake discuss...\n","base_model_rouge1                                                0.446735\n","Finetuned_rouge1                                                 0.401747\n","4o_rouge1                                                        0.474576\n","base_model_rouge2                                                0.152249\n","Finetuned_rouge2                                                 0.132159\n","4o_rouge2                                                        0.179487\n","base_model_rougeL                                                0.302405\n","Finetuned_rougeL                                                 0.296943\n","4o_rougeL                                                        0.313559\n","base_model_rougeLsum                                             0.350515\n","Finetuned_rougeLsum                                              0.296943\n","4o_rougeLsum                                                     0.313559\n","Name: 16, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nLinda: Hey Mark, d...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Office Conver...\n","summary                 <BEGIN SUMMARY>\\n\\nLinda and Mark discuss care...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   753.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nLinda and Mark discuss the...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLinda and Mark discuss ...\n","base_model_rouge1                                                0.296578\n","Finetuned_rouge1                                                 0.471429\n","4o_rouge1                                                        0.374429\n","base_model_rouge2                                                0.114943\n","Finetuned_rouge2                                                 0.188406\n","4o_rouge2                                                        0.101382\n","base_model_rougeL                                                0.197719\n","Finetuned_rougeL                                                 0.314286\n","4o_rougeL                                                        0.255708\n","base_model_rougeLsum                                             0.228137\n","Finetuned_rougeLsum                                              0.314286\n","4o_rougeLsum                                                     0.255708\n","Name: 17, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nNaomi: Hey Lucas, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nLucas, recently promote...\n","Violations              <BEGIN VIOLATIONS>\\n1. employment.high.employm...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   140.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nNaomi and Lucas discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nNaomi and Lucas catch u...\n","base_model_rouge1                                                0.538462\n","Finetuned_rouge1                                                 0.335025\n","4o_rouge1                                                        0.529968\n","base_model_rouge2                                                 0.23871\n","Finetuned_rouge2                                                 0.082051\n","4o_rouge2                                                        0.222222\n","base_model_rougeL                                                0.358974\n","Finetuned_rougeL                                                 0.172589\n","4o_rougeL                                                        0.365931\n","base_model_rougeLsum                                             0.378205\n","Finetuned_rougeLsum                                              0.172589\n","4o_rougeLsum                                                     0.359621\n","Name: 18, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmma: Hey Carlos, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Office Conver...\n","summary                 <BEGIN SUMMARY>\\n\\nCarlos and Emma discuss sev...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. employment.high.emplo...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   130.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Carlos discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Carlos discuss...\n","base_model_rouge1                                                 0.54485\n","Finetuned_rouge1                                                 0.344828\n","4o_rouge1                                                        0.528169\n","base_model_rouge2                                                 0.26087\n","Finetuned_rouge2                                                 0.059701\n","4o_rouge2                                                        0.234043\n","base_model_rougeL                                                0.392027\n","Finetuned_rougeL                                                 0.206897\n","4o_rougeL                                                        0.387324\n","base_model_rougeLsum                                             0.392027\n","Finetuned_rougeLsum                                              0.206897\n","4o_rougeLsum                                                     0.387324\n","Name: 19, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\n**Emily:** You kno...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Casual person...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nEmily and Brian discuss...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. family.high.family_hi...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   863.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent family con...\n","summary_finetuned        <BEGIN SUMMARY>\\nEmily and Brian discussed va...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Brian discuss...\n","base_model_rouge1                                                0.513011\n","Finetuned_rouge1                                                 0.369427\n","4o_rouge1                                                        0.588235\n","base_model_rouge2                                                  0.2397\n","Finetuned_rouge2                                                 0.090323\n","4o_rouge2                                                        0.237443\n","base_model_rougeL                                                0.379182\n","Finetuned_rougeL                                                 0.292994\n","4o_rougeL                                                         0.40724\n","base_model_rougeLsum                                             0.416357\n","Finetuned_rougeLsum                                              0.292994\n","4o_rougeLsum                                                      0.40724\n","Name: 20, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSarah: You know, I...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Paul discuss ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    53.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Paul discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Paul catch up...\n","base_model_rouge1                                                0.323625\n","Finetuned_rouge1                                                 0.597222\n","4o_rouge1                                                        0.492754\n","base_model_rouge2                                                0.091205\n","Finetuned_rouge2                                                 0.253521\n","4o_rouge2                                                         0.17561\n","base_model_rougeL                                                 0.20712\n","Finetuned_rougeL                                                 0.402778\n","4o_rougeL                                                        0.338164\n","base_model_rougeLsum                                             0.220065\n","Finetuned_rougeLsum                                              0.402778\n","4o_rougeLsum                                                     0.338164\n","Name: 21, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nAna: Hey Tim, did ...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Informal conv...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nAna and Tim discuss the...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. family.high.family_hi...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   757.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\nAna and Tim discuss a friend...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAna and Tim discuss var...\n","base_model_rouge1                                                0.474026\n","Finetuned_rouge1                                                 0.393782\n","4o_rouge1                                                        0.538776\n","base_model_rouge2                                                0.183007\n","Finetuned_rouge2                                                 0.136126\n","4o_rouge2                                                         0.18107\n","base_model_rougeL                                                0.285714\n","Finetuned_rougeL                                                 0.238342\n","4o_rougeL                                                        0.326531\n","base_model_rougeLsum                                             0.344156\n","Finetuned_rougeLsum                                              0.238342\n","4o_rougeLsum                                                     0.326531\n","Name: 22, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Laura:** So, how...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nKevin had a tense weekend d...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. Family and Relationsh...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                    45.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Kevin's family is embr...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\nKevin is dealing with a fa...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLaura and Kevin discuss...\n","base_model_rouge1                                                0.518272\n","Finetuned_rouge1                                                 0.555024\n","4o_rouge1                                                        0.533865\n","base_model_rouge2                                                 0.26087\n","Finetuned_rouge2                                                  0.21256\n","4o_rouge2                                                        0.248996\n","base_model_rougeL                                                0.378738\n","Finetuned_rougeL                                                 0.373206\n","4o_rougeL                                                        0.398406\n","base_model_rougeLsum                                             0.378738\n","Finetuned_rougeLsum                                              0.373206\n","4o_rougeLsum                                                     0.398406\n","Name: 23, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmily: Hey Jasmine...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nEmily and Jasmine discuss t...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. family.high.family_hi...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                    44.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Sarah's family is curr...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Jasmine disc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Jasmine discu...\n","base_model_rouge1                                                0.373134\n","Finetuned_rouge1                                                  0.43871\n","4o_rouge1                                                        0.578431\n","base_model_rouge2                                                0.172932\n","Finetuned_rouge2                                                  0.20915\n","4o_rouge2                                                         0.29703\n","base_model_rougeL                                                0.313433\n","Finetuned_rougeL                                                 0.348387\n","4o_rougeL                                                        0.421569\n","base_model_rougeLsum                                             0.328358\n","Finetuned_rougeLsum                                              0.348387\n","4o_rougeLsum                                                     0.421569\n","Name: 24, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Sophia:** Hey, L...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Catch-up conv...\n","summary                 <BEGIN SUMMARY>\\n\\nSophia and Liam catch up on...\n","Violations              <BEGIN VIOLATIONS>\\n1. family.high.family_memb...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                    39.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\nLiam and Sophia catch up o...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLiam and Sophia catch u...\n","base_model_rouge1                                                0.353659\n","Finetuned_rouge1                                                 0.540541\n","4o_rouge1                                                        0.454106\n","base_model_rouge2                                                 0.09816\n","Finetuned_rouge2                                                 0.295082\n","4o_rouge2                                                        0.136585\n","base_model_rougeL                                                0.237805\n","Finetuned_rougeL                                                 0.454054\n","4o_rougeL                                                        0.251208\n","base_model_rougeLsum                                             0.237805\n","Finetuned_rougeLsum                                              0.454054\n","4o_rougeLsum                                                     0.251208\n","Name: 25, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Sophia:** Hey Ja...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nSophia and Jake catch up on...\n","Violations              <BEGIN VIOLATIONS>\\n1. Family and Relationship...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                    22.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\nJake and Sophia catch up o...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSophia and Jake reconne...\n","base_model_rouge1                                                0.446352\n","Finetuned_rouge1                                                 0.409938\n","4o_rouge1                                                        0.353535\n","base_model_rouge2                                                0.121212\n","Finetuned_rouge2                                                 0.125786\n","4o_rouge2                                                        0.132653\n","base_model_rougeL                                                0.266094\n","Finetuned_rougeL                                                 0.298137\n","4o_rougeL                                                        0.252525\n","base_model_rougeLsum                                             0.266094\n","Finetuned_rougeLsum                                              0.298137\n","4o_rougeLsum                                                     0.252525\n","Name: 26, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\n**Sara:** Hey John...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nJohn and Sara discuss a...\n","Violations              <BEGIN VIOLATIONS>\\n\\n\\n\\n1. family.high.famil...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   828.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n The conversation betwe...\n","summary_finetuned        <BEGIN SUMMARY>\\nSara and John discuss the on...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSara and John discuss a...\n","base_model_rouge1                                                0.301282\n","Finetuned_rouge1                                                   0.4875\n","4o_rouge1                                                        0.430622\n","base_model_rouge2                                                0.045161\n","Finetuned_rouge2                                                 0.126582\n","4o_rouge2                                                        0.096618\n","base_model_rougeL                                                0.185897\n","Finetuned_rougeL                                                   0.2875\n","4o_rougeL                                                        0.248804\n","base_model_rougeLsum                                             0.205128\n","Finetuned_rougeLsum                                                0.2875\n","4o_rougeLsum                                                     0.248804\n","Name: 27, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Rachel:** Hey Da...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nDave and Rachel discuss...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                    10.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nDave and Rachel discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nRachel and Dave discuss...\n","base_model_rouge1                                                0.317152\n","Finetuned_rouge1                                                 0.535948\n","4o_rouge1                                                        0.321101\n","base_model_rouge2                                                0.058632\n","Finetuned_rouge2                                                 0.198675\n","4o_rouge2                                                        0.055556\n","base_model_rougeL                                                 0.15534\n","Finetuned_rougeL                                                 0.339869\n","4o_rougeL                                                        0.220183\n","base_model_rougeLsum                                             0.200647\n","Finetuned_rougeLsum                                              0.339869\n","4o_rougeLsum                                                     0.220183\n","Name: 28, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Laura:** Hey Pet...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nPeter and Laura discuss var...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. family.high.family_hi...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                     0.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nPeter and Laura catch ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLaura reconnected with ...\n","base_model_rouge1                                                0.481928\n","Finetuned_rouge1                                                 0.442308\n","4o_rouge1                                                        0.488889\n","base_model_rouge2                                                0.145749\n","Finetuned_rouge2                                                 0.106796\n","4o_rouge2                                                        0.152466\n","base_model_rougeL                                                0.273092\n","Finetuned_rougeL                                                 0.278846\n","4o_rougeL                                                        0.311111\n","base_model_rougeLsum                                             0.273092\n","Finetuned_rougeLsum                                              0.278846\n","4o_rougeLsum                                                     0.311111\n","Name: 29, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nJohn: Jess, have y...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nJohn and Jess discussed...\n","Violations              <BEGIN VIOLATIONS>\\n1. finances.high.investmen...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   890.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nJohn and Jess discussed thei...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Jess discuss t...\n","base_model_rouge1                                                0.338658\n","Finetuned_rouge1                                                     0.31\n","4o_rouge1                                                        0.374558\n","base_model_rouge2                                                0.115756\n","Finetuned_rouge2                                                 0.161616\n","4o_rouge2                                                        0.099644\n","base_model_rougeL                                                0.236422\n","Finetuned_rougeL                                                     0.26\n","4o_rougeL                                                        0.261484\n","base_model_rougeLsum                                             0.268371\n","Finetuned_rougeLsum                                                  0.26\n","4o_rougeLsum                                                     0.261484\n","Name: 30, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJames: **Hey Sarah...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJames and Sarah discuss...\n","Violations              <BEGIN VIOLATIONS>\\r\\n**None.**\\r\\n<END VIOLAT...\n","Quality                          <BEGIN LABEL>\\r\\n**GOOD**\\r\\n<END LABEL>\n","__index_level_0__                                                   248.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n James and Sarah discus...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJames and Sarah discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJames and Sarah discuss...\n","base_model_rouge1                                                0.431373\n","Finetuned_rouge1                                                 0.506329\n","4o_rouge1                                                        0.453202\n","base_model_rouge2                                                0.150198\n","Finetuned_rouge2                                                  0.24359\n","4o_rouge2                                                        0.159204\n","base_model_rougeL                                                 0.25098\n","Finetuned_rougeL                                                 0.392405\n","4o_rougeL                                                        0.325123\n","base_model_rougeLsum                                             0.321569\n","Finetuned_rougeLsum                                              0.392405\n","4o_rougeLsum                                                     0.325123\n","Name: 31, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nLaura: \"Hey Dan, I...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nLaura and Dan discussed...\n","Violations              <BEGIN VIOLATIONS>\\n1. Finances.high.investmen...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   770.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent discussion...\n","summary_finetuned        <BEGIN SUMMARY>\\nLaura and Dan discussed thei...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo friends, Laura and ...\n","base_model_rouge1                                                0.411392\n","Finetuned_rouge1                                                 0.564103\n","4o_rouge1                                                        0.519149\n","base_model_rouge2                                                0.178344\n","Finetuned_rouge2                                                 0.298701\n","4o_rouge2                                                        0.214592\n","base_model_rougeL                                                 0.28481\n","Finetuned_rougeL                                                 0.423077\n","4o_rougeL                                                        0.348936\n","base_model_rougeLsum                                             0.316456\n","Finetuned_rougeLsum                                              0.423077\n","4o_rougeLsum                                                     0.348936\n","Name: 32, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJohn: Hey Karen, d...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion be...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nKaren and John discusse...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. finances.high.loan.am...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   240.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent discussion...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Karen discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Karen discusse...\n","base_model_rouge1                                                0.378947\n","Finetuned_rouge1                                                 0.502857\n","4o_rouge1                                                        0.405063\n","base_model_rouge2                                                0.084806\n","Finetuned_rouge2                                                 0.138728\n","4o_rouge2                                                         0.13617\n","base_model_rougeL                                                0.217544\n","Finetuned_rougeL                                                 0.331429\n","4o_rougeL                                                        0.261603\n","base_model_rougeLsum                                             0.245614\n","Finetuned_rougeLsum                                              0.331429\n","4o_rougeLsum                                                     0.261603\n","Name: 33, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSarah: \"Hey Mark, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Mark discusse...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   239.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Mark discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Mark discuss ...\n","base_model_rouge1                                                0.337079\n","Finetuned_rouge1                                                 0.539877\n","4o_rouge1                                                        0.446281\n","base_model_rouge2                                                0.118644\n","Finetuned_rouge2                                                 0.273292\n","4o_rouge2                                                        0.166667\n","base_model_rougeL                                                0.241573\n","Finetuned_rougeL                                                 0.429448\n","4o_rougeL                                                        0.330579\n","base_model_rougeLsum                                             0.241573\n","Finetuned_rougeLsum                                              0.429448\n","4o_rougeLsum                                                     0.330579\n","Name: 34, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nLiam: **Hey, Olivi...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nLiam and Olivia discuss...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   234.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Olivia and Liam discus...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nLiam and Olivia discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLiam and Olivia engage ...\n","base_model_rouge1                                                0.466667\n","Finetuned_rouge1                                                 0.540541\n","4o_rouge1                                                        0.483051\n","base_model_rouge2                                                 0.24581\n","Finetuned_rouge2                                                 0.284153\n","4o_rouge2                                                         0.17094\n","base_model_rougeL                                                0.283333\n","Finetuned_rougeL                                                 0.410811\n","4o_rougeL                                                        0.279661\n","base_model_rougeLsum                                             0.322222\n","Finetuned_rougeLsum                                              0.410811\n","4o_rougeLsum                                                     0.279661\n","Name: 35, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nAnna: I'm really s...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nAnna and Ben discussed ...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   217.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAnna and Ben are discu...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAnna and Ben shared the...\n","base_model_rouge1                                                0.425532\n","Finetuned_rouge1                                                 0.539474\n","4o_rouge1                                                        0.472574\n","base_model_rouge2                                                0.103004\n","Finetuned_rouge2                                                 0.173333\n","4o_rouge2                                                        0.153191\n","base_model_rougeL                                                0.229787\n","Finetuned_rougeL                                                 0.342105\n","4o_rougeL                                                        0.278481\n","base_model_rougeLsum                                             0.229787\n","Finetuned_rougeLsum                                              0.342105\n","4o_rougeLsum                                                     0.278481\n","Name: 36, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nJohn: \"Hey Sarah, ...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nJohn informed Sarah abo...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   873.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nJohn and Sarah discuss a fri...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Sarah discuss ...\n","base_model_rouge1                                                0.384615\n","Finetuned_rouge1                                                 0.551724\n","4o_rouge1                                                        0.494505\n","base_model_rouge2                                                0.161972\n","Finetuned_rouge2                                                 0.293706\n","4o_rouge2                                                        0.155556\n","base_model_rougeL                                                 0.27972\n","Finetuned_rougeL                                                 0.372414\n","4o_rougeL                                                        0.263736\n","base_model_rougeLsum                                              0.27972\n","Finetuned_rougeLsum                                              0.372414\n","4o_rougeLsum                                                     0.263736\n","Name: 37, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSarah: You know, A...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Allen discuss...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   205.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Allen discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Allen discuss...\n","base_model_rouge1                                                0.443686\n","Finetuned_rouge1                                                 0.497238\n","4o_rouge1                                                        0.421053\n","base_model_rouge2                                                 0.14433\n","Finetuned_rouge2                                                 0.178771\n","4o_rouge2                                                        0.151515\n","base_model_rougeL                                                 0.25256\n","Finetuned_rougeL                                                 0.298343\n","4o_rougeL                                                        0.270677\n","base_model_rougeLsum                                             0.266212\n","Finetuned_rougeLsum                                              0.298343\n","4o_rougeLsum                                                     0.270677\n","Name: 38, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nRachel: Hey Mark, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nRachel and Mark discuss...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   195.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nRachel and Mark discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nRachel and Mark discuss...\n","base_model_rouge1                                                0.512821\n","Finetuned_rouge1                                                     0.56\n","4o_rouge1                                                        0.556054\n","base_model_rouge2                                                0.146552\n","Finetuned_rouge2                                                 0.196532\n","4o_rouge2                                                        0.271493\n","base_model_rougeL                                                0.273504\n","Finetuned_rougeL                                                 0.388571\n","4o_rougeL                                                        0.430493\n","base_model_rougeLsum                                             0.273504\n","Finetuned_rougeLsum                                              0.388571\n","4o_rougeLsum                                                     0.430493\n","Name: 39, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nAnna: \"Hey, Kevin....\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Catch-up disc...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nAnna and Kevin discuss ...\n","Violations                <BEGIN VIOLATIONS>\\n\\nNone.\\n\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\n\\nGOOD\\n\\n<END LABEL>\n","__index_level_0__                                                   971.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nKevin shared that he had s...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAnna and Kevin catch up...\n","base_model_rouge1                                                0.441315\n","Finetuned_rouge1                                                 0.506494\n","4o_rouge1                                                        0.497561\n","base_model_rouge2                                                0.104265\n","Finetuned_rouge2                                                 0.131579\n","4o_rouge2                                                        0.157635\n","base_model_rougeL                                                0.253521\n","Finetuned_rougeL                                                 0.350649\n","4o_rougeL                                                        0.302439\n","base_model_rougeLsum                                             0.253521\n","Finetuned_rougeLsum                                              0.350649\n","4o_rougeLsum                                                     0.302439\n","Name: 40, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**John:** Hey, Lis...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual discus...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Lisa discuss t...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   118.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Lisa discuss ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a conversation betwe...\n","base_model_rouge1                                                0.389105\n","Finetuned_rouge1                                                 0.533333\n","4o_rouge1                                                         0.48731\n","base_model_rouge2                                                0.141176\n","Finetuned_rouge2                                                 0.189189\n","4o_rouge2                                                        0.153846\n","base_model_rougeL                                                0.264591\n","Finetuned_rougeL                                                      0.4\n","4o_rougeL                                                        0.314721\n","base_model_rougeLsum                                             0.280156\n","Finetuned_rougeLsum                                                   0.4\n","4o_rougeLsum                                                     0.314721\n","Name: 41, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\n**Carla:** I ran i...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nCarla and Juan discusse...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. healthcare.high.medic...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   829.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nCarla and Juan discussed t...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nCarla and Juan discusse...\n","base_model_rouge1                                                0.420664\n","Finetuned_rouge1                                                 0.553459\n","4o_rouge1                                                        0.524017\n","base_model_rouge2                                                0.178439\n","Finetuned_rouge2                                                 0.242038\n","4o_rouge2                                                        0.202643\n","base_model_rougeL                                                0.273063\n","Finetuned_rougeL                                                 0.314465\n","4o_rougeL                                                        0.305677\n","base_model_rougeLsum                                             0.302583\n","Finetuned_rougeLsum                                              0.314465\n","4o_rougeLsum                                                     0.305677\n","Name: 42, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nLena: Hey, Alan, y...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Friends discu...\n","summary                 <BEGIN SUMMARY>\\n\\nAlan shared that he has bee...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. finances.high.loan.in...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   110.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Alan is managing multi...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlan and Lena discusse...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlan and Lena have a ca...\n","base_model_rouge1                                                0.437299\n","Finetuned_rouge1                                                 0.262295\n","4o_rouge1                                                        0.516129\n","base_model_rouge2                                                0.187702\n","Finetuned_rouge2                                                 0.077348\n","4o_rouge2                                                         0.24186\n","base_model_rougeL                                                0.276527\n","Finetuned_rougeL                                                 0.174863\n","4o_rougeL                                                        0.359447\n","base_model_rougeLsum                                             0.282958\n","Finetuned_rougeLsum                                              0.174863\n","4o_rougeLsum                                                     0.359447\n","Name: 43, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmma: Hey Lucas, d...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nEmma and Lucas discuss a fr...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   109.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent office mee...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Lucas discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Lucas discuss ...\n","base_model_rouge1                                                0.346405\n","Finetuned_rouge1                                                 0.627451\n","4o_rouge1                                                        0.507937\n","base_model_rouge2                                                0.151316\n","Finetuned_rouge2                                                 0.304636\n","4o_rouge2                                                        0.149733\n","base_model_rougeL                                                0.228758\n","Finetuned_rougeL                                                 0.431373\n","4o_rougeL                                                         0.31746\n","base_model_rougeLsum                                             0.248366\n","Finetuned_rougeLsum                                              0.431373\n","4o_rougeLsum                                                      0.31746\n","Name: 44, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nAva: You know, I j...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nAva discussed her recen...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   104.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Ava and Ethan discuss ...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAva and Ethan discuss ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAva and Ethan discuss t...\n","base_model_rouge1                                                 0.47619\n","Finetuned_rouge1                                                 0.448276\n","4o_rouge1                                                        0.446154\n","base_model_rouge2                                                0.182692\n","Finetuned_rouge2                                                 0.139535\n","4o_rouge2                                                        0.147287\n","base_model_rougeL                                                0.304762\n","Finetuned_rougeL                                                 0.252874\n","4o_rougeL                                                        0.292308\n","base_model_rougeLsum                                             0.304762\n","Finetuned_rougeLsum                                              0.252874\n","4o_rougeLsum                                                     0.292308\n","Name: 45, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nLisa: I just got b...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nLisa and Alex discussed...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                    87.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Lisa and Alex discuss ...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nLisa and Alex discusse...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLisa and Alex discuss t...\n","base_model_rouge1                                                0.416667\n","Finetuned_rouge1                                                 0.691729\n","4o_rouge1                                                        0.475138\n","base_model_rouge2                                                0.176471\n","Finetuned_rouge2                                                 0.305344\n","4o_rouge2                                                        0.223464\n","base_model_rougeL                                                    0.25\n","Finetuned_rougeL                                                 0.466165\n","4o_rougeL                                                        0.375691\n","base_model_rougeLsum                                             0.266667\n","Finetuned_rougeLsum                                              0.466165\n","4o_rougeLsum                                                     0.375691\n","Name: 46, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\n**Rachel:** Hey Et...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nRachel and Ethan discus...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. healthcare.high.medic...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   886.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Ethan, a university st...\n","summary_finetuned        <BEGIN SUMMARY>\\nEthan recently had surgery f...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a recent conversatio...\n","base_model_rouge1                                                0.495327\n","Finetuned_rouge1                                                 0.502674\n","4o_rouge1                                                        0.508772\n","base_model_rouge2                                                0.169811\n","Finetuned_rouge2                                                 0.172973\n","4o_rouge2                                                         0.19469\n","base_model_rougeL                                                0.308411\n","Finetuned_rougeL                                                 0.363636\n","4o_rougeL                                                        0.350877\n","base_model_rougeLsum                                             0.308411\n","Finetuned_rougeLsum                                              0.363636\n","4o_rougeLsum                                                     0.350877\n","Name: 47, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Jessica:** Hey O...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJessica and Oliver disc...\n","Violations              <BEGIN VIOLATIONS>\\r\\n\\t1. healthcare.high.med...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                    75.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nOliver and Jessica dis...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJessica and Oliver have...\n","base_model_rouge1                                                0.413534\n","Finetuned_rouge1                                                 0.505495\n","4o_rouge1                                                        0.506122\n","base_model_rouge2                                                0.113636\n","Finetuned_rouge2                                                 0.166667\n","4o_rouge2                                                        0.255144\n","base_model_rougeL                                                 0.24812\n","Finetuned_rougeL                                                  0.32967\n","4o_rougeL                                                         0.35102\n","base_model_rougeLsum                                              0.24812\n","Finetuned_rougeLsum                                               0.32967\n","4o_rougeLsum                                                      0.35102\n","Name: 48, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nAlice: Hey Brad, h...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nAlice and Brad discussed Sa...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. healthcare.high.medic...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                    65.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Brad discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Brad discusse...\n","base_model_rouge1                                                0.404959\n","Finetuned_rouge1                                                 0.391534\n","4o_rouge1                                                        0.518219\n","base_model_rouge2                                                     0.1\n","Finetuned_rouge2                                                 0.106952\n","4o_rouge2                                                        0.155102\n","base_model_rougeL                                                0.239669\n","Finetuned_rougeL                                                 0.253968\n","4o_rougeL                                                        0.307692\n","base_model_rougeLsum                                             0.239669\n","Finetuned_rougeLsum                                              0.253968\n","4o_rougeLsum                                                     0.307692\n","Name: 49, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nJessica: Hey Tom, ...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nJessica and Tom discussed t...\n","Violations                <BEGIN VIOLATIONS>\\n\\nNone.\\n\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\n\\nGOOD\\n\\n<END LABEL>\n","__index_level_0__                                                  1019.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\nJessica and Tom discuss a fr...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTom and Jessica discuss...\n","base_model_rouge1                                                0.510288\n","Finetuned_rouge1                                                 0.480447\n","4o_rouge1                                                        0.454902\n","base_model_rouge2                                                0.190871\n","Finetuned_rouge2                                                 0.180791\n","4o_rouge2                                                        0.126482\n","base_model_rougeL                                                0.312757\n","Finetuned_rougeL                                                 0.301676\n","4o_rougeL                                                        0.290196\n","base_model_rougeLsum                                             0.312757\n","Finetuned_rougeLsum                                              0.301676\n","4o_rougeLsum                                                     0.290196\n","Name: 50, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSamantha: **Hey Lu...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nSamantha and Luke discuss a...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   378.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Karen is facing a chal...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSamantha and Luke disc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSamantha and Luke discu...\n","base_model_rouge1                                                0.377049\n","Finetuned_rouge1                                                 0.564103\n","4o_rouge1                                                        0.480874\n","base_model_rouge2                                                0.157025\n","Finetuned_rouge2                                                 0.311688\n","4o_rouge2                                                        0.187845\n","base_model_rougeL                                                0.270492\n","Finetuned_rougeL                                                 0.448718\n","4o_rougeL                                                        0.371585\n","base_model_rougeLsum                                             0.286885\n","Finetuned_rougeLsum                                              0.448718\n","4o_rougeLsum                                                     0.371585\n","Name: 51, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nSophia: Hey Liam, ...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nSophia and Liam are discuss...\n","Violations              <BEGIN VIOLATIONS>\\n1. legal_proceedings.high....\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   790.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n David is currently fac...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nSophia and Liam discuss a ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nThe conversation betwee...\n","base_model_rouge1                                                0.418719\n","Finetuned_rouge1                                                 0.518919\n","4o_rouge1                                                        0.570248\n","base_model_rouge2                                                0.207921\n","Finetuned_rouge2                                                 0.218579\n","4o_rouge2                                                           0.225\n","base_model_rougeL                                                0.241379\n","Finetuned_rougeL                                                 0.345946\n","4o_rougeL                                                        0.363636\n","base_model_rougeLsum                                              0.26601\n","Finetuned_rougeLsum                                              0.345946\n","4o_rougeLsum                                                     0.363636\n","Name: 52, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJoe: Hey, did you ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nLydia is currently facing m...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. legal_proceedings.hig...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   370.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Lydia is entangled in ...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJoe and Anna discuss L...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAnna and Joe discuss Ly...\n","base_model_rouge1                                                0.537102\n","Finetuned_rouge1                                                  0.53125\n","4o_rouge1                                                        0.579365\n","base_model_rouge2                                                0.234875\n","Finetuned_rouge2                                                      0.2\n","4o_rouge2                                                            0.28\n","base_model_rougeL                                                0.360424\n","Finetuned_rougeL                                                 0.322917\n","4o_rougeL                                                        0.373016\n","base_model_rougeLsum                                             0.360424\n","Finetuned_rougeLsum                                              0.322917\n","4o_rougeLsum                                                     0.373016\n","Name: 53, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nRachel: **Hey John...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nRachel informs John abo...\n","Violations              <BEGIN VIOLATIONS>\\r\\n\\r\\n1. legal_proceedings...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   369.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nRachel and John discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nRachel and John discuss...\n","base_model_rouge1                                                0.395833\n","Finetuned_rouge1                                                 0.494505\n","4o_rouge1                                                        0.493274\n","base_model_rouge2                                                0.111888\n","Finetuned_rouge2                                                 0.111111\n","4o_rouge2                                                        0.171946\n","base_model_rougeL                                                0.201389\n","Finetuned_rougeL                                                 0.307692\n","4o_rougeL                                                        0.278027\n","base_model_rougeLsum                                             0.208333\n","Finetuned_rougeLsum                                              0.307692\n","4o_rougeLsum                                                     0.278027\n","Name: 54, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJessica: **Did you...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJessica and David are d...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. legal_proceedings.hig...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   364.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Tom, a man with a hist...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJessica and David disc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nThe conversation revolv...\n","base_model_rouge1                                                0.447552\n","Finetuned_rouge1                                                 0.440476\n","4o_rouge1                                                        0.444444\n","base_model_rouge2                                                 0.15493\n","Finetuned_rouge2                                                  0.13253\n","4o_rouge2                                                        0.152466\n","base_model_rougeL                                                0.265734\n","Finetuned_rougeL                                                 0.309524\n","4o_rougeL                                                        0.275556\n","base_model_rougeLsum                                             0.307692\n","Finetuned_rougeLsum                                              0.309524\n","4o_rougeLsum                                                     0.275556\n","Name: 55, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSamantha: **Hey Al...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nSamantha and Alex discussed...\n","Violations              <BEGIN VIOLATIONS>\\r\\n1. legal_proceedings.hig...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   347.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSamantha and Alex disc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSamantha and Alex discu...\n","base_model_rouge1                                                0.407143\n","Finetuned_rouge1                                                 0.463415\n","4o_rouge1                                                        0.532189\n","base_model_rouge2                                                0.151079\n","Finetuned_rouge2                                                 0.209877\n","4o_rouge2                                                         0.21645\n","base_model_rougeL                                                0.278571\n","Finetuned_rougeL                                                 0.390244\n","4o_rougeL                                                        0.334764\n","base_model_rougeLsum                                             0.292857\n","Finetuned_rougeLsum                                              0.390244\n","4o_rougeLsum                                                     0.334764\n","Name: 56, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nSarah: *Hey, John....\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nSarah informs John about Je...\n","Violations              <BEGIN VIOLATIONS>\\n1. legal_proceedings.high....\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   907.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nSarah and John discuss a fri...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSarah and John discuss ...\n","base_model_rouge1                                                 0.51049\n","Finetuned_rouge1                                                 0.391061\n","4o_rouge1                                                        0.604839\n","base_model_rouge2                                                0.176056\n","Finetuned_rouge2                                                 0.101695\n","4o_rouge2                                                        0.243902\n","base_model_rougeL                                                0.314685\n","Finetuned_rougeL                                                 0.268156\n","4o_rougeL                                                        0.395161\n","base_model_rougeLsum                                             0.314685\n","Finetuned_rougeLsum                                              0.268156\n","4o_rougeLsum                                                     0.395161\n","Name: 57, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nLisa: **Hey, Alex,...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nLisa and Alex discuss T...\n","Violations              <BEGIN VIOLATIONS>\\r\\n\\t1. legal_proceedings.h...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   335.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nLisa and Alex discuss ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo individuals, Lisa a...\n","base_model_rouge1                                                0.571429\n","Finetuned_rouge1                                                 0.523256\n","4o_rouge1                                                        0.567308\n","base_model_rouge2                                                0.238683\n","Finetuned_rouge2                                                 0.164706\n","4o_rouge2                                                         0.23301\n","base_model_rougeL                                                0.383673\n","Finetuned_rougeL                                                 0.337209\n","4o_rougeL                                                        0.307692\n","base_model_rougeLsum                                             0.383673\n","Finetuned_rougeLsum                                              0.337209\n","4o_rougeLsum                                                     0.307692\n","Name: 58, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                 Legal Proceedings\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJames: Hey Jenna, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJames and Jenna discuss...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. legal_proceedings.hig...\n","Quality                              <BEGIN LABEL>\\r\\nBAD \\r\\n<END LABEL>\n","__index_level_0__                                                   325.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJames and Jenna discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo individuals, James ...\n","base_model_rouge1                                                0.439834\n","Finetuned_rouge1                                                 0.505882\n","4o_rouge1                                                        0.475728\n","base_model_rouge2                                                0.158996\n","Finetuned_rouge2                                                 0.178571\n","4o_rouge2                                                        0.166667\n","base_model_rougeL                                                0.273859\n","Finetuned_rougeL                                                 0.329412\n","4o_rougeL                                                        0.320388\n","base_model_rougeLsum                                             0.273859\n","Finetuned_rougeLsum                                              0.329412\n","4o_rougeLsum                                                     0.320388\n","Name: 59, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nEmma: Hey Alex, di...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Friends discu...\n","summary                 <BEGIN SUMMARY>\\n\\nEmma and Alex discussed the...\n","Violations              <BEGIN VIOLATIONS>\\n1. political.high.politica...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   912.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nEmma and Alex discussed a re...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Alex discuss t...\n","base_model_rouge1                                                0.517647\n","Finetuned_rouge1                                                 0.480447\n","4o_rouge1                                                           0.475\n","base_model_rouge2                                                 0.27668\n","Finetuned_rouge2                                                 0.237288\n","4o_rouge2                                                        0.218487\n","base_model_rougeL                                                0.392157\n","Finetuned_rougeL                                                 0.402235\n","4o_rougeL                                                        0.333333\n","base_model_rougeLsum                                             0.392157\n","Finetuned_rougeLsum                                              0.402235\n","4o_rougeLsum                                                     0.333333\n","Name: 60, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nDavid: So, Emma, h...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion be...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nDavid and Emma discuss ...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   443.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nDavid and Emma discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nDavid and Emma discusse...\n","base_model_rouge1                                                0.356436\n","Finetuned_rouge1                                                 0.496552\n","4o_rouge1                                                        0.437247\n","base_model_rouge2                                                0.066445\n","Finetuned_rouge2                                                 0.153846\n","4o_rouge2                                                        0.122449\n","base_model_rougeL                                                 0.19802\n","Finetuned_rougeL                                                 0.344828\n","4o_rougeL                                                        0.259109\n","base_model_rougeLsum                                             0.211221\n","Finetuned_rougeLsum                                              0.344828\n","4o_rougeLsum                                                     0.259109\n","Name: 61, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nAmit: **Hey Deepa,...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nAmit and Deepa discussed se...\n","Violations              <BEGIN VIOLATIONS>\\n1. political.high.membersh...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   797.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nAmit and Deepa discussed rec...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAmit and Deepa engaged ...\n","base_model_rouge1                                                0.473333\n","Finetuned_rouge1                                                 0.519608\n","4o_rouge1                                                        0.513011\n","base_model_rouge2                                                0.248322\n","Finetuned_rouge2                                                 0.217822\n","4o_rouge2                                                         0.23221\n","base_model_rougeL                                                0.353333\n","Finetuned_rougeL                                                 0.392157\n","4o_rougeL                                                        0.371747\n","base_model_rougeLsum                                             0.353333\n","Finetuned_rougeLsum                                              0.392157\n","4o_rougeLsum                                                     0.371747\n","Name: 62, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nPriya: So, Rahul, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nRahul recently joined the N...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. political_activities....\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   435.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Rahul has recently joi...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nPriya and Rahul discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nPriya and Rahul discuss...\n","base_model_rouge1                                                0.475884\n","Finetuned_rouge1                                                 0.375635\n","4o_rouge1                                                        0.537634\n","base_model_rouge2                                                 0.23301\n","Finetuned_rouge2                                                 0.082051\n","4o_rouge2                                                        0.296029\n","base_model_rougeL                                                0.327974\n","Finetuned_rougeL                                                 0.233503\n","4o_rougeL                                                        0.408602\n","base_model_rougeLsum                                             0.398714\n","Finetuned_rougeLsum                                              0.233503\n","4o_rougeLsum                                                     0.408602\n","Name: 63, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nNina: Hey Mark, di...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nNina and Mark discuss atten...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. political_activities....\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   434.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nNina and Mark discuss ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nNina and Mark discuss a...\n","base_model_rouge1                                                0.446281\n","Finetuned_rouge1                                                 0.386364\n","4o_rouge1                                                        0.527197\n","base_model_rouge2                                                0.133333\n","Finetuned_rouge2                                                 0.114943\n","4o_rouge2                                                        0.177215\n","base_model_rougeL                                                0.256198\n","Finetuned_rougeL                                                 0.295455\n","4o_rougeL                                                        0.317992\n","base_model_rougeLsum                                             0.239669\n","Finetuned_rougeLsum                                              0.295455\n","4o_rougeLsum                                                     0.317992\n","Name: 64, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmily: Hey Mark, d...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nEmily and Mark discuss the ...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. sexual_orientation_an...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   429.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n The conversation betwe...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Mark discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Mark discuss ...\n","base_model_rouge1                                                 0.39375\n","Finetuned_rouge1                                                 0.597701\n","4o_rouge1                                                        0.543779\n","base_model_rouge2                                                0.106918\n","Finetuned_rouge2                                                 0.302326\n","4o_rouge2                                                        0.204651\n","base_model_rougeL                                                   0.225\n","Finetuned_rougeL                                                 0.390805\n","4o_rougeL                                                        0.322581\n","base_model_rougeLsum                                               0.2625\n","Finetuned_rougeLsum                                              0.390805\n","4o_rougeLsum                                                     0.322581\n","Name: 65, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmily: Hey, Lucas!...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nEmily and Lucas discussed t...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   412.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nLucas attended a polit...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Lucas discuss...\n","base_model_rouge1                                                0.374582\n","Finetuned_rouge1                                                 0.420455\n","4o_rouge1                                                         0.45098\n","base_model_rouge2                                                0.127946\n","Finetuned_rouge2                                                 0.126437\n","4o_rouge2                                                        0.158416\n","base_model_rougeL                                                0.234114\n","Finetuned_rougeL                                                 0.340909\n","4o_rougeL                                                        0.323529\n","base_model_rougeLsum                                             0.274247\n","Finetuned_rougeLsum                                              0.340909\n","4o_rougeLsum                                                     0.323529\n","Name: 66, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nSamantha: **Hey Ma...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nSamantha and Mark discussed...\n","Violations              <BEGIN VIOLATIONS>\\n1. sexual_orientation_and_...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   810.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nSamantha and Mark discussed ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSamantha and Mark discu...\n","base_model_rouge1                                                0.337079\n","Finetuned_rouge1                                                  0.43871\n","4o_rouge1                                                        0.392523\n","base_model_rouge2                                                 0.10566\n","Finetuned_rouge2                                                 0.156863\n","4o_rouge2                                                        0.169811\n","base_model_rougeL                                                0.194757\n","Finetuned_rougeL                                                 0.309677\n","4o_rougeL                                                        0.242991\n","base_model_rougeLsum                                             0.224719\n","Finetuned_rougeLsum                                              0.309677\n","4o_rougeLsum                                                     0.242991\n","Name: 67, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJessica: Hey Mark,...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nMark discussed his active i...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. political_activities....\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   400.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nMark and Jessica discu...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJessica and Mark discus...\n","base_model_rouge1                                                0.379562\n","Finetuned_rouge1                                                 0.421622\n","4o_rouge1                                                        0.466667\n","base_model_rouge2                                                0.132353\n","Finetuned_rouge2                                                 0.163934\n","4o_rouge2                                                        0.168067\n","base_model_rougeL                                                0.270073\n","Finetuned_rougeL                                                 0.259459\n","4o_rougeL                                                        0.316667\n","base_model_rougeLsum                                             0.270073\n","Finetuned_rougeLsum                                              0.259459\n","4o_rougeLsum                                                     0.316667\n","Name: 68, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                              Political Activities\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSamantha: **So, di...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\r\\nSamantha and Bryan discusse...\n","Violations              <BEGIN VIOLATIONS>\\r\\n\\t1. political_activitie...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   390.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a local council ini...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSamantha and Bryan dis...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nBryan and Samantha disc...\n","base_model_rouge1                                                0.350365\n","Finetuned_rouge1                                                 0.335404\n","4o_rouge1                                                        0.563107\n","base_model_rouge2                                                0.102941\n","Finetuned_rouge2                                                 0.125786\n","4o_rouge2                                                        0.215686\n","base_model_rougeL                                                 0.20438\n","Finetuned_rougeL                                                 0.285714\n","4o_rougeL                                                         0.38835\n","base_model_rougeLsum                                             0.270073\n","Finetuned_rougeLsum                                              0.285714\n","4o_rougeLsum                                                      0.38835\n","Name: 69, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nPriya: **Hey Rajes...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nPriya and Rajesh discussed ...\n","Violations              <BEGIN VIOLATIONS>\\n1. religious.high.religion...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   922.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nRajesh attended a seminar di...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nPriya and Rajesh discus...\n","base_model_rouge1                                                0.426471\n","Finetuned_rouge1                                                 0.435294\n","4o_rouge1                                                        0.377358\n","base_model_rouge2                                                0.162963\n","Finetuned_rouge2                                                 0.119048\n","4o_rouge2                                                        0.161905\n","base_model_rougeL                                                0.272059\n","Finetuned_rougeL                                                 0.305882\n","4o_rougeL                                                        0.292453\n","base_model_rougeLsum                                             0.330882\n","Finetuned_rougeLsum                                              0.305882\n","4o_rougeLsum                                                     0.292453\n","Name: 70, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Sofia**: Did you...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Chat about re...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nSofia and Amit are disc...\n","Violations              <BEGIN VIOLATIONS>\\r\\n\\t1. religious.high.reli...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   508.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSofia and Amit discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSofia and Amit discusse...\n","base_model_rouge1                                                0.486111\n","Finetuned_rouge1                                                 0.518919\n","4o_rouge1                                                        0.571429\n","base_model_rouge2                                                0.146853\n","Finetuned_rouge2                                                 0.131148\n","4o_rouge2                                                        0.317308\n","base_model_rougeL                                                0.284722\n","Finetuned_rougeL                                                 0.302703\n","4o_rougeL                                                        0.419048\n","base_model_rougeLsum                                             0.284722\n","Finetuned_rougeLsum                                              0.302703\n","4o_rougeLsum                                                     0.419048\n","Name: 71, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nPriya: **Hey David...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\n\\nPriya and David discuss an ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   784.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n The conversation betwe...\n","summary_finetuned        <BEGIN SUMMARY>\\nPriya and David discuss an u...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nPriya and David discuss...\n","base_model_rouge1                                                0.363171\n","Finetuned_rouge1                                                 0.597701\n","4o_rouge1                                                         0.52549\n","base_model_rouge2                                                  0.1491\n","Finetuned_rouge2                                                 0.313953\n","4o_rouge2                                                        0.213439\n","base_model_rougeL                                                0.225064\n","Finetuned_rougeL                                                 0.436782\n","4o_rougeL                                                        0.352941\n","base_model_rougeLsum                                             0.245524\n","Finetuned_rougeLsum                                              0.436782\n","4o_rougeLsum                                                     0.352941\n","Name: 72, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Julia**: Hey Tom...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Friends discu...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJulia and Tom discussed...\n","Violations              <BEGIN VIOLATIONS>\\n1. religions.high.religion...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   500.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nTom and Julia discusse...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a conversation betwe...\n","base_model_rouge1                                                0.444444\n","Finetuned_rouge1                                                 0.511364\n","4o_rouge1                                                        0.454902\n","base_model_rouge2                                                0.183051\n","Finetuned_rouge2                                                 0.183908\n","4o_rouge2                                                        0.173913\n","base_model_rougeL                                                0.316498\n","Finetuned_rougeL                                                 0.340909\n","4o_rougeL                                                        0.258824\n","base_model_rougeLsum                                             0.323232\n","Finetuned_rougeLsum                                              0.340909\n","4o_rougeLsum                                                     0.258824\n","Name: 73, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nPriya: Hey, John! ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn missed a charity event...\n","Violations              <BEGIN VIOLATIONS>\\r\\n1. religious.high.specif...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   499.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nPriya and John catch u...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nPriya and John catch up...\n","base_model_rouge1                                                0.407295\n","Finetuned_rouge1                                                 0.481283\n","4o_rouge1                                                        0.445902\n","base_model_rouge2                                                0.140673\n","Finetuned_rouge2                                                 0.140541\n","4o_rouge2                                                        0.145215\n","base_model_rougeL                                                0.212766\n","Finetuned_rougeL                                                 0.235294\n","4o_rougeL                                                         0.27541\n","base_model_rougeLsum                                             0.267477\n","Finetuned_rougeLsum                                              0.235294\n","4o_rougeLsum                                                      0.27541\n","Name: 74, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSophia: Hey Luke, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nLuke and Sophia discuss...\n","Violations              <BEGIN VIOLATIONS>\\n1. religions.high.religion...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   494.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n At an interfaith dialo...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSophia and Luke discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSophia and Luke discuss...\n","base_model_rouge1                                                0.393013\n","Finetuned_rouge1                                                     0.45\n","4o_rouge1                                                        0.465517\n","base_model_rouge2                                                0.167401\n","Finetuned_rouge2                                                 0.113924\n","4o_rouge2                                                        0.165217\n","base_model_rougeL                                                0.262009\n","Finetuned_rougeL                                                   0.2375\n","4o_rougeL                                                        0.310345\n","base_model_rougeLsum                                             0.262009\n","Finetuned_rougeLsum                                                0.2375\n","4o_rougeLsum                                                     0.310345\n","Name: 75, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n***\\r\\nPriya: Hey ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nPriya and Sam discuss t...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   477.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nPriya and Sam discusse...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nPriya and Sam discussed...\n","base_model_rouge1                                                0.394984\n","Finetuned_rouge1                                                 0.509554\n","4o_rouge1                                                        0.506667\n","base_model_rouge2                                                0.157729\n","Finetuned_rouge2                                                 0.219355\n","4o_rouge2                                                        0.179372\n","base_model_rougeL                                                0.275862\n","Finetuned_rougeL                                                 0.369427\n","4o_rougeL                                                        0.248889\n","base_model_rougeLsum                                             0.225705\n","Finetuned_rougeLsum                                              0.369427\n","4o_rougeLsum                                                     0.293333\n","Name: 76, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nMira: Hey Tom, lon...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nTom and Mira catch up a...\n","Violations              <BEGIN VIOLATIONS>\\n1. religions.high.specific...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   898.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\nTom and Mira discussed their...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nMira and Tom catch up a...\n","base_model_rouge1                                                0.393258\n","Finetuned_rouge1                                                  0.33121\n","4o_rouge1                                                        0.498221\n","base_model_rouge2                                                0.152542\n","Finetuned_rouge2                                                 0.090323\n","4o_rouge2                                                        0.222222\n","base_model_rougeL                                                0.269663\n","Finetuned_rougeL                                                 0.216561\n","4o_rougeL                                                        0.355872\n","base_model_rougeLsum                                             0.275281\n","Finetuned_rougeLsum                                              0.216561\n","4o_rougeLsum                                                     0.384342\n","Name: 77, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSophia: Hey Mark, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nSophia and Mark discuss...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   465.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nMark and Sophia discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nMark and Sophia discuss...\n","base_model_rouge1                                                0.440559\n","Finetuned_rouge1                                                 0.556818\n","4o_rouge1                                                        0.451282\n","base_model_rouge2                                                0.140845\n","Finetuned_rouge2                                                 0.229885\n","4o_rouge2                                                        0.186528\n","base_model_rougeL                                                0.230769\n","Finetuned_rougeL                                                 0.420455\n","4o_rougeL                                                        0.297436\n","base_model_rougeLsum                                             0.272727\n","Finetuned_rougeLsum                                              0.420455\n","4o_rougeLsum                                                     0.297436\n","Name: 78, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                Religious Contexts\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJames: Hey Lisa, d...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\n\\nJames and Lisa discussed th...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. religion.high.transit...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   455.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJames and Lisa discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLisa and James discuss ...\n","base_model_rouge1                                                0.403974\n","Finetuned_rouge1                                                 0.459893\n","4o_rouge1                                                        0.491228\n","base_model_rouge2                                                0.126667\n","Finetuned_rouge2                                                 0.227027\n","4o_rouge2                                                        0.168142\n","base_model_rougeL                                                0.278146\n","Finetuned_rougeL                                                 0.363636\n","4o_rougeL                                                        0.315789\n","base_model_rougeLsum                                             0.278146\n","Finetuned_rougeLsum                                              0.363636\n","4o_rougeLsum                                                     0.315789\n","Name: 79, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\n**Sophia:** Hey Ma...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nSophia and Mark discuss...\n","Violations                <BEGIN VIOLATIONS>\\n\\nNone.\\n\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\n\\nGOOD\\n\\n<END LABEL>\n","__index_level_0__                                                  1059.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nSophia and Mark discussed ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSophia and Mark discuss...\n","base_model_rouge1                                                0.381579\n","Finetuned_rouge1                                                 0.547619\n","4o_rouge1                                                        0.417778\n","base_model_rouge2                                                0.178808\n","Finetuned_rouge2                                                 0.301205\n","4o_rouge2                                                        0.152466\n","base_model_rougeL                                                0.236842\n","Finetuned_rougeL                                                 0.428571\n","4o_rougeL                                                        0.284444\n","base_model_rougeLsum                                             0.276316\n","Finetuned_rougeLsum                                              0.428571\n","4o_rougeLsum                                                     0.284444\n","Name: 80, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nSamantha: **\"Hey J...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nSamantha and Jamie disc...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   573.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSamantha and Jamie dis...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a conversation, Sama...\n","base_model_rouge1                                                 0.39759\n","Finetuned_rouge1                                                 0.497041\n","4o_rouge1                                                         0.49789\n","base_model_rouge2                                                0.127273\n","Finetuned_rouge2                                                 0.191617\n","4o_rouge2                                                        0.178723\n","base_model_rougeL                                                0.271084\n","Finetuned_rougeL                                                 0.343195\n","4o_rougeL                                                        0.337553\n","base_model_rougeLsum                                             0.325301\n","Finetuned_rougeLsum                                              0.343195\n","4o_rougeLsum                                                     0.337553\n","Name: 81, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\n**Rachel:** Hey Sa...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\n\\nRachel and Sam are discussi...\n","Violations              <BEGIN VIOLATIONS>\\n1. sng_identity.high.trans...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   877.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nRachel and Sam discussed the...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nRachel and Sam discusse...\n","base_model_rouge1                                                0.418919\n","Finetuned_rouge1                                                 0.363636\n","4o_rouge1                                                        0.444444\n","base_model_rouge2                                                0.136054\n","Finetuned_rouge2                                                  0.08589\n","4o_rouge2                                                        0.171642\n","base_model_rougeL                                                0.297297\n","Finetuned_rougeL                                                 0.230303\n","4o_rougeL                                                        0.266667\n","base_model_rougeLsum                                             0.310811\n","Finetuned_rougeLsum                                              0.230303\n","4o_rougeLsum                                                     0.288889\n","Name: 82, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Sophie:** Hey, M...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nTaylor came out as non-bina...\n","Violations              <BEGIN VIOLATIONS>\\n1. sng_identity.high.gende...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   565.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent team meeti...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSophie and Matt discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSophie and Matt discuss...\n","base_model_rouge1                                                0.532787\n","Finetuned_rouge1                                                 0.324022\n","4o_rouge1                                                        0.471111\n","base_model_rouge2                                                0.239669\n","Finetuned_rouge2                                                 0.079096\n","4o_rouge2                                                        0.161435\n","base_model_rougeL                                                0.385246\n","Finetuned_rougeL                                                 0.178771\n","4o_rougeL                                                        0.311111\n","base_model_rougeLsum                                             0.385246\n","Finetuned_rougeLsum                                              0.178771\n","4o_rougeLsum                                                     0.311111\n","Name: 83, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJenna: **Hey Tom, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Informal conv...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJenna and Tom discussed...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   564.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJenna and Tom discuss ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJenna and Tom discussed...\n","base_model_rouge1                                                0.553571\n","Finetuned_rouge1                                                 0.587629\n","4o_rouge1                                                        0.567164\n","base_model_rouge2                                                0.198198\n","Finetuned_rouge2                                                   0.3125\n","4o_rouge2                                                        0.281407\n","base_model_rougeL                                                0.348214\n","Finetuned_rougeL                                                 0.484536\n","4o_rougeL                                                         0.39801\n","base_model_rougeLsum                                             0.348214\n","Finetuned_rougeLsum                                              0.484536\n","4o_rougeLsum                                                      0.39801\n","Name: 84, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Emily:** Hey Chr...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Informal conv...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Chris discuss...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   559.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a supportive conver...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Chris discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and Chris discuss...\n","base_model_rouge1                                                0.468468\n","Finetuned_rouge1                                                 0.551724\n","4o_rouge1                                                        0.493023\n","base_model_rouge2                                                0.136364\n","Finetuned_rouge2                                                  0.20979\n","4o_rouge2                                                        0.150235\n","base_model_rougeL                                                0.252252\n","Finetuned_rougeL                                                 0.386207\n","4o_rougeL                                                        0.334884\n","base_model_rougeLsum                                             0.243243\n","Finetuned_rougeLsum                                              0.386207\n","4o_rougeLsum                                                     0.334884\n","Name: 85, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nJamie: \"Hey Taylor...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJamie and Taylor discus...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   542.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJamie and Taylor discu...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo friends, Jamie and ...\n","base_model_rouge1                                                0.495935\n","Finetuned_rouge1                                                 0.598802\n","4o_rouge1                                                        0.555556\n","base_model_rouge2                                                0.188525\n","Finetuned_rouge2                                                 0.230303\n","4o_rouge2                                                        0.244898\n","base_model_rougeL                                                0.317073\n","Finetuned_rougeL                                                 0.407186\n","4o_rougeL                                                        0.353535\n","base_model_rougeLsum                                             0.317073\n","Finetuned_rougeLsum                                              0.407186\n","4o_rougeLsum                                                     0.353535\n","Name: 86, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\n**Jordan:** Hey Ch...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nJordan and Chris discus...\n","Violations              <BEGIN VIOLATIONS>\\n1. sng_identity.high.gende...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   930.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nJordan and Chris discussed a...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJordan and Chris discus...\n","base_model_rouge1                                                 0.48254\n","Finetuned_rouge1                                                 0.519774\n","4o_rouge1                                                        0.528139\n","base_model_rouge2                                                0.191693\n","Finetuned_rouge2                                                 0.274286\n","4o_rouge2                                                        0.262009\n","base_model_rougeL                                                0.285714\n","Finetuned_rougeL                                                 0.418079\n","4o_rougeL                                                        0.363636\n","base_model_rougeLsum                                             0.336508\n","Finetuned_rougeLsum                                              0.418079\n","4o_rougeLsum                                                     0.363636\n","Name: 87, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Jenny:** Hey Luc...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Friends discu...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJenny and Lucas talk ab...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   530.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n At a Pride parade, Luc...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJenny and Lucas are di...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo friends, Jenny and ...\n","base_model_rouge1                                                0.437768\n","Finetuned_rouge1                                                 0.666667\n","4o_rouge1                                                        0.537445\n","base_model_rouge2                                                 0.17316\n","Finetuned_rouge2                                                 0.313253\n","4o_rouge2                                                        0.213333\n","base_model_rougeL                                                0.274678\n","Finetuned_rougeL                                                 0.440476\n","4o_rougeL                                                        0.334802\n","base_model_rougeLsum                                             0.274678\n","Finetuned_rougeLsum                                              0.440476\n","4o_rougeLsum                                                     0.334802\n","Name: 88, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                            Sexual Orientation and Gender Identity\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Sophia:** Hey Ma...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\nSophia and Marcus discuss t...\n","Violations              <BEGIN VIOLATIONS>\\n1. sng_identity.high.gende...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   520.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSophia and Marcus disc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSophia and Marcus, who ...\n","base_model_rouge1                                                   0.375\n","Finetuned_rouge1                                                 0.430769\n","4o_rouge1                                                        0.494545\n","base_model_rouge2                                                0.125714\n","Finetuned_rouge2                                                  0.11399\n","4o_rouge2                                                        0.175824\n","base_model_rougeL                                                    0.25\n","Finetuned_rougeL                                                  0.25641\n","4o_rougeL                                                        0.283636\n","base_model_rougeLsum                                             0.261364\n","Finetuned_rougeLsum                                               0.25641\n","4o_rougeLsum                                                     0.283636\n","Name: 89, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nDavid: **Hey Laura...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nDavid and Laura discuss...\n","Violations              <BEGIN VIOLATIONS>\\r\\n1. employment.high.work_...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   322.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nDavid and Laura discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nDavid and Laura discuss...\n","base_model_rouge1                                                     0.5\n","Finetuned_rouge1                                                 0.357616\n","4o_rouge1                                                        0.366492\n","base_model_rouge2                                                     0.2\n","Finetuned_rouge2                                                 0.161074\n","4o_rouge2                                                         0.10582\n","base_model_rougeL                                                0.415094\n","Finetuned_rougeL                                                 0.291391\n","4o_rougeL                                                        0.251309\n","base_model_rougeLsum                                             0.415094\n","Finetuned_rougeLsum                                              0.291391\n","4o_rougeLsum                                                     0.251309\n","Name: 90, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**Alice:** Hey Bri...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion on...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Brian discuss...\n","Violations              <BEGIN VIOLATIONS>\\n1. social_media.high.priva...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   300.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Brian discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Brian discuss...\n","base_model_rouge1                                                0.466403\n","Finetuned_rouge1                                                 0.394737\n","4o_rouge1                                                        0.516129\n","base_model_rouge2                                                0.159363\n","Finetuned_rouge2                                                 0.150442\n","4o_rouge2                                                        0.209386\n","base_model_rougeL                                                0.332016\n","Finetuned_rougeL                                                 0.298246\n","4o_rougeL                                                        0.387097\n","base_model_rougeLsum                                             0.332016\n","Finetuned_rougeLsum                                              0.298246\n","4o_rougeLsum                                                     0.387097\n","Name: 91, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nSophia: **Hey Mark...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nSophia and Mark discuss...\n","Violations                <BEGIN VIOLATIONS>\\n\\nNone.\\n\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\n\\nGOOD\\n\\n<END LABEL>\n","__index_level_0__                                                  1015.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nSophia and Mark discuss va...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSophia and Mark discuss...\n","base_model_rouge1                                                0.534884\n","Finetuned_rouge1                                                      0.5\n","4o_rouge1                                                         0.38806\n","base_model_rouge2                                                0.247059\n","Finetuned_rouge2                                                 0.222222\n","4o_rouge2                                                        0.160804\n","base_model_rougeL                                                0.360465\n","Finetuned_rougeL                                                 0.390625\n","4o_rougeL                                                        0.298507\n","base_model_rougeLsum                                             0.360465\n","Finetuned_rougeLsum                                              0.390625\n","4o_rougeLsum                                                     0.298507\n","Name: 92, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nAlex: **Hey Taylor...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion on...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nAlex and Taylor discuss...\n","Violations              <BEGIN VIOLATIONS>\\r\\n1. social_media.high.per...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   278.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlex and Taylor discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlex and Taylor discuss...\n","base_model_rouge1                                                0.392157\n","Finetuned_rouge1                                                 0.516129\n","4o_rouge1                                                        0.542714\n","base_model_rouge2                                                 0.09901\n","Finetuned_rouge2                                                  0.20915\n","4o_rouge2                                                        0.243655\n","base_model_rougeL                                                0.254902\n","Finetuned_rougeL                                                 0.309677\n","4o_rougeL                                                         0.41206\n","base_model_rougeLsum                                             0.254902\n","Finetuned_rougeLsum                                              0.309677\n","4o_rougeLsum                                                      0.41206\n","Name: 93, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nLiam: Hey, Olivia,...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nLiam and Olivia discuss the...\n","Violations                <BEGIN VIOLATIONS>\\n\\nNone.\\n\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\n\\nGOOD\\n\\n<END LABEL>\n","__index_level_0__                                                  1017.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nLiam and Olivia discuss a ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLiam and Olivia discuss...\n","base_model_rouge1                                                0.324841\n","Finetuned_rouge1                                                 0.506667\n","4o_rouge1                                                        0.502513\n","base_model_rouge2                                                0.115385\n","Finetuned_rouge2                                                 0.189189\n","4o_rouge2                                                         0.13198\n","base_model_rougeL                                                0.178344\n","Finetuned_rougeL                                                     0.36\n","4o_rougeL                                                        0.321608\n","base_model_rougeLsum                                             0.203822\n","Finetuned_rougeLsum                                                  0.36\n","4o_rougeLsum                                                     0.321608\n","Name: 94, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\n**Jessica:** Hey, ...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nJessica and Tom discuss...\n","Violations                <BEGIN VIOLATIONS>\\n\\nNone.\\n\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\n\\nGOOD\\n\\n<END LABEL>\n","__index_level_0__                                                  1004.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nJessica and Tom discuss thei...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJessica and Tom discuss...\n","base_model_rouge1                                                0.439252\n","Finetuned_rouge1                                                 0.447552\n","4o_rouge1                                                         0.52439\n","base_model_rouge2                                                0.141509\n","Finetuned_rouge2                                                 0.184397\n","4o_rouge2                                                        0.185185\n","base_model_rougeL                                                0.280374\n","Finetuned_rougeL                                                 0.321678\n","4o_rougeL                                                        0.329268\n","base_model_rougeLsum                                             0.280374\n","Finetuned_rougeLsum                                              0.321678\n","4o_rougeLsum                                                     0.329268\n","Name: 95, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nVictor: Hey, Lexie...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nVictor and Lexie discus...\n","Violations              <BEGIN VIOLATIONS>\\r\\n1. socialmedia.high.pers...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   324.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nVictor and Lexie discu...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nVictor and Lexie are co...\n","base_model_rouge1                                                0.493274\n","Finetuned_rouge1                                                 0.390533\n","4o_rouge1                                                        0.518868\n","base_model_rouge2                                                0.171946\n","Finetuned_rouge2                                                 0.107784\n","4o_rouge2                                                         0.27619\n","base_model_rougeL                                                0.367713\n","Finetuned_rougeL                                                 0.284024\n","4o_rougeL                                                         0.40566\n","base_model_rougeLsum                                             0.367713\n","Finetuned_rougeLsum                                              0.284024\n","4o_rougeLsum                                                      0.40566\n","Name: 96, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmma: **Hey Jake, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Jake discuss t...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   302.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Jake discuss ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmma and Jake discuss t...\n","base_model_rouge1                                                0.528846\n","Finetuned_rouge1                                                 0.532544\n","4o_rouge1                                                            0.58\n","base_model_rouge2                                                0.165049\n","Finetuned_rouge2                                                 0.203593\n","4o_rouge2                                                        0.272727\n","base_model_rougeL                                                0.298077\n","Finetuned_rougeL                                                 0.295858\n","4o_rougeL                                                            0.34\n","base_model_rougeLsum                                             0.298077\n","Finetuned_rougeLsum                                              0.295858\n","4o_rougeLsum                                                         0.34\n","Name: 97, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nMaria: **Hey David...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nDavid and Maria discuss...\n","Violations              <BEGIN VIOLATIONS>\\r\\n1. social_media.high.per...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   270.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation abou...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nMaria and David discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nMaria and David discuss...\n","base_model_rouge1                                                0.442553\n","Finetuned_rouge1                                                 0.336957\n","4o_rouge1                                                        0.328205\n","base_model_rouge2                                                0.103004\n","Finetuned_rouge2                                                 0.098901\n","4o_rouge2                                                        0.072539\n","base_model_rougeL                                                0.306383\n","Finetuned_rougeL                                                  0.23913\n","4o_rougeL                                                        0.225641\n","base_model_rougeLsum                                             0.306383\n","Finetuned_rougeLsum                                               0.23913\n","4o_rougeLsum                                                     0.225641\n","Name: 98, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\n**James:** Hey Kat...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nJames and Katherine discuss...\n","Violations              <BEGIN VIOLATIONS>\\n\\tNone. (Just don't mentio...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   260.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation abou...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJames and Katherine di...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJames and Katherine dis...\n","base_model_rouge1                                                0.392344\n","Finetuned_rouge1                                                 0.402116\n","4o_rouge1                                                        0.497817\n","base_model_rouge2                                                0.135266\n","Finetuned_rouge2                                                 0.213904\n","4o_rouge2                                                        0.220264\n","base_model_rougeL                                                0.220096\n","Finetuned_rougeL                                                 0.275132\n","4o_rougeL                                                        0.340611\n","base_model_rougeLsum                                             0.220096\n","Finetuned_rougeLsum                                              0.275132\n","4o_rougeLsum                                                     0.340611\n","Name: 99, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nEmily: Hey John, I...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: A conversatio...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nJohn recently returned ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   950.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nJohn recently returned from ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJohn recently returned ...\n","base_model_rouge1                                                0.472362\n","Finetuned_rouge1                                                 0.555556\n","4o_rouge1                                                        0.475676\n","base_model_rouge2                                                0.142132\n","Finetuned_rouge2                                                 0.359551\n","4o_rouge2                                                        0.251366\n","base_model_rougeL                                                0.321608\n","Finetuned_rougeL                                                 0.444444\n","4o_rougeL                                                        0.367568\n","base_model_rougeLsum                                             0.321608\n","Finetuned_rougeLsum                                              0.444444\n","4o_rougeLsum                                                     0.367568\n","Name: 100, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nLisa: So Jake, how...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Conversation ...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJake shared details abo...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. travel_and_location.h...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   640.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Jake recently returned...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJake shared details ab...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJake recently traveled ...\n","base_model_rouge1                                                0.542373\n","Finetuned_rouge1                                                 0.506329\n","4o_rouge1                                                        0.478873\n","base_model_rouge2                                                0.205128\n","Finetuned_rouge2                                                 0.269231\n","4o_rouge2                                                        0.189573\n","base_model_rougeL                                                0.313559\n","Finetuned_rougeL                                                  0.35443\n","4o_rougeL                                                          0.2723\n","base_model_rougeLsum                                             0.313559\n","Finetuned_rougeLsum                                               0.35443\n","4o_rougeLsum                                                       0.2723\n","Name: 101, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nDaniel: **Hey Amir...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: **Casual conv...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nAmira recounted her Eur...\n","Violations              <BEGIN VIOLATIONS>\\n\\n    1. travel.high.hotel...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   732.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Amira and Daniel share...\n","summary_finetuned        <BEGIN SUMMARY>\\nAmira shared details about h...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAmira recently returned...\n","base_model_rouge1                                                0.486647\n","Finetuned_rouge1                                                 0.280702\n","4o_rouge1                                                         0.46729\n","base_model_rouge2                                                0.274627\n","Finetuned_rouge2                                                 0.071006\n","4o_rouge2                                                        0.216981\n","base_model_rougeL                                                0.356083\n","Finetuned_rougeL                                                  0.19883\n","4o_rougeL                                                        0.345794\n","base_model_rougeLsum                                             0.379822\n","Finetuned_rougeLsum                                               0.19883\n","4o_rougeLsum                                                     0.345794\n","Name: 102, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\n\\n\\n\\nSarah: Can't belie...\n","metadata                <BEGIN METADATA>\\n\\n\\n\\nContext: A casual conv...\n","summary                 <BEGIN SUMMARY>\\n\\n\\n\\nSarah and Tom are meeti...\n","Violations              <BEGIN VIOLATIONS>\\n\\n1. travel.high.hotel_boo...\n","Quality                               <BEGIN LABEL>\\n\\nBAD\\n\\n<END LABEL>\n","__index_level_0__                                                   814.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nTom shared his recent trip t...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSarah and Tom catch up ...\n","base_model_rouge1                                                 0.41543\n","Finetuned_rouge1                                                 0.432161\n","4o_rouge1                                                        0.469231\n","base_model_rouge2                                                0.137313\n","Finetuned_rouge2                                                 0.121827\n","4o_rouge2                                                        0.178295\n","base_model_rougeL                                                0.231454\n","Finetuned_rougeL                                                 0.251256\n","4o_rougeL                                                        0.276923\n","base_model_rougeLsum                                             0.225519\n","Finetuned_rougeLsum                                              0.251256\n","4o_rougeLsum                                                     0.276923\n","Name: 103, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nMichael: **Hey Cla...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: **Casual conv...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nMichael and Clara discu...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   630.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Clara and Michael disc...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nClara and Michael disc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nMichael and Clara discu...\n","base_model_rouge1                                                0.407143\n","Finetuned_rouge1                                                 0.505882\n","4o_rouge1                                                        0.482759\n","base_model_rouge2                                                0.115108\n","Finetuned_rouge2                                                 0.119048\n","4o_rouge2                                                        0.165217\n","base_model_rougeL                                                     0.2\n","Finetuned_rougeL                                                 0.270588\n","4o_rougeL                                                        0.293103\n","base_model_rougeLsum                                             0.214286\n","Finetuned_rougeLsum                                              0.270588\n","4o_rougeLsum                                                     0.293103\n","Name: 104, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nHannah: I just got...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nHannah recently returne...\n","Violations              <BEGIN VIOLATIONS>\\r\\n1. travel_and_location.h...\n","Quality                              <BEGIN LABEL>\\r\\nBAD \\r\\n<END LABEL>\n","__index_level_0__                                                   624.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Hannah recently return...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nHannah and Jake discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nHannah recently returne...\n","base_model_rouge1                                                0.512635\n","Finetuned_rouge1                                                 0.380952\n","4o_rouge1                                                        0.491379\n","base_model_rouge2                                                0.210909\n","Finetuned_rouge2                                                 0.064171\n","4o_rouge2                                                        0.165217\n","base_model_rougeL                                                0.368231\n","Finetuned_rougeL                                                  0.21164\n","4o_rougeL                                                        0.301724\n","base_model_rougeLsum                                              0.34657\n","Finetuned_rougeLsum                                               0.21164\n","4o_rougeLsum                                                     0.301724\n","Name: 105, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmma: **Hey John, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Discussion ab...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn shared details about h...\n","Violations              <BEGIN VIOLATIONS>\\n1. travel_and_location.hig...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   607.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n John enjoyed a luxurio...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn shared details ab...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Emma catch up ...\n","base_model_rouge1                                                0.529617\n","Finetuned_rouge1                                                 0.397959\n","4o_rouge1                                                        0.473684\n","base_model_rouge2                                                0.266667\n","Finetuned_rouge2                                                 0.185567\n","4o_rouge2                                                        0.166667\n","base_model_rougeL                                                0.432056\n","Finetuned_rougeL                                                 0.316327\n","4o_rougeL                                                        0.338346\n","base_model_rougeLsum                                             0.432056\n","Finetuned_rougeLsum                                              0.316327\n","4o_rougeLsum                                                     0.338346\n","Name: 106, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nMaria: So, Lucas, ...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nLucas shared his experi...\n","Violations                <BEGIN VIOLATIONS>\\r\\nNone.\\r\\n<END VIOLATIONS>\n","Quality                              <BEGIN LABEL>\\r\\nGOOD\\r\\n<END LABEL>\n","__index_level_0__                                                   629.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n During a conversation ...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nMaria and Lucas discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLucas recounted his rec...\n","base_model_rouge1                                                0.468468\n","Finetuned_rouge1                                                 0.542373\n","4o_rouge1                                                        0.486726\n","base_model_rouge2                                                0.145455\n","Finetuned_rouge2                                                 0.194286\n","4o_rouge2                                                        0.169643\n","base_model_rougeL                                                0.252252\n","Finetuned_rougeL                                                 0.350282\n","4o_rougeL                                                        0.327434\n","base_model_rougeLsum                                             0.252252\n","Finetuned_rougeLsum                                              0.350282\n","4o_rougeLsum                                                     0.327434\n","Name: 107, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nEmily: **Hey John,...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: **Casual conv...\n","summary                 <BEGIN SUMMARY>\\n\\nEmily and John discussed Li...\n","Violations              <BEGIN VIOLATIONS>\\n\\n\\t1. travel.high.hotel_b...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   595.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nEmily and John discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nEmily and John discuss ...\n","base_model_rouge1                                                0.513699\n","Finetuned_rouge1                                                 0.505051\n","4o_rouge1                                                        0.491228\n","base_model_rouge2                                                0.193103\n","Finetuned_rouge2                                                  0.27551\n","4o_rouge2                                                         0.20354\n","base_model_rougeL                                                0.253425\n","Finetuned_rougeL                                                 0.323232\n","4o_rougeL                                                        0.324561\n","base_model_rougeLsum                                             0.253425\n","Finetuned_rougeLsum                                              0.323232\n","4o_rougeLsum                                                     0.324561\n","Name: 108, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  \\r\\n<BEGIN CONVERSATION>\\r\\n\\r\\nJenna: **Hey M...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nJenna shared details of...\n","Violations              <BEGIN VIOLATIONS>\\n1. travel.high.travel_hist...\n","Quality                               <BEGIN LABEL>\\r\\nBAD\\r\\n<END LABEL>\n","__index_level_0__                                                   585.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJenna and Mark discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJenna and Mark discuss ...\n","base_model_rouge1                                                0.427481\n","Finetuned_rouge1                                                  0.50237\n","4o_rouge1                                                        0.520661\n","base_model_rouge2                                                0.130769\n","Finetuned_rouge2                                                 0.162679\n","4o_rouge2                                                        0.141667\n","base_model_rougeL                                                0.236641\n","Finetuned_rougeL                                                  0.28436\n","4o_rougeL                                                        0.297521\n","base_model_rougeLsum                                             0.236641\n","Finetuned_rougeLsum                                               0.28436\n","4o_rougeLsum                                                     0.297521\n","Name: 109, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\r\\n\\r\\nOlivia: **Hey Mark...\n","metadata                <BEGIN METADATA>\\r\\n\\r\\nContext: Casual conver...\n","summary                 <BEGIN SUMMARY>\\r\\n\\r\\nMark recently traveled ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                   603.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Mark and Olivia shared...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nMark and Olivia discus...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nOlivia and Mark discuss...\n","base_model_rouge1                                                0.467005\n","Finetuned_rouge1                                                  0.51462\n","4o_rouge1                                                        0.581633\n","base_model_rouge2                                                0.153846\n","Finetuned_rouge2                                                 0.142012\n","4o_rouge2                                                        0.309278\n","base_model_rougeL                                                0.294416\n","Finetuned_rougeL                                                 0.327485\n","4o_rougeL                                                        0.377551\n","base_model_rougeLsum                                             0.294416\n","Finetuned_rougeLsum                                              0.327485\n","4o_rougeLsum                                                     0.377551\n","Name: 110, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\nAnna: Next week is your ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Casual conversati...\n","summary                 <BEGIN SUMMARY>\\n\\nRyan, who is turning 9 soon...\n","Violations              <BEGIN VIOLATIONS>\\n1. Sexual Orientation and ...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                    19.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation abou...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAnna and Ryan are disc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nA playful conversation ...\n","base_model_rouge1                                                 0.44586\n","Finetuned_rouge1                                                 0.477876\n","4o_rouge1                                                        0.428571\n","base_model_rouge2                                                0.180645\n","Finetuned_rouge2                                                  0.18018\n","4o_rouge2                                                        0.144928\n","base_model_rougeL                                                0.292994\n","Finetuned_rougeL                                                 0.336283\n","4o_rougeL                                                        0.242857\n","base_model_rougeLsum                                             0.292994\n","Finetuned_rougeLsum                                              0.336283\n","4o_rougeLsum                                                     0.242857\n","Name: 111, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\nJohn: So it looks like w...\n","metadata                <BEGIN METADATA>\\n\\nContext: Discussion about ...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn and Chen are discussin...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    49.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In the conversation, J...\n","summary_finetuned        <BEGIN SUMMARY>\\nJohn and Chen are discussing...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo colleagues, John an...\n","base_model_rouge1                                                0.468619\n","Finetuned_rouge1                                                 0.493976\n","4o_rouge1                                                        0.512315\n","base_model_rouge2                                                0.219409\n","Finetuned_rouge2                                                 0.256098\n","4o_rouge2                                                        0.238806\n","base_model_rougeL                                                 0.32636\n","Finetuned_rougeL                                                 0.349398\n","4o_rougeL                                                        0.403941\n","base_model_rougeLsum                                              0.32636\n","Finetuned_rougeLsum                                              0.349398\n","4o_rougeLsum                                                     0.403941\n","Name: 112, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\nAlex: Dad, can I go to a...\n","metadata                <BEGIN METADATA>\\n\\nContext: Conversation betw...\n","summary                 <BEGIN SUMMARY>\\n\\nAlex asks their dad for per...\n","Violations              <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\\n\\...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    48.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlex and his dad discu...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlex asks her dad for p...\n","base_model_rouge1                                                0.401961\n","Finetuned_rouge1                                                 0.420382\n","4o_rouge1                                                        0.551351\n","base_model_rouge2                                                0.128713\n","Finetuned_rouge2                                                 0.206452\n","4o_rouge2                                                        0.295082\n","base_model_rougeL                                                0.264706\n","Finetuned_rougeL                                                 0.267516\n","4o_rougeL                                                        0.421622\n","base_model_rougeLsum                                             0.264706\n","Finetuned_rougeLsum                                              0.267516\n","4o_rougeLsum                                                     0.421622\n","Name: 113, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\nCarlos: I've heard that ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer inquirin...\n","summary                 <BEGIN SUMMARY>\\n\\nCarlos contacted Joan for m...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    12.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\nCarlos is planning to move f...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nCarlos contacted Joan's...\n","base_model_rouge1                                                 0.39548\n","Finetuned_rouge1                                                 0.503311\n","4o_rouge1                                                        0.497238\n","base_model_rouge2                                                0.114286\n","Finetuned_rouge2                                                 0.214765\n","4o_rouge2                                                        0.256983\n","base_model_rougeL                                                0.282486\n","Finetuned_rougeL                                                 0.384106\n","4o_rougeL                                                         0.39779\n","base_model_rougeLsum                                             0.282486\n","Finetuned_rougeLsum                                              0.384106\n","4o_rougeLsum                                                      0.39779\n","Name: 114, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nAlice: Are you excited a...\n","metadata                <BEGIN METADATA>\\n\\nContext: Casual conversati...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn is anxious about his u...\n","Violations              <BEGIN VIOLATIONS>\\n 1. healthcare.high.health...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    44.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlice and John discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlice and John discuss ...\n","base_model_rouge1                                                0.477419\n","Finetuned_rouge1                                                 0.439716\n","4o_rouge1                                                        0.607407\n","base_model_rouge2                                                0.235294\n","Finetuned_rouge2                                                 0.230216\n","4o_rouge2                                                        0.300752\n","base_model_rougeL                                                0.348387\n","Finetuned_rougeL                                                 0.326241\n","4o_rougeL                                                        0.533333\n","base_model_rougeLsum                                             0.348387\n","Finetuned_rougeLsum                                              0.326241\n","4o_rougeLsum                                                     0.533333\n","Name: 115, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\nDavid: This is a good ba...\n","metadata                <BEGIN METADATA>\\n\\nContext: In-store conversa...\n","summary                 <BEGIN SUMMARY>\\n\\nDavid and Alex discuss a co...\n","Violations              <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\\n\\...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                     5.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation abou...\n","summary_finetuned        <BEGIN SUMMARY>\\nDavid and Alex are discussin...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo individuals discuss...\n","base_model_rouge1                                                0.518519\n","Finetuned_rouge1                                                 0.628099\n","4o_rouge1                                                        0.641221\n","base_model_rouge2                                                  0.2625\n","Finetuned_rouge2                                                 0.336134\n","4o_rouge2                                                        0.356589\n","base_model_rougeL                                                0.444444\n","Finetuned_rougeL                                                 0.495868\n","4o_rougeL                                                        0.549618\n","base_model_rougeLsum                                             0.444444\n","Finetuned_rougeLsum                                              0.495868\n","4o_rougeLsum                                                     0.549618\n","Name: 116, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nAlice: So, how was your ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Conversation betw...\n","summary                 <BEGIN SUMMARY>\\n\\nMark recently returned from...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    17.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n During a casual conver...\n","summary_finetuned        <BEGIN SUMMARY>\\nMark shared his recent vacat...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlice asked Mark about ...\n","base_model_rouge1                                                0.567901\n","Finetuned_rouge1                                                 0.516129\n","4o_rouge1                                                         0.68323\n","base_model_rouge2                                                  0.2875\n","Finetuned_rouge2                                                 0.196721\n","4o_rouge2                                                         0.36478\n","base_model_rougeL                                                0.407407\n","Finetuned_rougeL                                                 0.403226\n","4o_rougeL                                                        0.559006\n","base_model_rougeLsum                                             0.407407\n","Finetuned_rougeLsum                                              0.403226\n","4o_rougeLsum                                                     0.559006\n","Name: 117, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nTan Ling: Excuse me. You...\n","metadata                <BEGIN METADATA>\\n\\nContext: Business meeting ...\n","summary                 <BEGIN SUMMARY>\\n\\nTan Ling, a source manager ...\n","Violations              <BEGIN VIOLATIONS>\\n1. travel_and_location.hig...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                    52.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a professional exch...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nTan Ling, the source manag...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTan Ling meets Mr. Gree...\n","base_model_rouge1                                                     0.5\n","Finetuned_rouge1                                                 0.520548\n","4o_rouge1                                                        0.505263\n","base_model_rouge2                                                     0.2\n","Finetuned_rouge2                                                 0.222222\n","4o_rouge2                                                        0.212766\n","base_model_rougeL                                                0.385417\n","Finetuned_rougeL                                                 0.328767\n","4o_rougeL                                                        0.326316\n","base_model_rougeLsum                                             0.385417\n","Finetuned_rougeLsum                                              0.328767\n","4o_rougeLsum                                                     0.326316\n","Name: 118, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nJohn: Here we come.\\nTax...\n","metadata                <BEGIN METADATA>\\n\\nContext: Taxi ride fare di...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn and a taxi driver disc...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                     3.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a private conversat...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn and the taxi driv...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nA customer named John a...\n","base_model_rouge1                                                     0.5\n","Finetuned_rouge1                                                     0.68\n","4o_rouge1                                                            0.58\n","base_model_rouge2                                                0.220339\n","Finetuned_rouge2                                                  0.44898\n","4o_rouge2                                                        0.367347\n","base_model_rougeL                                                0.383333\n","Finetuned_rougeL                                                      0.6\n","4o_rougeL                                                            0.52\n","base_model_rougeLsum                                             0.383333\n","Finetuned_rougeLsum                                                   0.6\n","4o_rougeLsum                                                         0.52\n","Name: 119, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\nGrace: Help! Are you a d...\n","metadata                <BEGIN METADATA>\\n\\nContext: Emergency medical...\n","summary                 <BEGIN SUMMARY>\\n\\nGrace sought urgent help fo...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    32.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a critical emergenc...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nGrace's pet is in crit...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nA distressed pet owner,...\n","base_model_rouge1                                                0.489796\n","Finetuned_rouge1                                                 0.549618\n","4o_rouge1                                                        0.426966\n","base_model_rouge2                                                0.164948\n","Finetuned_rouge2                                                 0.248062\n","4o_rouge2                                                           0.125\n","base_model_rougeL                                                0.326531\n","Finetuned_rougeL                                                 0.366412\n","4o_rougeL                                                        0.280899\n","base_model_rougeLsum                                             0.326531\n","Finetuned_rougeLsum                                              0.366412\n","4o_rougeLsum                                                     0.280899\n","Name: 120, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\nJohn: Hi, Mike. Haven't ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Casual conversati...\n","summary                 <BEGIN SUMMARY>\\n\\nMike and John discuss that ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    13.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a recent conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Mike are catc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nMike and John catch up ...\n","base_model_rouge1                                                0.296774\n","Finetuned_rouge1                                                  0.57377\n","4o_rouge1                                                        0.592593\n","base_model_rouge2                                                0.078431\n","Finetuned_rouge2                                                     0.25\n","4o_rouge2                                                        0.396226\n","base_model_rougeL                                                0.206452\n","Finetuned_rougeL                                                 0.409836\n","4o_rougeL                                                        0.555556\n","base_model_rougeLsum                                             0.206452\n","Finetuned_rougeLsum                                              0.409836\n","4o_rougeLsum                                                     0.555556\n","Name: 121, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\nAlice: Did Bean send the...\n","metadata                <BEGIN METADATA>\\n\\nContext: Discussion about ...\n","summary                 <BEGIN SUMMARY>\\n\\nAlice and Brian are discuss...\n","Violations              <BEGIN VIOLATIONS>\\n1. generic.high.government...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                     8.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Brian are di...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a conversation, Alic...\n","base_model_rouge1                                                0.355556\n","Finetuned_rouge1                                                 0.484848\n","4o_rouge1                                                        0.485981\n","base_model_rouge2                                                0.120301\n","Finetuned_rouge2                                                 0.268041\n","4o_rouge2                                                        0.266667\n","base_model_rougeL                                                0.266667\n","Finetuned_rougeL                                                  0.40404\n","4o_rougeL                                                         0.46729\n","base_model_rougeLsum                                             0.266667\n","Finetuned_rougeLsum                                               0.40404\n","4o_rougeLsum                                                      0.46729\n","Name: 122, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\nJohn: Mrs. Phoebe, let's...\n","metadata                <BEGIN METADATA>\\n\\nContext: Business Negotiat...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn and Mrs. Phoebe are di...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    26.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a private conversat...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Mrs. Phoebe d...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a business conversat...\n","base_model_rouge1                                                0.549763\n","Finetuned_rouge1                                                 0.611399\n","4o_rouge1                                                         0.52381\n","base_model_rouge2                                                0.258373\n","Finetuned_rouge2                                                 0.272251\n","4o_rouge2                                                        0.288462\n","base_model_rougeL                                                0.454976\n","Finetuned_rougeL                                                 0.435233\n","4o_rougeL                                                        0.409524\n","base_model_rougeLsum                                             0.454976\n","Finetuned_rougeLsum                                              0.435233\n","4o_rougeLsum                                                     0.409524\n","Name: 123, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\nAlice: Could you do me a...\n","metadata                <BEGIN METADATA>\\n\\nContext: Alice asking Bob ...\n","summary                 <BEGIN SUMMARY>\\n\\nAlice asked Bob to run to t...\n","Violations              <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\\n\\...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                     6.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a private conversat...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlice asks Bob to pick...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlice asks Bob to run a...\n","base_model_rouge1                                                0.294118\n","Finetuned_rouge1                                                 0.369565\n","4o_rouge1                                                         0.44186\n","base_model_rouge2                                                     0.1\n","Finetuned_rouge2                                                 0.177778\n","4o_rouge2                                                        0.261905\n","base_model_rougeL                                                0.254902\n","Finetuned_rougeL                                                 0.326087\n","4o_rougeL                                                         0.44186\n","base_model_rougeLsum                                             0.254902\n","Finetuned_rougeLsum                                              0.326087\n","4o_rougeLsum                                                      0.44186\n","Name: 124, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\nJohn: Good morning. I’m ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Interview about t...\n","summary                 <BEGIN SUMMARY>\\n\\nA New York book reviewer in...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    34.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nJohn from a book review ag...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nA journalist from the N...\n","base_model_rouge1                                                0.478049\n","Finetuned_rouge1                                                 0.554054\n","4o_rouge1                                                        0.701571\n","base_model_rouge2                                                0.246305\n","Finetuned_rouge2                                                 0.219178\n","4o_rouge2                                                        0.465608\n","base_model_rougeL                                                     0.4\n","Finetuned_rougeL                                                 0.432432\n","4o_rougeL                                                        0.628272\n","base_model_rougeLsum                                                  0.4\n","Finetuned_rougeLsum                                              0.432432\n","4o_rougeLsum                                                     0.628272\n","Name: 125, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\nJohn: Can I help you?\\nJ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Inquiry about job...\n","summary                 <BEGIN SUMMARY>\\n\\nJudy Liao visited John to v...\n","Violations              <BEGIN VIOLATIONS>\\n1. employment.high.credent...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                     4.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a privacy-preservin...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJudy visited John to i...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nA job applicant visited...\n","base_model_rouge1                                                     0.5\n","Finetuned_rouge1                                                 0.601307\n","4o_rouge1                                                        0.465116\n","base_model_rouge2                                                0.246914\n","Finetuned_rouge2                                                 0.264901\n","4o_rouge2                                                        0.223529\n","base_model_rougeL                                                0.365854\n","Finetuned_rougeL                                                 0.470588\n","4o_rougeL                                                        0.372093\n","base_model_rougeLsum                                             0.365854\n","Finetuned_rougeLsum                                              0.470588\n","4o_rougeLsum                                                     0.372093\n","Name: 126, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\nAlicia: How many people ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Casual conversati...\n","summary                 <BEGIN SUMMARY>\\n\\nJames and Alicia talk about...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    37.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\nJames and Alicia discuss the...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn this conversation, A...\n","base_model_rouge1                                                0.505618\n","Finetuned_rouge1                                                 0.586466\n","4o_rouge1                                                        0.413793\n","base_model_rouge2                                                0.136364\n","Finetuned_rouge2                                                 0.229008\n","4o_rouge2                                                        0.208955\n","base_model_rougeL                                                0.303371\n","Finetuned_rougeL                                                 0.360902\n","4o_rougeL                                                        0.246305\n","base_model_rougeLsum                                             0.303371\n","Finetuned_rougeLsum                                              0.360902\n","4o_rougeLsum                                                     0.246305\n","Name: 127, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\nOh, Linda. You must be s...\n","metadata                <BEGIN METADATA>\\n\\nContext: Discussion about ...\n","summary                 <BEGIN SUMMARY>\\n\\nLinda is excited about movi...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    24.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation abou...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nLinda is excited about...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLinda expresses her exc...\n","base_model_rouge1                                                 0.27972\n","Finetuned_rouge1                                                 0.561798\n","4o_rouge1                                                        0.348624\n","base_model_rouge2                                                0.070922\n","Finetuned_rouge2                                                 0.367816\n","4o_rouge2                                                        0.149533\n","base_model_rougeL                                                0.195804\n","Finetuned_rougeL                                                 0.494382\n","4o_rougeL                                                        0.293578\n","base_model_rougeLsum                                             0.195804\n","Finetuned_rougeLsum                                              0.494382\n","4o_rougeLsum                                                     0.293578\n","Name: 128, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\nAlice: I don't understan...\n","metadata                <BEGIN METADATA>\\n\\nContext: Discussion betwee...\n","summary                 <BEGIN SUMMARY>\\n\\nAlice is curious why Mr. Wa...\n","Violations              <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\\n\\...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    45.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\nAlice and Mr. Wang discuss h...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlice and Mr. Wang disc...\n","base_model_rouge1                                                0.395722\n","Finetuned_rouge1                                                 0.601399\n","4o_rouge1                                                        0.409091\n","base_model_rouge2                                                0.118919\n","Finetuned_rouge2                                                 0.241135\n","4o_rouge2                                                        0.119266\n","base_model_rougeL                                                0.224599\n","Finetuned_rougeL                                                 0.363636\n","4o_rougeL                                                        0.245455\n","base_model_rougeLsum                                             0.224599\n","Finetuned_rougeLsum                                              0.363636\n","4o_rougeLsum                                                     0.245455\n","Name: 129, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nAlex: Ladies and gentlem...\n","metadata                <BEGIN METADATA>\\n\\nContext: Discussion about ...\n","summary                 <BEGIN SUMMARY>\\n\\nAlex informs the group abou...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    33.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a privacy-preservin...\n","summary_finetuned        <BEGIN SUMMARY>\\nAlex and Jordan are discussi...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nAlex and Jordan discuss...\n","base_model_rouge1                                                0.455446\n","Finetuned_rouge1                                                 0.521739\n","4o_rouge1                                                        0.552381\n","base_model_rouge2                                                    0.16\n","Finetuned_rouge2                                                 0.163522\n","4o_rouge2                                                        0.221154\n","base_model_rougeL                                                0.356436\n","Finetuned_rougeL                                                 0.322981\n","4o_rougeL                                                        0.409524\n","base_model_rougeLsum                                             0.356436\n","Finetuned_rougeLsum                                              0.322981\n","4o_rougeLsum                                                     0.409524\n","Name: 130, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nWaiter: Are you ready to...\n","metadata                <BEGIN METADATA>\\n\\nContext: Restaurant orderi...\n","summary                 <BEGIN SUMMARY>\\n\\nA customer at a restaurant ...\n","Violations              <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\\n\\...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    50.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a dining conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nThe customer ordered a crab ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nA customer and a waiter...\n","base_model_rouge1                                                0.409836\n","Finetuned_rouge1                                                  0.45977\n","4o_rouge1                                                        0.442748\n","base_model_rouge2                                                0.166667\n","Finetuned_rouge2                                                 0.282353\n","4o_rouge2                                                        0.248062\n","base_model_rougeL                                                0.278689\n","Finetuned_rougeL                                                 0.436782\n","4o_rougeL                                                        0.351145\n","base_model_rougeLsum                                             0.278689\n","Finetuned_rougeLsum                                              0.436782\n","4o_rougeLsum                                                     0.351145\n","Name: 131, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nPerson1: What's all the ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Casual conversati...\n","summary                 <BEGIN SUMMARY>\\n\\nTwo individuals are at a ba...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    15.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a casual conversati...\n","summary_finetuned        <BEGIN SUMMARY>\\nJimmy and Person1 are at a b...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a casual conversatio...\n","base_model_rouge1                                                0.467066\n","Finetuned_rouge1                                                 0.533333\n","4o_rouge1                                                        0.582857\n","base_model_rouge2                                                0.169697\n","Finetuned_rouge2                                                 0.237288\n","4o_rouge2                                                        0.358382\n","base_model_rougeL                                                0.323353\n","Finetuned_rougeL                                                 0.433333\n","4o_rougeL                                                        0.434286\n","base_model_rougeLsum                                             0.323353\n","Finetuned_rougeLsum                                              0.433333\n","4o_rougeLsum                                                     0.434286\n","Name: 132, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                          Family and Relationships\n","dialog                  <BEGIN CONVERSATION>\\nJohn: How old is Keith?\\...\n","metadata                <BEGIN METADATA>\\n\\nContext: Casual conversati...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn and Carol discuss the ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                     9.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a private conversat...\n","summary_finetuned        <BEGIN SUMMARY>\\nJohn and Carol discuss the r...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Carol discusse...\n","base_model_rouge1                                                0.461538\n","Finetuned_rouge1                                                  0.45283\n","4o_rouge1                                                        0.447368\n","base_model_rouge2                                                0.167665\n","Finetuned_rouge2                                                 0.211538\n","4o_rouge2                                                            0.16\n","base_model_rougeL                                                0.331361\n","Finetuned_rougeL                                                 0.339623\n","4o_rougeL                                                        0.342105\n","base_model_rougeLsum                                             0.331361\n","Finetuned_rougeLsum                                              0.339623\n","4o_rougeLsum                                                     0.342105\n","Name: 133, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                        Employment\n","dialog                  <BEGIN CONVERSATION>\\nJane: Have you had any e...\n","metadata                <BEGIN METADATA>\\n\\nContext: Job interview con...\n","summary                 <BEGIN SUMMARY>\\n\\nTom has prior sales experie...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    16.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation abou...\n","summary_finetuned        <BEGIN SUMMARY>\\nJane and Tom discuss Tom's p...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTom discussed his previ...\n","base_model_rouge1                                                 0.45283\n","Finetuned_rouge1                                                    0.576\n","4o_rouge1                                                        0.653846\n","base_model_rouge2                                                0.152866\n","Finetuned_rouge2                                                 0.211382\n","4o_rouge2                                                        0.441558\n","base_model_rougeL                                                0.301887\n","Finetuned_rougeL                                                    0.432\n","4o_rougeL                                                        0.628205\n","base_model_rougeLsum                                             0.301887\n","Finetuned_rougeLsum                                                 0.432\n","4o_rougeLsum                                                     0.628205\n","Name: 134, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Healthcare Settings\n","dialog                  <BEGIN CONVERSATION>\\nChris: Why don't you wat...\n","metadata                <BEGIN METADATA>\\n\\nContext: Conversation betw...\n","summary                 <BEGIN SUMMARY>\\n\\nChris and Jordan were invol...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    30.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a vehicular inciden...\n","summary_finetuned        <BEGIN SUMMARY>\\nChris and Jordan are arguing...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nTwo individuals, Chris ...\n","base_model_rouge1                                                0.485437\n","Finetuned_rouge1                                                 0.468085\n","4o_rouge1                                                        0.537445\n","base_model_rouge2                                                0.196078\n","Finetuned_rouge2                                                 0.201439\n","4o_rouge2                                                        0.248889\n","base_model_rougeL                                                0.300971\n","Finetuned_rougeL                                                 0.312057\n","4o_rougeL                                                        0.405286\n","base_model_rougeLsum                                             0.300971\n","Finetuned_rougeLsum                                              0.312057\n","4o_rougeLsum                                                     0.405286\n","Name: 135, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nJohn: Now I understand. ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Casual conversati...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn and Emily discuss what...\n","Violations              <BEGIN VIOLATIONS>\\n1. finances.high.insurance...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                    36.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn and Emily discuss...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a recent conversatio...\n","base_model_rouge1                                                0.437158\n","Finetuned_rouge1                                                 0.537931\n","4o_rouge1                                                        0.445596\n","base_model_rouge2                                                0.132597\n","Finetuned_rouge2                                                 0.307692\n","4o_rouge2                                                        0.167539\n","base_model_rougeL                                                0.327869\n","Finetuned_rougeL                                                 0.482759\n","4o_rougeL                                                        0.352332\n","base_model_rougeLsum                                             0.327869\n","Finetuned_rougeLsum                                              0.482759\n","4o_rougeLsum                                                     0.352332\n","Name: 136, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                         Education\n","dialog                  <BEGIN CONVERSATION>\\nAlicia: Would you talk t...\n","metadata                <BEGIN METADATA>\\n\\nContext: Discussion betwee...\n","summary                 <BEGIN SUMMARY>\\n\\nAlicia is considering takin...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. employment.work_histo...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                    25.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nAlicia and Jordan disc...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a conversation about...\n","base_model_rouge1                                                0.376238\n","Finetuned_rouge1                                                 0.466667\n","4o_rouge1                                                         0.54878\n","base_model_rouge2                                                    0.12\n","Finetuned_rouge2                                                 0.169492\n","4o_rouge2                                                        0.259259\n","base_model_rougeL                                                0.287129\n","Finetuned_rougeL                                                 0.316667\n","4o_rougeL                                                        0.414634\n","base_model_rougeLsum                                             0.287129\n","Finetuned_rougeLsum                                              0.316667\n","4o_rougeLsum                                                     0.414634\n","Name: 137, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nStacy: Hello, if my flig...\n","metadata                <BEGIN METADATA>\\n\\nContext: **Customer servic...\n","summary                 <BEGIN SUMMARY>\\n\\nStacy is worried about miss...\n","Violations              <BEGIN VIOLATIONS>\\n    1. travel.high.modes_o...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                    31.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nStacy is concerned abo...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nStacy inquired about th...\n","base_model_rouge1                                                0.476636\n","Finetuned_rouge1                                                 0.550725\n","4o_rouge1                                                        0.487047\n","base_model_rouge2                                                0.188679\n","Finetuned_rouge2                                                 0.264706\n","4o_rouge2                                                        0.209424\n","base_model_rougeL                                                0.336449\n","Finetuned_rougeL                                                 0.449275\n","4o_rougeL                                                        0.352332\n","base_model_rougeLsum                                             0.336449\n","Finetuned_rougeLsum                                              0.449275\n","4o_rougeLsum                                                     0.352332\n","Name: 138, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\nLucinda: Absolutely appa...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer complain...\n","summary                 <BEGIN SUMMARY>\\n\\nLucinda is outraged by Tesc...\n","Violations              <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\\n\\...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                     5.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a discussion about ...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nLucinda expressed her ...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nLucinda expressed frust...\n","base_model_rouge1                                                0.378151\n","Finetuned_rouge1                                                 0.422222\n","4o_rouge1                                                        0.479263\n","base_model_rouge2                                                 0.09322\n","Finetuned_rouge2                                                 0.089888\n","4o_rouge2                                                        0.130233\n","base_model_rougeL                                                0.226891\n","Finetuned_rougeL                                                 0.266667\n","4o_rougeL                                                        0.304147\n","base_model_rougeLsum                                             0.226891\n","Finetuned_rougeLsum                                              0.266667\n","4o_rougeLsum                                                     0.304147\n","Name: 139, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\nXan: Waited in all day f...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer complain...\n","summary                 <BEGIN SUMMARY>\\n\\nA user named Xan expressed ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    32.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation abou...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nXan is frustrated beca...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nXan expressed frustrati...\n","base_model_rouge1                                                 0.41791\n","Finetuned_rouge1                                                 0.550898\n","4o_rouge1                                                        0.480874\n","base_model_rouge2                                                0.160804\n","Finetuned_rouge2                                                 0.266667\n","4o_rouge2                                                        0.176796\n","base_model_rougeL                                                0.318408\n","Finetuned_rougeL                                                 0.347305\n","4o_rougeL                                                        0.327869\n","base_model_rougeLsum                                             0.318408\n","Finetuned_rougeLsum                                              0.347305\n","4o_rougeLsum                                                     0.327869\n","Name: 140, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nNatasha: Hello, assuming...\n","metadata                <BEGIN METADATA>\\n\\nContext: A conversation di...\n","summary                 <BEGIN SUMMARY>\\n\\nNatasha is frustrated with ...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. travel.high.travel_hi...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                    13.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation abou...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nNatasha is experiencin...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nNatasha expressed frust...\n","base_model_rouge1                                                0.452229\n","Finetuned_rouge1                                                  0.43617\n","4o_rouge1                                                        0.477366\n","base_model_rouge2                                                0.108974\n","Finetuned_rouge2                                                 0.129032\n","4o_rouge2                                                        0.149378\n","base_model_rougeL                                                0.191083\n","Finetuned_rougeL                                                 0.244681\n","4o_rougeL                                                        0.255144\n","base_model_rougeLsum                                             0.242038\n","Finetuned_rougeLsum                                              0.244681\n","4o_rougeLsum                                                     0.255144\n","Name: 141, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nHamish: Hello, can you h...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer service ...\n","summary                 <BEGIN SUMMARY>\\n\\nHamish expressed frustratio...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    19.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nHamish is frustrated w...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nHamish reached out to a...\n","base_model_rouge1                                                0.456621\n","Finetuned_rouge1                                                 0.540541\n","4o_rouge1                                                        0.557214\n","base_model_rouge2                                                0.184332\n","Finetuned_rouge2                                                 0.205479\n","4o_rouge2                                                        0.261307\n","base_model_rougeL                                                0.328767\n","Finetuned_rougeL                                                 0.364865\n","4o_rougeL                                                         0.40796\n","base_model_rougeLsum                                             0.328767\n","Finetuned_rougeLsum                                              0.364865\n","4o_rougeLsum                                                      0.40796\n","Name: 142, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nJacqueline: Hello, I'm n...\n","metadata                <BEGIN METADATA>\\n\\nContext: Conversation rega...\n","summary                 <BEGIN SUMMARY>\\n\\nJacqueline missed her conne...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    49.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a privacy-preservin...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nJacqueline is experiencing...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJacqueline contacted LC...\n","base_model_rouge1                                                0.325301\n","Finetuned_rouge1                                                 0.432432\n","4o_rouge1                                                        0.423529\n","base_model_rouge2                                                0.060976\n","Finetuned_rouge2                                                 0.164384\n","4o_rouge2                                                        0.166667\n","base_model_rougeL                                                0.240964\n","Finetuned_rougeL                                                 0.351351\n","4o_rougeL                                                        0.329412\n","base_model_rougeLsum                                             0.240964\n","Finetuned_rougeLsum                                              0.351351\n","4o_rougeLsum                                                     0.329412\n","Name: 143, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nMaia: Hello, asking your...\n","metadata                <BEGIN METADATA>\\n\\nContext: Feedback and grie...\n","summary                 <BEGIN SUMMARY>\\n\\nMaia expressed frustration ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    41.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n During a holiday seaso...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nMaia expressed frustra...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nMaia expressed frustrat...\n","base_model_rouge1                                                0.446352\n","Finetuned_rouge1                                                 0.554913\n","4o_rouge1                                                        0.512821\n","base_model_rouge2                                                0.164502\n","Finetuned_rouge2                                                 0.233918\n","4o_rouge2                                                        0.238342\n","base_model_rougeL                                                0.257511\n","Finetuned_rougeL                                                 0.346821\n","4o_rougeL                                                             0.4\n","base_model_rougeLsum                                             0.257511\n","Finetuned_rougeLsum                                              0.346821\n","4o_rougeLsum                                                          0.4\n","Name: 144, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nJason: So my MyChoice sc...\n","metadata                <BEGIN METADATA>\\n\\nContext: Complaint about a...\n","summary                 <BEGIN SUMMARY>\\n\\nJason's MyChoice delivery w...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    26.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Jason experienced sign...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJason experienced mult...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJason experienced signi...\n","base_model_rouge1                                                0.429448\n","Finetuned_rouge1                                                 0.468085\n","4o_rouge1                                                        0.452055\n","base_model_rouge2                                                0.198758\n","Finetuned_rouge2                                                 0.230216\n","4o_rouge2                                                        0.236111\n","base_model_rougeL                                                0.355828\n","Finetuned_rougeL                                                 0.382979\n","4o_rougeL                                                        0.369863\n","base_model_rougeLsum                                             0.355828\n","Finetuned_rougeLsum                                              0.382979\n","4o_rougeLsum                                                     0.369863\n","Name: 145, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\nJames: AT WHAT POINT CAN...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer support ...\n","summary                 <BEGIN SUMMARY>\\n\\nJames is experiencing frequ...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    43.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n James experienced buff...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nJames is experiencing buff...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJames reported persiste...\n","base_model_rouge1                                                0.502994\n","Finetuned_rouge1                                                 0.587302\n","4o_rouge1                                                        0.493671\n","base_model_rouge2                                                0.169697\n","Finetuned_rouge2                                                 0.225806\n","4o_rouge2                                                        0.205128\n","base_model_rougeL                                                0.335329\n","Finetuned_rougeL                                                 0.428571\n","4o_rougeL                                                        0.379747\n","base_model_rougeLsum                                             0.335329\n","Finetuned_rougeLsum                                              0.428571\n","4o_rougeLsum                                                     0.379747\n","Name: 146, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\nJohn: Please help, my ne...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer service ...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn is frustrated with ong...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    12.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n John is experiencing r...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn is experiencing i...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nA frustrated customer, ...\n","base_model_rouge1                                                0.494118\n","Finetuned_rouge1                                                 0.522388\n","4o_rouge1                                                        0.448087\n","base_model_rouge2                                                0.214286\n","Finetuned_rouge2                                                 0.227273\n","4o_rouge2                                                        0.198895\n","base_model_rougeL                                                0.341176\n","Finetuned_rougeL                                                 0.447761\n","4o_rougeL                                                        0.349727\n","base_model_rougeLsum                                             0.341176\n","Finetuned_rougeLsum                                              0.447761\n","4o_rougeLsum                                                     0.349727\n","Name: 147, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                      Social Media\n","dialog                  <BEGIN CONVERSATION>\\nJoliz: I am having the m...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer support ...\n","summary                 <BEGIN SUMMARY>\\n\\nJoliz experienced frustrati...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    52.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Joliz expressed frustr...\n","summary_finetuned        <BEGIN SUMMARY>\\n\\nJoliz is frustrated with A...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJoliz expressed frustra...\n","base_model_rouge1                                                0.494845\n","Finetuned_rouge1                                                 0.426966\n","4o_rouge1                                                        0.454976\n","base_model_rouge2                                                0.145833\n","Finetuned_rouge2                                                 0.113636\n","4o_rouge2                                                        0.172249\n","base_model_rougeL                                                0.268041\n","Finetuned_rougeL                                                 0.280899\n","4o_rougeL                                                        0.350711\n","base_model_rougeLsum                                             0.268041\n","Finetuned_rougeLsum                                              0.280899\n","4o_rougeLsum                                                     0.350711\n","Name: 148, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nChris: Cancelled flight ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Discussion about ...\n","summary                 <BEGIN SUMMARY>\\n\\nChris is highly dissatisfie...\n","Violations              <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\\n\\...\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                     3.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nChris experienced mult...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nChris experiences signi...\n","base_model_rouge1                                                0.519608\n","Finetuned_rouge1                                                 0.444444\n","4o_rouge1                                                        0.466019\n","base_model_rouge2                                                0.188119\n","Finetuned_rouge2                                                  0.16129\n","4o_rouge2                                                        0.166667\n","base_model_rougeL                                                0.323529\n","Finetuned_rougeL                                                 0.285714\n","4o_rougeL                                                        0.300971\n","base_model_rougeLsum                                             0.323529\n","Finetuned_rougeLsum                                              0.285714\n","4o_rougeLsum                                                     0.300971\n","Name: 149, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nElin: Hi, how may we ass...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer support ...\n","summary                 <BEGIN SUMMARY>\\n\\nA customer contacted Elin t...\n","Violations              <BEGIN VIOLATIONS>\\n1. travel_and_location.hig...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                    33.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a privacy-preservin...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nThe customer is inquir...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nA customer inquired abo...\n","base_model_rouge1                                                0.561798\n","Finetuned_rouge1                                                 0.540541\n","4o_rouge1                                                        0.719577\n","base_model_rouge2                                                0.204545\n","Finetuned_rouge2                                                 0.260274\n","4o_rouge2                                                        0.470588\n","base_model_rougeL                                                0.382022\n","Finetuned_rougeL                                                 0.432432\n","4o_rougeL                                                        0.613757\n","base_model_rougeLsum                                             0.382022\n","Finetuned_rougeLsum                                              0.432432\n","4o_rougeLsum                                                     0.613757\n","Name: 150, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\nMuyiwa: Is this how you ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Conversation betw...\n","summary                 <BEGIN SUMMARY>\\n\\nMuyiwa expressed frustratio...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    34.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nMuyiwa expressed frust...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nIn a conversation, Muyi...\n","base_model_rouge1                                                    0.47\n","Finetuned_rouge1                                                 0.567742\n","4o_rouge1                                                        0.552083\n","base_model_rouge2                                                0.151515\n","Finetuned_rouge2                                                 0.313725\n","4o_rouge2                                                        0.294737\n","base_model_rougeL                                                    0.28\n","Finetuned_rougeL                                                 0.425806\n","4o_rougeL                                                        0.427083\n","base_model_rougeLsum                                                 0.28\n","Finetuned_rougeLsum                                              0.425806\n","4o_rougeLsum                                                     0.427083\n","Name: 151, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\nDimitar: Hello, I bought...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer support ...\n","summary                 <BEGIN SUMMARY>\\n\\nDimitar contacted the store...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                     8.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n Dimitar contacted the ...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nDimitar purchased a Ce...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nDimitar reached out for...\n","base_model_rouge1                                                     0.5\n","Finetuned_rouge1                                                 0.525641\n","4o_rouge1                                                         0.52381\n","base_model_rouge2                                                0.208791\n","Finetuned_rouge2                                                 0.220779\n","4o_rouge2                                                        0.192771\n","base_model_rougeL                                                0.326087\n","Finetuned_rougeL                                                 0.384615\n","4o_rougeL                                                        0.309524\n","base_model_rougeLsum                                             0.326087\n","Finetuned_rougeLsum                                              0.384615\n","4o_rougeLsum                                                     0.309524\n","Name: 152, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nSarah: Thank you... Flig...\n","metadata                <BEGIN METADATA>\\n\\nContext: Complaint and reb...\n","summary                 <BEGIN SUMMARY>\\n\\nSarah's flight was canceled...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    17.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nSarah is frustrated be...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nSarah experienced frust...\n","base_model_rouge1                                                0.395349\n","Finetuned_rouge1                                                    0.375\n","4o_rouge1                                                        0.479452\n","base_model_rouge2                                                0.105882\n","Finetuned_rouge2                                                 0.112676\n","4o_rouge2                                                        0.222222\n","base_model_rougeL                                                0.255814\n","Finetuned_rougeL                                                 0.305556\n","4o_rougeL                                                        0.369863\n","base_model_rougeLsum                                             0.255814\n","Finetuned_rougeLsum                                              0.305556\n","4o_rougeLsum                                                     0.369863\n","Name: 153, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nDan: Hello, how long is ...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer service ...\n","summary                 <BEGIN SUMMARY>\\n\\nDan expressed frustration o...\n","Violations              <BEGIN VIOLATIONS>\\n1. generic.high.authorizat...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                     6.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation rega...\n","summary_finetuned        <BEGIN SUMMARY>\\nDan is frustrated because hi...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nDan is frustrated becau...\n","base_model_rouge1                                                0.381743\n","Finetuned_rouge1                                                 0.337079\n","4o_rouge1                                                         0.47541\n","base_model_rouge2                                                0.108787\n","Finetuned_rouge2                                                 0.113636\n","4o_rouge2                                                        0.247934\n","base_model_rougeL                                                0.240664\n","Finetuned_rougeL                                                 0.213483\n","4o_rougeL                                                        0.352459\n","base_model_rougeLsum                                             0.240664\n","Finetuned_rougeLsum                                              0.213483\n","4o_rougeLsum                                                     0.352459\n","Name: 154, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                                          Finances\n","dialog                  <BEGIN CONVERSATION>\\nRahul: Hey! Amazon pantr...\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer service ...\n","summary                 <BEGIN SUMMARY>\\n\\nRahul contacted Amazon supp...\n","Violations              <BEGIN VIOLATIONS>\\n\\t1. Generic.High Sensitiv...\n","Quality                                   <BEGIN LABEL>\\nBAD\\n<END LABEL>\n","__index_level_0__                                                     4.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a privacy-preservin...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nRahul contacted an age...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nRahul reported that his...\n","base_model_rouge1                                                0.415301\n","Finetuned_rouge1                                                 0.378049\n","4o_rouge1                                                        0.476744\n","base_model_rouge2                                                0.154696\n","Finetuned_rouge2                                                 0.123457\n","4o_rouge2                                                        0.258824\n","base_model_rougeL                                                0.273224\n","Finetuned_rougeL                                                 0.280488\n","4o_rougeL                                                        0.383721\n","base_model_rougeLsum                                             0.273224\n","Finetuned_rougeLsum                                              0.280488\n","4o_rougeLsum                                                     0.383721\n","Name: 155, dtype: object\n"]},{"name":"stderr","output_type":"stream","text":["/home/t-ppurkayast/work/email/email/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["setting                                               Travel and Location\n","dialog                  <BEGIN CONVERSATION>\\nJohn: Here we are again....\n","metadata                <BEGIN METADATA>\\n\\nContext: Customer support ...\n","summary                 <BEGIN SUMMARY>\\n\\nJohn reported losing all hi...\n","Violations                    <BEGIN VIOLATIONS>\\nNone.\\n<END VIOLATIONS>\n","Quality                                  <BEGIN LABEL>\\nGOOD\\n<END LABEL>\n","__index_level_0__                                                    47.0\n","summary_base_model      <BEGIN SUMMARY>\\r\\n\\r\\n In a conversation betw...\n","summary_finetuned        <BEGIN SUMMARY>\\r\\n\\r\\nJohn is experiencing a...\n","summary_4o              <BEGIN SUMMARY>\\r\\n\\r\\nJohn reported losing al...\n","base_model_rouge1                                                0.436782\n","Finetuned_rouge1                                                 0.606061\n","4o_rouge1                                                        0.654321\n","base_model_rouge2                                                0.244186\n","Finetuned_rouge2                                                 0.338462\n","4o_rouge2                                                           0.425\n","base_model_rougeL                                                0.413793\n","Finetuned_rougeL                                                      0.5\n","4o_rougeL                                                        0.555556\n","base_model_rougeLsum                                             0.413793\n","Finetuned_rougeLsum                                                   0.5\n","4o_rougeLsum                                                     0.555556\n","Name: 156, dtype: object\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[32], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Apply the ROUGE calculation for each row in the dataframe\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_rouge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Save the final dataset with ROUGE scores\u001b[39;00m\n\u001b[1;32m     97\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./splits/final_test_rouge.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","Cell \u001b[0;32mIn[32], line 47\u001b[0m, in \u001b[0;36mcalculate_rouge\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     40\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [ \n\u001b[1;32m     41\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}, \n\u001b[1;32m     42\u001b[0m ]     \n\u001b[1;32m     43\u001b[0m     messages2 \u001b[38;5;241m=\u001b[39m [ \n\u001b[1;32m     44\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt2}, \n\u001b[1;32m     45\u001b[0m ] \n\u001b[0;32m---> 47\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhywaygpt4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# model = \"deployment_name\".\u001b[39;49;00m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m# Generate the summary using the pipe function\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     generated_summary \u001b[38;5;241m=\u001b[39m pipe(messages, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgeneration_args) [\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# assuming the generated text is in this format\u001b[39;00m\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/openai/resources/chat/completions.py:646\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    645\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/openai/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/openai/_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    975\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 978\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    984\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n","File \u001b[0;32m~/work/email/email/lib/python3.12/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.12/ssl.py:1233\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1230\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1231\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1232\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n","File \u001b[0;32m~/miniconda3/lib/python3.12/ssl.py:1106\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import pandas as pd\n","from datasets import load_metric,Dataset, concatenate_datasets\n","import random\n","import torch \n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n","import pandas as pd\n","from azure.identity import AzureCliCredential, get_bearer_token_provider\n","from openai import AzureOpenAI\n","import re\n","\n","token_provider = get_bearer_token_provider(\n","    AzureCliCredential(), \"https://cognitiveservices.azure.com/.default\"\n",")\n","\n","client = AzureOpenAI(\n","    # api_version=\"2023-03-15-preview\",\n","    api_version=\"2024-02-15-preview\",\n","    azure_endpoint=\"https://hywayllm-gpt4.openai.azure.com/\",\n","    azure_ad_token_provider=token_provider\n",")\n","\n","\n","# Load the dataset\n","file_path = './splits/final_test_split.csv'  # Replace with the actual file path\n","df = pd.read_csv(file_path)\n","\n","# Load the rouge metric\n","rouge_metric = load_metric(\"rouge\", trust_remote_code=True)\n","torch.random.manual_seed(0) \n","\n","def calculate_rouge(row):\n","    dialog = row['dialog']\n","    true_summary = row['summary']\n","\n","    rv= ''' Provide a privacy preserving summary for the following conversation - '''\n","    rv2= ''' Provide a privacy preserving summary for the following conversation in about 50-200 words - '''\n","    prompt = f''' {rv} \\n {dialog}'''\n","    prompt2 = f''' {rv2} \\n {dialog}'''\n","\n","    messages = [ \n","    {\"role\": \"user\", \"content\": prompt}, \n","]     \n","    messages2 = [ \n","    {\"role\": \"user\", \"content\": prompt2}, \n","] \n","\n","    response = client.chat.completions.create(\n","    model=\"hywaygpt4o\", # model = \"deployment_name\".\n","    messages=messages2)\n","\n","    # Generate the summary using the pipe function\n","    generated_summary = pipe(messages, **generation_args) [0]['generated_text']  # assuming the generated text is in this format\n","    generated_summary2 = f\"<BEGIN SUMMARY>\\r\\n\\r\\n{pipe2(messages2, **generation_args) [0]['generated_text']}\\r\\n\\r\\n<END SUMMARY>\" # assuming the generated text is in this format\n","    \n","\n","    # Append the dialog and summary to the result DataFrame\n","    text= response.choices[0].message.content\n","    \n","    generated_summary3 = f\"<BEGIN SUMMARY>\\r\\n\\r\\n{text}\\r\\n\\r\\n<END SUMMARY>\" # assuming the generated text is in this format\n","\n","    # Compute ROUGE scores\n","    rouge_scores = rouge_metric.compute(predictions=[generated_summary], references=[true_summary])\n","    rouge_scores2 = rouge_metric.compute(predictions=[generated_summary2], references=[true_summary])\n","    rouge_scores3 = rouge_metric.compute(predictions=[generated_summary3], references=[true_summary])\n","    \n","    # Extract ROUGE scores (R1, R2, RL, RLsum)\n","\n","    row['summary_base_model']= generated_summary2\n","    row['summary_finetuned']= generated_summary\n","    row['summary_4o']= generated_summary3\n","\n","    row['base_model_rouge1'] = rouge_scores2['rouge1'].mid.fmeasure\n","    row['Finetuned_rouge1'] = rouge_scores['rouge1'].mid.fmeasure\n","    row['4o_rouge1'] = rouge_scores3['rouge1'].mid.fmeasure\n","\n","    row['base_model_rouge2'] = rouge_scores2['rouge2'].mid.fmeasure\n","    row['Finetuned_rouge2'] = rouge_scores['rouge2'].mid.fmeasure\n","    row['4o_rouge2'] = rouge_scores3['rouge2'].mid.fmeasure\n","\n","    row['base_model_rougeL'] = rouge_scores2['rougeL'].mid.fmeasure\n","    row['Finetuned_rougeL'] = rouge_scores['rougeL'].mid.fmeasure\n","    row['4o_rougeL'] = rouge_scores3['rougeL'].mid.fmeasure\n","\n","\n","    row['base_model_rougeLsum'] = rouge_scores2['rougeLsum'].mid.fmeasure if 'rougeLsum' in rouge_scores2 else None\n","    row['Finetuned_rougeLsum'] = rouge_scores['rougeLsum'].mid.fmeasure if 'rougeLsum' in rouge_scores else None\n","    row['4o_rougeLsum'] = rouge_scores3['rougeLsum'].mid.fmeasure if 'rougeLsum' in rouge_scores3 else None\n","\n","    print(row)\n","    \n","    return row\n","\n","# Apply the ROUGE calculation for each row in the dataframe\n","df = df.apply(calculate_rouge, axis=1)\n","\n","# Save the final dataset with ROUGE scores\n","df.to_csv('./splits/final_test_rouge.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import re\n","import pandas as pd\n","from datasets import load_metric,Dataset, concatenate_datasets\n","import random\n","import torch \n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n","import pandas as pd\n","from azure.identity import AzureCliCredential, get_bearer_token_provider\n","from openai import AzureOpenAI\n","import re\n","\n","token_provider = get_bearer_token_provider(\n","    AzureCliCredential(), \"https://cognitiveservices.azure.com/.default\"\n",")\n","\n","client = AzureOpenAI(\n","    # api_version=\"2023-03-15-preview\",\n","    api_version=\"2024-02-15-preview\",\n","    azure_endpoint=\"https://hywayllm-gpt4.openai.azure.com/\",\n","    azure_ad_token_provider=token_provider\n",")\n","\n","# Load the dataset\n","file_path = './splits/final_test_rouge.csv'  # Replace with the actual file path\n","df = pd.read_csv(file_path)\n","def calculate_metrics(row):\n","    print(\"IN\")\n","    dialog = row['summary']\n","\n","    rv= ''' Identify and return BOTH the label and the violations in the privacy preserving summary given below. LABEL CAN ONLY BE \"GOOD\" OR \"BAD\", NOTHING ELSE. IF LABEL IS \"GOOD\", THEN VIOLATIONS CAN ONLY BE \"None.\". State the violations by sticking to the Taxonomy provided earlier.\n","    \n","    This is the response output structure to be followed-\n","    \n","    <BEGIN STRUCTURE>\n","\n","        <BEGIN LABEL>\n","        Enter Label here (ONLY CAN BE GOOD or BAD, NO OTHER VALUES ALLOWED)\n","        <END LABEL>\n","\n","        <BEGIN VIOLATIONS>\n","        Enter Violations here (if Label is GOOD CAN ONLY BE \"None.\")\n","        <END VIOLATIONS>\n","\n","    <END STRUCTURE>\n","\n","    MANDATORILY FOLLOW THIS STRUCTURE WHEN GENERATING RESPONSE. LABEL CAN ONLY BE GOOD OR BAD, NO OTHER VALUES ALLOWED. IF LABEL IS GOOD THEN VIOLATIONS CAN ONLY BE \"None.\". MAKE SURE THAT THE RESPONSE STRUCTURE IS COMPULSORILY FOLLOWED AND HAS BOTH LABEL AND VIOLATIONS.\n","    '''\n","    rv2= rv\n","    prompt = f''' {rv} \\n {dialog}'''\n","    prompt2 = f''' {rv2} \\n {dialog}'''\n","\n","    messages = [ \n","    {\"role\": \"system\", \"content\": taxo}, \n","    {\"role\": \"user\", \"content\": prompt}, \n","]     \n","    messages2 = [ \n","    {\"role\": \"system\", \"content\": taxo}, \n","    {\"role\": \"user\", \"content\": prompt2}, \n","] \n","    \n","    response = client.chat.completions.create(\n","    model=\"hywaygpt4o\", # model = \"deployment_name\".\n","    messages=messages2)\n","\n","    # Append the dialog and summary to the result DataFrame\n","    generated_response3= response.choices[0].message.content\n","\n","    # Generate the summary using the pipe function\n","    print(\"GEN1 START\")\n","    generated_response = pipe(messages, **generation_args) [0]['generated_text']  # assuming the generated text is in this format\n","    print(\"GEN1 DONE\")\n","    generated_response2 = pipe2(messages2, **generation_args) [0]['generated_text'] # assuming the generated text is in this format\n","    print(\"GEN2 DONE\")\n","\n","    print(\"FT: \\n\",generated_response )\n","    print(\"BM: \\n\",generated_response2 )\n","    print(\"4o: \\n\",generated_response3 )\n","\n","\n","\t# Regular expression patterns to extract labels and violations\n","    label_pattern = r\"(<BEGIN LABEL>.*?<END LABEL>)\"\n","    violations_pattern = r\"(<BEGIN VIOLATIONS>.*?<END VIOLATIONS>)\"\n","\n","\t# Find matches using the regular expression patterns\n","    label_match = re.search(label_pattern, generated_response, re.DOTALL)\n","    violations_match = re.search(violations_pattern, generated_response, re.DOTALL)\n","\n","    label_match2 = re.search(label_pattern, generated_response2, re.DOTALL)\n","    violations_match2 = re.search(violations_pattern, generated_response2, re.DOTALL)\n","\n","    label_match3 = re.search(label_pattern, generated_response3, re.DOTALL)\n","    violations_match3 = re.search(violations_pattern, generated_response3, re.DOTALL)\n","\n","\t# Extract matched text if found\n","    labels = label_match.group(1) if label_match else '''SCREWED UP SMH'''\n","    violations = violations_match.group(1) if violations_match else '''SCREWED UP SMW'''\n","\n","    \t# Extract matched text if found\n","    labels2 = label_match2.group(1) if label_match2 else '''SCREWED UP SMH'''\n","    violations2 = violations_match2.group(1) if violations_match2 else '''SCREWED UP SMW'''\n","\n","    labels3 = label_match3.group(1) if label_match3 else '''SCREWED UP SMH'''\n","    violations3 = violations_match3.group(1) if violations_match3 else '''SCREWED UP SMW'''\n","    \n","    # Extract ROUGE scores (R1, R2, RL, RLsum)\n","\n","    row['label_base_model']= labels2\n","    row['violations_base_model']= violations2\n","    row['label_finetuned']= labels\n","    row['violations_finetuned']= violations    \n","    row['label_4o']= labels3\n","    row['violations_4o']= violations3\n","    print(\"WR DONE\")\n","\n","    print(row)\n","\n","    print(\"Out\")\n","\n","    \n","    return row\n","\n","# Apply the ROUGE calculation for each row in the dataframe\n","df = df.apply(calculate_metrics, axis=1)\n","\n","# Save the final dataset with ROUGE scores\n","df.to_csv('./splits/final_test_rouge_label.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","# Load the dataset\n","file_path = './splits/final_test_rouge_label.csv'  # Replace with the actual file path\n","df = pd.read_csv(file_path)\n","\n","# Initialize confusion matrix counters for Fine-tuned (FT) and Base Model (BM)\n","FT_TP = FT_TN = FT_FP = FT_FN = 0\n","BM_TP = BM_TN = BM_FP = BM_FN = 0\n","\n","# Iterate through each row in the DataFrame\n","for index, row in df.iterrows():\n","    label = row['Quality']\n","    FT_label = row['label_finetuned']\n","    BM_label = row['label_base_model']\n","\n","    # For cases where 'Quality' is marked as 'good'\n","    if \"good\" in label.lower():\n","        if \"good\" in FT_label.lower():\n","            FT_TN += 1  # True Negative for Fine-tuned\n","        else:\n","            FT_FP += 1  # False Positive for Fine-tuned\n","        \n","        if \"good\" in BM_label.lower():\n","            BM_TN += 1  # True Negative for Base Model\n","        else:\n","            BM_FP += 1  # False Positive for Base Model\n","\n","    # For cases where 'Quality' is marked as 'bad'\n","    elif \"bad\" in label.lower():\n","        if \"good\" in FT_label.lower():\n","            FT_FN += 1  # True Positive for Fine-tuned\n","        else:\n","            FT_TP += 1  # False Negative for Fine-tuned\n","        \n","        if \"good\" in BM_label.lower():\n","            BM_FN += 1  # True Positive for Base Model\n","        else:\n","            BM_TP += 1  # False Negative for Base Model\n","\n","# Function to calculate evaluation metrics\n","def calculate_metrics(TP, TN, FP, FN):\n","    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n","    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n","    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n","    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n","    return accuracy, precision, recall, f1_score, specificity\n","\n","# Calculate metrics for Fine-tuned model\n","FT_accuracy, FT_precision, FT_recall, FT_f1, FT_specificity = calculate_metrics(FT_TP, FT_TN, FT_FP, FT_FN)\n","print(FT_TP, FT_TN, FT_FP, FT_FN)\n","# Calculate metrics for Base Model\n","BM_accuracy, BM_precision, BM_recall, BM_f1, BM_specificity = calculate_metrics(BM_TP, BM_TN, BM_FP, BM_FN)\n","print(BM_TP, BM_TN, BM_FP, BM_FN)\n","\n","# Display results\n","print(\"\\nBase Model Metrics:\")\n","print(f\"Accuracy: {BM_accuracy:.4f}\")\n","print(f\"Precision: {BM_precision:.4f}\")\n","print(f\"Recall: {BM_recall:.4f}\")\n","print(f\"F1-Score: {BM_f1:.4f}\")\n","print(f\"Specificity: {BM_specificity:.4f}\")\n","\n","print(\"-------------------------------------------------------------\")\n","\n","\n","print(\"Fine-tuned Model Metrics:\")\n","print(f\"Accuracy: {FT_accuracy:.4f}\")\n","print(f\"Precision: {FT_precision:.4f}\")\n","print(f\"Recall: {FT_recall:.4f}\")\n","print(f\"F1-Score: {FT_f1:.4f}\")\n","print(f\"Specificity: {FT_specificity:.4f}\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"789fb1f1-fd01-4446-8a52-cef54d3331af"},"source":["Develop a function for performing inference and assessing an instance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c31d294b-79a4-42d4-ad88-2229551feecb","tags":[]},"outputs":[],"source":["# This code block defines a function 'calculate_rogue' that calculates the ROUGE score for a given row in the dataset.\n","\n","# 'row' is the input to the function. It is a row in the dataset that contains a message and its corresponding output.\n","\n","# 'test_inference(row['messages'][0]['content'])' calls the 'test_inference' function with the first message in the row as the prompt.\n","# 'test_inference' performs inference on the prompt and returns a generated response.\n","# The response is stored in the 'response' variable.\n","\n","# 'rouge_metric.compute' is a method that calculates the ROUGE score for the generated response and the corresponding output in the row.\n","# 'predictions' is set to the generated response and 'references' is set to the output in the row.\n","# 'use_stemmer' is set to True, which means that the method will use a stemmer to reduce words to their root form.\n","# The calculated ROUGE score is stored in the 'result' variable.\n","\n","# The 'result' dictionary is updated to contain the F-measure of each ROUGE score multiplied by 100.\n","# The F-measure is a measure of a test's accuracy that considers both the precision and the recall of the test.\n","\n","# The 'response' is added to the 'result' dictionary.\n","\n","# The function returns the 'result' dictionary.\n","def calculate_rogue(row):\n","    response = test_inference(row['messages'][0]['content'])\n","    result = rouge_metric.compute(predictions=[response], references=[row['output']], use_stemmer=True)\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    result['response']=response\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"l1hUxkIiZxtV"},"source":["Now, we have the ability to execute inference on a collection of samples. For simplicity, the process isn't optimized at this stage. In the future, we plan to perform inference in batches to enhance performance. However, for the time being,"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["a4af29a883094a6a85de45dc582781df","e4a98928460446019223c806ed7dd877","06acfb56fc304e28a3113aab69aed66c","3c603af8f4364fdcac2b09529293e18e","47c2bde9bc01463ba8111be4b22fcdc3","55f08d2043b94ce499ee55b1871402ad","5e53398218a54804b69c805a6e95a37d","2cb950ef10d24e4f8ad3a6131ab80ff4","bdca6009505c4fe7b2e51b0432717ab8","221294f628ef4b5aaac0d9a503a9bf78","651e52cc3fe1490db20646ae975727d8"]},"executionInfo":{"elapsed":2813043,"status":"ok","timestamp":1715514645937,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"e6d45ed0-6c91-4738-a5e9-25601c76ffba","outputId":"a97bcd84-a678-4d61-8e3c-e0202b4ce398","tags":[]},"outputs":[],"source":["# '%%time' is a magic command in Jupyter notebooks that measures the execution time of the cell.\n","\n","# 'dataset_chatml['test'].select(range(0,500))' selects the first 500 elements from the test set in the 'dataset_chatml' dataset.\n","\n","# '.map(calculate_rogue, batched=False)' applies the 'calculate_rogue' function to each element in the selected subset.\n","# 'calculate_rogue' calculates the ROUGE score for each element.\n","# 'batched' is set to False, which means that the function will be applied to each element individually, not in batches.\n","\n","# The results are stored in the 'metricas' variable.\n","%%time\n","metricas = dataset_chatml['test'].select(range(0,500)).map(calculate_rogue, batched=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"39d66860-aac6-44ea-9f75-17efbbdcb9e1","tags":[]},"outputs":[],"source":["# 'numpy' is a library in Python that provides support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n","# 'import numpy as np' imports the 'numpy' library and gives it the alias 'np'. This allows us to use 'np' instead of 'numpy' when calling its functions.\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"zzn8sk_3V0Rm"},"source":["Now, we have the ability to compute the metric for the sample."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1715515676067,"user":{"displayName":"Eduardo Muñoz Sala","userId":"13317831924226771761"},"user_tz":-120},"id":"6877ad08-32a2-4be6-a18d-76a47818886a","outputId":"2e20e6cf-c579-4633-b90e-75c8fa845ed4","tags":[]},"outputs":[],"source":["# This code block prints the mean of the ROUGE-1, ROUGE-2, ROUGE-L, and ROUGE-Lsum scores in the 'metricas' dictionary.\n","\n","# 'np.mean(metricas['rouge1'])' calculates the mean of the ROUGE-1 scores.\n","# 'np.mean(metricas['rouge2'])' calculates the mean of the ROUGE-2 scores.\n","# 'np.mean(metricas['rougeL'])' calculates the mean of the ROUGE-L scores.\n","# 'np.mean(metricas['rougeLsum'])' calculates the mean of the ROUGE-Lsum scores.\n","\n","# 'print' is used to print the calculated means to the console.\n","print(\"Rouge 1 Mean: \",np.mean(metricas['rouge1']))\n","print(\"Rouge 2 Mean: \",np.mean(metricas['rouge2']))\n","print(\"Rouge L Mean: \",np.mean(metricas['rougeL']))\n","print(\"Rouge Lsum Mean: \",np.mean(metricas['rougeLsum']))"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOb1j0bm75D2Nfp6H9gt8EF","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0028bc0c938b4d549d7971f43590fa05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0090c8a99d08434ab1a7fc08cbae07b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00bbf7787ad44919bb9920c825e38d19":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00ca19e7921b4f61b32265c79c091874":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"013c5888b3f24d008b29ddb50a85184e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d5709bce7c24395a0a63f5187c897d8","placeholder":"​","style":"IPY_MODEL_595e65642d3042a9a3995072d721be7d","value":" 172/172 [00:00&lt;00:00, 14.6kB/s]"}},"01f52fd34c1943f483db8ddb8b98601f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d0708befa484d26ab88e8172b67fc6a","placeholder":"​","style":"IPY_MODEL_d414908f8047408aaf31108c38d0be63","value":"model-00001-of-00002.safetensors: 100%"}},"022f4ce349904008af13409e6e3621e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8676ea5c9074c7b88874aad7d447139","placeholder":"​","style":"IPY_MODEL_4dcb0b76c0474ca6b2082ae871fc680f","value":" 500k/500k [00:00&lt;00:00, 2.21MB/s]"}},"029819fa8bf44099946ac08fcb2aadb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1dd590f35a64e968113caaacb3b4e80","placeholder":"​","style":"IPY_MODEL_90acdd2e01904b47bbba42c1ee2f362d","value":" 73.8k/73.8k [00:00&lt;00:00, 3.30MB/s]"}},"03631a493fcf4a6e985d35962f2d4029":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03c829f852404d028a5a22c031cfa70a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"040a12849797455c939e4bd85c9b39bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0436130ee049419a8ffdef720626149a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0454bc7b15584eb7af1e6c83a0284e22":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"046620941782440abecb9e6cf190f824":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04a09e6c9ca64f25a3d4fbac1662f3ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04d77fcab4f84fa3a7d108a9648981c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c292b94cc39402591d119e9334ed9f2","placeholder":"​","style":"IPY_MODEL_e4ac020f037642299004abc08c5b7cbc","value":"tokenizer_config.json: 100%"}},"04dccb6e02f3443bb3bc6882ffc4096c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06062332a4c34d26ba5fa0a357b483b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc3dfa5eedc44e27aaa3e29be3c77310","placeholder":"​","style":"IPY_MODEL_76b645e105224e5b95083c46c7325ecc","value":"Downloading builder script: "}},"06acfb56fc304e28a3113aab69aed66c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cb950ef10d24e4f8ad3a6131ab80ff4","max":500,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdca6009505c4fe7b2e51b0432717ab8","value":500}},"075e610b3ed141fea8f3b0155fcdcb93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"092e91029a7c469fb79058c518dc3092":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b04aa6337c54790812e567f93b07f25":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_103257314ecf419b956b7645459329e6","max":2169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e586ef1090d94c64837d249c395ed111","value":2169}},"0b3e88a19bc84d188ef8cd7ff19d907e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c205cb5b0a047a7b244388ef1b5f03f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c343b8036f84f4782454b5dd4cfea7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c7c94003f5640e68ca0284794853a14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d48213f7e1c481099fd5ef55c709085":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ee5fc46bba145269b9e1ec349c0c45c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_601d887d687d471e803026152577e55a","max":18612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_579e15c2f5a84f83b7cd9f04c29f630f","value":18612}},"0eece1e6ef00406287739ce6ece81b2e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1de09104478348ac83d431260fde8779","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_659dddcfd95b41b9b7d9b4c63f5d0852","value":2}},"0f0b36c8ab604525928be5e720637ad0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f1e5deef0a24f55a9f9b22ad3d49d17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0fb088e83959437e833231b9e091df9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0fdcd532f6184ac4b6b6aeba8c54a82c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"102ece1779d1409fb4fd0e1a4ed8a8ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_721f6878cf124b0b96d9d8570cd047b2","placeholder":"​","style":"IPY_MODEL_a2d8655bc330432fb28022ec87141ef3","value":" 3/3 [00:02&lt;00:00,  2.33s/it]"}},"103257314ecf419b956b7645459329e6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10cad4dc22014a9ab601bf3c31af19c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"118ed7a45ea145668dfb11b74d780f3b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11e74c6f08934ba39e54337dff2a5ecd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1246f9886bc84fca95c963560733e826":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12f8922b6f9249b5b36b979bffcb4493":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_529fe14a9c2d4074bf31da17da11ca40","max":568,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b70b814dcae0421c91507eab1e152f02","value":568}},"145fc3fb1e404b0abe6eba03a6e834c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c52f0c3c7d614adea3e20364a1fe394f","placeholder":"​","style":"IPY_MODEL_a102c215a46a40ee98a81995a8667f46","value":"model.safetensors.index.json: 100%"}},"148248066c0e44469c29609fb844e304":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1561787e0545497aaef43ce3f79d0e4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15d8a137d0364004975ceaee8d0ed8d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15e1dbe1e70f4cfa9c06b981b09151e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"171d95ec467c4c51806b6470fc45bf6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"172ab1da8e394c599ddee76f48f80399":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1759e4153c2c49b3adee58c5d20a5ae7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"175d3e2edd404079aaca9a0b8fb16995":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1765413771f74585be4023c5c437bf41":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1786bf22999a4ee9aa8677308cb3509a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"181c8ab5d7e148bd8d70595fbc0c9175":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"195ab5fcec8349439abab8590d4a41dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19db76d11f3444ac88965d1804c95ee3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a2d05bc514a45e2ae3fec48b068f5d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eeede55ddd0e40e1a8fb308a4f3ad233","max":4972489328,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8dc4ab8a7a1450e8dbfc6e31bdcb202","value":4972489328}},"1c0a529e2aba41b1a2c7c324d00572b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92d8eebb8fb44044a79bfef596791d9d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50abc43038b64f5eb03d0da37ef33eba","value":2}},"1c2bd106a0f643dbb07d1db1964a8188":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d1be0fc03fb4b7080bea43436bd571c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_172ab1da8e394c599ddee76f48f80399","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c9451703d554290b101c6f8b2946fb7","value":2}},"1d6c4ab6162b44db8e5eb6c0911891ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62fbdfde9c8e4d87962bbfdaa34b29b7","placeholder":"​","style":"IPY_MODEL_6d5688737e5744c5828cc386c650cc1e","value":" 568/568 [00:00&lt;00:00, 49.3kB/s]"}},"1de09104478348ac83d431260fde8779":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f0917d1bc354d4b82876af2c82054f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44f29936885a47d4afa3fe49ecfc0b5d","max":905,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb612d41baf54c50914cd72a5b269e91","value":905}},"2126390b60444879a21e99a02c4af518":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21663d98913e43a992798be7e10a7bb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1b620a4ccf84d2a99c0d0e3b4fc5ff6","placeholder":"​","style":"IPY_MODEL_33bc4818309c4d90aed0d40227b5ca1c","value":"model-00002-of-00002.safetensors: 100%"}},"221294f628ef4b5aaac0d9a503a9bf78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"224e68aeff7940d4a7eafde48f3cab49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22923fe1412345bd8ecda3fba24db01d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dbc872ea3eb043c6bc92ca2c2ab77e19","IPY_MODEL_636c8e6adf264c2d99925f5addfe15d7","IPY_MODEL_dbb5ec51bd834c50bdbf1e711d384ec9"],"layout":"IPY_MODEL_3a35130eaec440de8b48164f3cbe0b49"}},"22b3ed00418d44338cdf745340fa18a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22b495d9e099437aa0c1267110f3ed9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23b8c74bbf3d44cd8c30c06c30e0531c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fbba0403e6e478d961cba143d1170ad","IPY_MODEL_5220091d3218419db63a27f3e09c63ef","IPY_MODEL_9de99cacfcd34cf487fa610e2eca498d"],"layout":"IPY_MODEL_bf09841951154f9d8a5c808da138b72f"}},"257f093d380e4d05b7252c53c3730755":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2661b0440326407fb74cea4cd7b80f9b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"266e4bbb79a64642bc174f3c7dad95d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26d761bd22e84ea0bf66242c4216c4f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a91b926b1cc549899b2dbf7476712ee1","IPY_MODEL_12f8922b6f9249b5b36b979bffcb4493","IPY_MODEL_1d6c4ab6162b44db8e5eb6c0911891ce"],"layout":"IPY_MODEL_34cd3e3aee324e1085fe395f0be6e299"}},"289328c4e17b4219b96fb47bee399a84":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2958f961d7634a07b5c0b4adc1f3b5c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"296b7f23ba0c4b4a8e8ec49427152c5c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29ca7d61681e4c55abc27e59fce84a12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a1a106dd02b430fb531260b85e68428":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ac823cc9a7d4a1899f9a185b659cc34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1765413771f74585be4023c5c437bf41","max":5174,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d07197cefa7b4715bee9f2a0d604bd42","value":5174}},"2adf4097c40a4a6388945d374d505028":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2aff1fedfb8b4e1f928f5ea74cd9edbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b4f5cef256a4711bc060f3294fa8ef4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b76900c76f346f288d4a42e5a6a19c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2be773e7b0c543b78402c42f27e56a7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c449bed2c484110ac8ae0f362d739b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c4a6ebda2604ddbb7a1b7c311afa5e7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfa74756deaa4f99a060c1e2e346589c","IPY_MODEL_f29cfcc949dc4de68f25d7f67215c33e","IPY_MODEL_93950d4174524a62a2811161f2606e58"],"layout":"IPY_MODEL_c37ce6058b5c4474bbb1d0d4147a377e"}},"2cb950ef10d24e4f8ad3a6131ab80ff4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc158682aff403a9e8aac09c6dd54c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00bbf7787ad44919bb9920c825e38d19","placeholder":"​","style":"IPY_MODEL_976916bba18e4c4aba1291dbb6967724","value":"tokenizer.model: 100%"}},"2cdd2f0c761642469b5c9241dbdf07cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e20352069a343ebaba1ba04e4f80cf8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83d4d3611edd4389a93364046ace1160","IPY_MODEL_ecc3a536f91c4685905bcae0b53ef777","IPY_MODEL_7e22f2c6ddfd42bdabfe2ca6e4d9d5bf"],"layout":"IPY_MODEL_cfc00687a8984631861d8ff1235ff4d5"}},"2f571f2447aa4c34a8a129189998a791":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65db43f8e5ef45659bf982784bacba48","IPY_MODEL_2ac823cc9a7d4a1899f9a185b659cc34","IPY_MODEL_9b0142584c6a45e896e4f819a9799f4b"],"layout":"IPY_MODEL_0b3e88a19bc84d188ef8cd7ff19d907e"}},"2f65a82bed7e4077943483bd9fe3c257":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_075e610b3ed141fea8f3b0155fcdcb93","placeholder":"​","style":"IPY_MODEL_e82486323d3f4403a7c60f79d56bf4b9","value":" 16.3k/16.3k [00:00&lt;00:00, 989kB/s]"}},"2f8b17db9ddd48e0b03b497895f785d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fd2efd511714c11b693acdf8599796d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"301500418c7f4e50b2babdb337f91080":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3057cb40215747e39e46ba451f2a2faf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"305fb821f28e48a09cb9de9c7ed100e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_98eaae214ef144a49786e2bb88d66e5b","IPY_MODEL_0eece1e6ef00406287739ce6ece81b2e","IPY_MODEL_8af247e84ce84feeb210fd136cc757f3"],"layout":"IPY_MODEL_19db76d11f3444ac88965d1804c95ee3"}},"30decaf508724418ab4b51fe9594ba47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_586b02e105644582b99a7f248df5a8b8","placeholder":"​","style":"IPY_MODEL_340b26123c5a49b68c162d2df70b7591","value":" 2/2 [02:07&lt;00:00, 63.18s/it]"}},"30f1a93d85d54aa790f2922db10e2fad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfdcc9ae18124b719591120c8c9a5533","max":2669692552,"min":0,"orientation":"horizontal","style":"IPY_MODEL_41fee93fdd1c4d97a6a552141182eebb","value":2669692552}},"30f40b4621f3483592803659a2dcd69e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"317127b9c03d4a88879b71478f96cea0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31cb3a6b2ece4df8ba3cdb2a7e0853c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d98dac63254877bbd6941992cc3c11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4a58ae2b740445bb980b9639daad37e","placeholder":"​","style":"IPY_MODEL_c8db4344bf6e4cfab30d54965659789e","value":"adapter_model.safetensors: 100%"}},"32f3c777dd5e4608a7c39c34549c3c8a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32f4413bf6a04fc4a02c159e33dbd71d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f79bb7e41ae34c01802cf81d52572620","placeholder":"​","style":"IPY_MODEL_0f1e5deef0a24f55a9f9b22ad3d49d17","value":"generation_config.json: 100%"}},"331e1a532ef74d99abbcc62bfb2c666a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d48213f7e1c481099fd5ef55c709085","placeholder":"​","style":"IPY_MODEL_37b0d96518c94f56affe25724bdc7448","value":" 4.97G/4.97G [00:21&lt;00:00, 260MB/s]"}},"33bc4818309c4d90aed0d40227b5ca1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33e04e76e32e487dbd5a9167917ea190":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32f4413bf6a04fc4a02c159e33dbd71d","IPY_MODEL_42735f1e079f42d790b802b977ea5f52","IPY_MODEL_013c5888b3f24d008b29ddb50a85184e"],"layout":"IPY_MODEL_d2cebab3787442528ce9c6d8b9acff43"}},"340b26123c5a49b68c162d2df70b7591":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3449acde6d9c4d08a73e40c26905b14b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3492c45c01084e1c8cfeeae95ed4599c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34cd3e3aee324e1085fe395f0be6e299":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3517b67bd29b49dea624af395a61981f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3597dc3247c143c386326ac79f72c7a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35f65873ac94477cbef2df06d4c68e10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3623a68450404578b8101d192733b28a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36eb716a460442dd8e370c7b7cf1dd70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37136592e27d419b93a7b3bb65c8dab4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37b0d96518c94f56affe25724bdc7448":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"383d379aabdb4d4587f7a11520f01ec1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_88130d5880c64533b1833c5e715f64f6","IPY_MODEL_c28beafc58d34b118dcd1f69ed1d44f8","IPY_MODEL_b7196498aaeb41a0a410764ca41a5a80"],"layout":"IPY_MODEL_2be773e7b0c543b78402c42f27e56a7e"}},"38f94d449c5f4c0bb72dcc54ee11dbcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0855c7022f54058abed8e08fa966d8b","placeholder":"​","style":"IPY_MODEL_3cc0fe8afaf14ad580a58bab1b947e15","value":"Map: 100%"}},"38ff8593bd2b480ebd55607b8c54a587":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3924ead7d1e149e2bed8266caa4add08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39cb0c878a624cb48a230807cee0ad7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a06aeeb23f74709b9eae8154b683797":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d5b93e40594822b9a2cc2912012761","placeholder":"​","style":"IPY_MODEL_521f1e9b48ac43e88dde4f33cc960665","value":" 16.3k/16.3k [00:00&lt;00:00, 1.44MB/s]"}},"3a35130eaec440de8b48164f3cbe0b49":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a3fc4962a1e44bf80cc1175cdcab1e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d384c2f905e9484bb71918c6566d9490","placeholder":"​","style":"IPY_MODEL_8a0986e816fe4dde8784f56f7c6e78c8","value":"Upload 2 LFS files: 100%"}},"3a4bb66dbeda43f9942362590aa54cbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a3fc4962a1e44bf80cc1175cdcab1e6","IPY_MODEL_1c0a529e2aba41b1a2c7c324d00572b4","IPY_MODEL_30decaf508724418ab4b51fe9594ba47"],"layout":"IPY_MODEL_b677f4bde46c43a6ae7579a24fd219d4"}},"3b1e002f9f374184a6dfca10df7b5c44":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bcbd420b0ea4fe189d9a6af501963d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3be7bf3f7f124831bb4b988f31304727":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4b96f6c51eb46f085c07daffc54c6ac","IPY_MODEL_ce3c25872ea443ce8e54fd6241effddf","IPY_MODEL_e3db7f9cb43f4aada76b72373afa5a44"],"layout":"IPY_MODEL_38ff8593bd2b480ebd55607b8c54a587"}},"3c2a9dd5b94a4839842265e12c1080a8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c603af8f4364fdcac2b09529293e18e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_221294f628ef4b5aaac0d9a503a9bf78","placeholder":"​","style":"IPY_MODEL_651e52cc3fe1490db20646ae975727d8","value":" 500/500 [46:52&lt;00:00,  4.84s/ examples]"}},"3cc0fe8afaf14ad580a58bab1b947e15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0708befa484d26ab88e8172b67fc6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d185b1d39ad41408664f2f11ded491b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e4613669dd54cd685f8dd7d4cea1ced":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ef01550b7e8426fb0fdc86e28aee0f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_439b2bd975cc41f99d097d0e4a68a659","IPY_MODEL_68ea6f81a0014b00a79fcc02488956d4","IPY_MODEL_5e42f68b396a43eca211cc5c738e63e5"],"layout":"IPY_MODEL_b4b95d28135b4c868330ddf3342c2b68"}},"3f519139e1c74a6babe3fec272f6752a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_42aa901e9a034134b2ac04698159fe1f","max":3169,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ed363711b3794a39b7ead82558cf26f7","value":3169}},"3fa473bc407841f38bee517c52dc790b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d59488087dd54981a35b946c258794de","IPY_MODEL_bd127c03b9524c31ac9e01c1fefb0de3","IPY_MODEL_d7fe81223ded4e66809a5be599dc9b58"],"layout":"IPY_MODEL_ac98d431d47c44bda6819b3728bb5bbe"}},"3fd63dfbf5fc4cc5a05cabfdfea85fd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40d3efeaacef42e78467a6cc10868866":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41fee93fdd1c4d97a6a552141182eebb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42735f1e079f42d790b802b977ea5f52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31cb3a6b2ece4df8ba3cdb2a7e0853c6","max":172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_10cad4dc22014a9ab601bf3c31af19c1","value":172}},"42869c54a0f2400489e424d665a65786":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"42aa901e9a034134b2ac04698159fe1f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4310fd1dba3141deb1e19d20230b8247":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_591a0e2cd8e945dd9ae719eb774ae3ee","IPY_MODEL_acb08bb2712d4d238c03eef1c15d5d98","IPY_MODEL_7c3f114c4b484551a922894f6fd8905d"],"layout":"IPY_MODEL_0436130ee049419a8ffdef720626149a"}},"439b2bd975cc41f99d097d0e4a68a659":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b4f5cef256a4711bc060f3294fa8ef4","placeholder":"​","style":"IPY_MODEL_148248066c0e44469c29609fb844e304","value":"modeling_phi3.py: 100%"}},"43c5dc528aae42879292cfefc5a1aebf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44f29936885a47d4afa3fe49ecfc0b5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"450ae7bb94db4c16a9defb44f007f561":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"450e41978dca4010b8969b48491cf0f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef1fef6471af459aa4ac089be9724f00","placeholder":"​","style":"IPY_MODEL_7039249a6a314d3db0e9b5224cbe660d","value":"Map: 100%"}},"45abbb2acbab404191851c503a43f460":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45dcc7940a0a4fe5910b0b4e522eac80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"45f337c9a4ea45e39358a14198a47eec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46a1ea1357514d0eaa731e7286d62bd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76073d46b27c44119d2c8f9060ff2f31","IPY_MODEL_cd5773d98dcd48ada478251e5d8f667a","IPY_MODEL_3a06aeeb23f74709b9eae8154b683797"],"layout":"IPY_MODEL_7fd3cb68269c40a59e3d681a17ab5ad2"}},"472d2e329fe542dc898a237458d5686c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"478a058d22194634a4df745e3cd9f478":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcabb4a8e10f4d61bfc0d4d55d241d99","max":982,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94afa80f33844271bcdb3ff85470aab4","value":982}},"47c2bde9bc01463ba8111be4b22fcdc3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48b473c904c049c29a42a056bf84c900":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f0ca1a4f5b14063af3d7d6465507a0f","placeholder":"​","style":"IPY_MODEL_eb86bd36bc8b4e4298157ea474e5029f","value":"tokenizer.json: 100%"}},"4983e7b601d44417a8ed7e7f9f70745e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49dc6a5e39d241649c1ab5640c05509a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21663d98913e43a992798be7e10a7bb9","IPY_MODEL_30f1a93d85d54aa790f2922db10e2fad","IPY_MODEL_7e1d5d4cef5a432c9e28dacce74cb4e0"],"layout":"IPY_MODEL_b2519736637a4722b58590d0283c806a"}},"4a1c0cd048234c85b5aa54317ef0c2f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38f94d449c5f4c0bb72dcc54ee11dbcb","IPY_MODEL_0ee5fc46bba145269b9e1ec349c0c45c","IPY_MODEL_d521ef01918b4d1a95c2528855c08d8a"],"layout":"IPY_MODEL_f7baa800a11c4ae9a84941f67868127d"}},"4a29804ee58d4d01903ae9d5d64e8ee5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61cb12f9f0144a5e928120df9f2a6eaa","placeholder":"​","style":"IPY_MODEL_03c829f852404d028a5a22c031cfa70a","value":"model-00002-of-00002.safetensors: 100%"}},"4a6dade4fa4740d79bd9016261479c50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4afa5f5a5fb64a80b9caca4e10d171b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f50eeebaa04f42938928a83f49513718","IPY_MODEL_57d5f5e220e54650a394b02db8adf734","IPY_MODEL_022f4ce349904008af13409e6e3621e8"],"layout":"IPY_MODEL_2cdd2f0c761642469b5c9241dbdf07cb"}},"4be0749b3ac04fac9ca2c8c05775ccff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c54ba6b957d4bcaa6c6badabf37eec5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c205cb5b0a047a7b244388ef1b5f03f","placeholder":"​","style":"IPY_MODEL_9eb8db21e0904bd0bc9291df5959b42b","value":"modeling_phi3.py: 100%"}},"4dcb0b76c0474ca6b2082ae871fc680f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e87a17ef2e9469690f28544a7ef736a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8637e0ecee0b4736b6fe1387272c45d2","placeholder":"​","style":"IPY_MODEL_3517b67bd29b49dea624af395a61981f","value":"added_tokens.json: 100%"}},"4eea9777aa3a4fd294d1c960f0a67f3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f5efc3784584d9d9751d55fa8dc7451":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2cc158682aff403a9e8aac09c6dd54c5","IPY_MODEL_74acac2027ad4d08b8994e3bccfcbe17","IPY_MODEL_aba6c1eb379949589357685f68f25802"],"layout":"IPY_MODEL_c7e7a08ec7a041bc9776a15026bfbc9e"}},"504b142157694a3a85cf1b8e0374022b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50999791713342138b63d2c414d246d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50abc43038b64f5eb03d0da37ef33eba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50ed903542fc427582e77020ef135898":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"512351ca43e3407cb2c1388c54f1ee4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5123bb14e00d45c5ba7e4db4b3543b13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"521f1e9b48ac43e88dde4f33cc960665":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5220091d3218419db63a27f3e09c63ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53f68b06f71d4479b6e2684a6edc5ab7","max":904,"min":0,"orientation":"horizontal","style":"IPY_MODEL_046620941782440abecb9e6cf190f824","value":904}},"529fe14a9c2d4074bf31da17da11ca40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53eb0821262048d1bb1e1824401f5856":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53f68b06f71d4479b6e2684a6edc5ab7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54a7c113c9f34118843e761698b2d0e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"552424871d8c42388ccf191502baeff3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5589d4f9a8904568a6a3cb90d3882be7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55f08d2043b94ce499ee55b1871402ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56446ad26c6d4343b74cf664f56c4b9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"569cc7d37f374b37881243f4c3fcf71e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_604cc86aef55472ca1486939b33cd948","max":3160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_672409d0133d4db9a5439ccd92ca5685","value":3160}},"56e31e9ebcbc452bb74f1374d345e2f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5735d665770740a6b226511d2a4b9faa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15e1dbe1e70f4cfa9c06b981b09151e2","placeholder":"​","style":"IPY_MODEL_59e8243d36f64b1f8e031973ef99d543","value":" 18612/18612 [00:00&lt;00:00, 85366.81 examples/s]"}},"579e15c2f5a84f83b7cd9f04c29f630f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"57d5f5e220e54650a394b02db8adf734":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f8b17db9ddd48e0b03b497895f785d8","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a1a106dd02b430fb531260b85e68428","value":499723}},"57ea92df94984c9387e3a5224e41f258":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_65f529a8191d4586b7a8fe9b58ea75bc","placeholder":"​","style":"IPY_MODEL_8713b6c14b9e4cbc938d83dc37228d72","value":"Loading checkpoint shards: 100%"}},"582f76ead4434254b45f3a76e04e4a5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9887201b9b65496583ae96e82ae2b219","placeholder":"​","style":"IPY_MODEL_7d81a07f16774c1185728c88f857ca1e","value":"Loading checkpoint shards: 100%"}},"586228e34da640df9c03fc45ce719d89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2adf4097c40a4a6388945d374d505028","placeholder":"​","style":"IPY_MODEL_b2f689bade764e0fac3f83a1e64b28ba","value":" 4.98k/4.98k [00:00&lt;00:00, 28.8kB/s]"}},"586b02e105644582b99a7f248df5a8b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58ef49074584496bb4e1b350cc073161":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"591a0e2cd8e945dd9ae719eb774ae3ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cdaf9b4376e8425181bc8db4cccef385","placeholder":"​","style":"IPY_MODEL_195ab5fcec8349439abab8590d4a41dd","value":"tokenizer.model: 100%"}},"593fc5a4d40a4c05831e5bb4001a6d19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"595d8af5740c4c93bd461a365cb7b4dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50ed903542fc427582e77020ef135898","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_181c8ab5d7e148bd8d70595fbc0c9175","value":499723}},"595e65642d3042a9a3995072d721be7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59e8243d36f64b1f8e031973ef99d543":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a7c8e3e4b1b4831ad66a8725f805edb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a941064b3584a7391912e2524a564c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_450e41978dca4010b8969b48491cf0f9","IPY_MODEL_a1a92f6e80764f59a9e4d029d9e88b5f","IPY_MODEL_b9fe743a8cf74c1697af07602b3a2d58"],"layout":"IPY_MODEL_3597dc3247c143c386326ac79f72c7a5"}},"5d991991a5644befbd6b34d5dee18d13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f033adb758544d1c89e842339b12dde0","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3c20616b2f941c69b8ff983b9e3c192","value":3}},"5de4d24cb81f49728e12c04cd2575395":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e42f68b396a43eca211cc5c738e63e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e0995b34528475e801f5c760354a6ac","placeholder":"​","style":"IPY_MODEL_e6e3cc38aceb49eb9a2cd497a0107718","value":" 73.8k/73.8k [00:00&lt;00:00, 897kB/s]"}},"5e53398218a54804b69c805a6e95a37d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f66799fd7964508bfb690acecb8bf0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5fb978c32e3e4492bb1e28996f32ef24":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_00ca19e7921b4f61b32265c79c091874","max":73778,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d13a31237124c61bbfd394d6a612595","value":73778}},"60016177db6d45e0a0a42f2cfb24a9de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_667910d71e304470a0be5e7645242bc4","placeholder":"​","style":"IPY_MODEL_7b67bd6e50324fe3b80b93e3e81803b0","value":"Upload 3 LFS files: 100%"}},"601d887d687d471e803026152577e55a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"604cc86aef55472ca1486939b33cd948":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61108297e38343148ee2def1f649a652":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6de72277f3f44149b94827a57d31a2bf","max":4972163696,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4406159d03d42198a647c3f1285a938","value":4972163696}},"611b8d1ead824b9fad7a3a072208f39f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61cb12f9f0144a5e928120df9f2a6eaa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6268d760b3ac43a69f115e65a790599a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62e9860c615b42a6813ce70f301a66bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62fbdfde9c8e4d87962bbfdaa34b29b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6342ebd8a2db47ed8214b9369e77b22d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"634ff8d193864528848a173ff1b506f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"635d6b6aacae4002a0af24f48f712a6a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f87526f1efa24f4ab2942c4b8d9dbc99","placeholder":"​","style":"IPY_MODEL_2c449bed2c484110ac8ae0f362d739b9","value":"Downloading shards: 100%"}},"636c8e6adf264c2d99925f5addfe15d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c02a3d798bf3479e93f7d55b0077db16","max":931,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c6ea3f34f09d4af596beb3daba50c513","value":931}},"644047f844dc4f2fbaa678570c3b64c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"651e52cc3fe1490db20646ae975727d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6578daab99bc44f5ba4286e4efe31308":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0454bc7b15584eb7af1e6c83a0284e22","max":1845458,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ba946d03e1384bdf8ea13e8f61b730ae","value":1845458}},"659dddcfd95b41b9b7d9b4c63f5d0852":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"65db43f8e5ef45659bf982784bacba48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62e9860c615b42a6813ce70f301a66bf","placeholder":"​","style":"IPY_MODEL_4be0749b3ac04fac9ca2c8c05775ccff","value":"README.md: 100%"}},"65f529a8191d4586b7a8fe9b58ea75bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6627a90d4e05400abb2a8f2aff8fb085":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667910d71e304470a0be5e7645242bc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"672409d0133d4db9a5439ccd92ca5685":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68064669c1a54b58814e2075c666762f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68ea6f81a0014b00a79fcc02488956d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43c5dc528aae42879292cfefc5a1aebf","max":73778,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b50c9fe94fa54eab9862e6fb73d30634","value":73778}},"69625e03e76d4d1ca841aada699f06d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b43b2067e7d432c8bee14b67a5675f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_48b473c904c049c29a42a056bf84c900","IPY_MODEL_6578daab99bc44f5ba4286e4efe31308","IPY_MODEL_c2a03890d9534f858d345e3ac6278fed"],"layout":"IPY_MODEL_8601d892d7594fcfaa85989b5628ae12"}},"6b460ae86ac64220a7b1ed3ed5e8a4bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6be6720aa1484075a81410d7a03839ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d13a31237124c61bbfd394d6a612595":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d5688737e5744c5828cc386c650cc1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dde3ae85dc5423aae584d985e84fcd4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3bcbd420b0ea4fe189d9a6af501963d8","max":4972163696,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e68ed8ec991f40058924e637a63d0aca","value":4972163696}},"6de72277f3f44149b94827a57d31a2bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6faa9332fcb44560b7bcc0cea7b47a62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_60016177db6d45e0a0a42f2cfb24a9de","IPY_MODEL_5d991991a5644befbd6b34d5dee18d13","IPY_MODEL_102ece1779d1409fb4fd0e1a4ed8a8ea"],"layout":"IPY_MODEL_a641fa1135014b67ac3d1c821d1d8485"}},"6fdab3fbd6af40c3bd80341f1d17f9c0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7028fc49a88948e1a1b04e29ea7e66c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7039249a6a314d3db0e9b5224cbe660d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7167d4aee8474b2985b54c5bed615079":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53eb0821262048d1bb1e1824401f5856","placeholder":"​","style":"IPY_MODEL_9497a37dece34e7a8f7bda0fc2b6424f","value":" 4.97G/4.97G [01:04&lt;00:00, 81.8MB/s]"}},"71b0e02999b94aa28075784e98c85da9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68064669c1a54b58814e2075c666762f","placeholder":"​","style":"IPY_MODEL_b110311825d940048a1d708649be4a27","value":"Downloading data: 100%"}},"721f6878cf124b0b96d9d8570cd047b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7333088d29524b2caf816364eb4afda7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b73ceda5dcdd4434978323f0ac93a9d2","IPY_MODEL_ce4b118e8b924f32a489dba39d3b6347","IPY_MODEL_940061ed42524fbba9b0463e087347b8"],"layout":"IPY_MODEL_289328c4e17b4219b96fb47bee399a84"}},"7352f788860a4971b0c1cc467839fef7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"741e24f18c1f4464a420c0a92f132189":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"746e06b4b2854150a08f289b1285c6ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7fbace23606246569aff21d61c98e5c7","IPY_MODEL_8c38cd0818e44f6b822d832d445a37ba","IPY_MODEL_5735d665770740a6b226511d2a4b9faa"],"layout":"IPY_MODEL_d6c2c3d36f7440b5b8199b3fc1acf16d"}},"74acac2027ad4d08b8994e3bccfcbe17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6342ebd8a2db47ed8214b9369e77b22d","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a4a272df7f84a8c8d7ce1f363ab9380","value":499723}},"76073d46b27c44119d2c8f9060ff2f31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c454d78f75f443e6963e53e13a8837b1","placeholder":"​","style":"IPY_MODEL_8b0cc59419ad4259a21e0f896753df02","value":"model.safetensors.index.json: 100%"}},"76b645e105224e5b95083c46c7325ecc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"794f1bbd82844a78bc4436a4fbd788e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"795ca63d458a4d0b9702ba2fb5d96e26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"798f7065dbd24d3e87f56f81b7257028":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_634ff8d193864528848a173ff1b506f0","placeholder":"​","style":"IPY_MODEL_9441db8efe2a4c1ba3a689a865433735","value":"configuration_phi3.py: 100%"}},"7b67bd6e50324fe3b80b93e3e81803b0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c3f114c4b484551a922894f6fd8905d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fced298b55248f2948b01f39b6c6f51","placeholder":"​","style":"IPY_MODEL_a4691e1563e54c1c9b4308bb169b5a5f","value":" 500k/500k [00:00&lt;00:00, 12.6MB/s]"}},"7c4fa902753048d9a50572a967c88a1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8cb810011b34676988ff17d4dc258f4","placeholder":"​","style":"IPY_MODEL_ac384fc9d180441e9849a95e4242290f","value":" 982/982 [00:00&lt;00:00, 53.4kB/s]"}},"7c9451703d554290b101c6f8b2946fb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c9f5ee016da47108b6f8eb153b24332":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cc6fe3321304ec8a765b37a058c8cdc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d5b567f4cee43c8aa1f419f88e5498e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d81a07f16774c1185728c88f857ca1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7da60d519c1d4692affdbdf5c6aa2582":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01f52fd34c1943f483db8ddb8b98601f","IPY_MODEL_1a2d05bc514a45e2ae3fec48b068f5d2","IPY_MODEL_331e1a532ef74d99abbcc62bfb2c666a"],"layout":"IPY_MODEL_5589d4f9a8904568a6a3cb90d3882be7"}},"7dd25ab882d2482294bfd7765c1cf581":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7de63db120a54bd4bf4244a91f0d6855":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e1d5d4cef5a432c9e28dacce74cb4e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d697dc926cdb4f48863aa7e198b37afc","placeholder":"​","style":"IPY_MODEL_bbdccc1fc48b40a3b30f9512830c5083","value":" 2.67G/2.67G [00:08&lt;00:00, 291MB/s]"}},"7e22f2c6ddfd42bdabfe2ca6e4d9d5bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b1e002f9f374184a6dfca10df7b5c44","placeholder":"​","style":"IPY_MODEL_175d3e2edd404079aaca9a0b8fb16995","value":" 447/447 [00:00&lt;00:00, 17.8kB/s]"}},"7ea7424c3fd34e6fac070c5628515d9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db71310f4cd24148ac63b6b964154d78","placeholder":"​","style":"IPY_MODEL_babccb5d4beb4412954f694dc734bdc7","value":" 905/905 [00:00&lt;00:00, 65.0kB/s]"}},"7fbace23606246569aff21d61c98e5c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_741e24f18c1f4464a420c0a92f132189","placeholder":"​","style":"IPY_MODEL_aadccbbb14dd4a90bc74053147de4502","value":"Generating train split: 100%"}},"7fced298b55248f2948b01f39b6c6f51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fd3cb68269c40a59e3d681a17ab5ad2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fec64180fae415bbc47f4e5fd85dbe2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80636b6081d14f1c875aa383bda1dc98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efa656a63aad435e9bc6b28959520a6a","max":2669366920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_092e91029a7c469fb79058c518dc3092","value":2669366920}},"81a32ff4365741c28c3c35ccbd4d7d6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81fec40188bd4b87ba94088ee10ee343":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8300f9783033420da636f53d1ab0e0b5","IPY_MODEL_a5e54c06a49041a69ff888315f5fc5db","IPY_MODEL_ad7a422c25824360a3c7043102b0165a"],"layout":"IPY_MODEL_5123bb14e00d45c5ba7e4db4b3543b13"}},"8263ffe9ced04628a0e0c185417ff6c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82ab63d1f4c2468590a7324372adc4fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_04d77fcab4f84fa3a7d108a9648981c5","IPY_MODEL_569cc7d37f374b37881243f4c3fcf71e","IPY_MODEL_91c83715e20c47b5b313d0e7987c34b6"],"layout":"IPY_MODEL_04dccb6e02f3443bb3bc6882ffc4096c"}},"8300f9783033420da636f53d1ab0e0b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2126390b60444879a21e99a02c4af518","placeholder":"​","style":"IPY_MODEL_9528212df8b443dfbc9cce27997e4a21","value":"Map: 100%"}},"83d4d3611edd4389a93364046ace1160":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_450ae7bb94db4c16a9defb44f007f561","placeholder":"​","style":"IPY_MODEL_e8c2a4fd59b64995a3757cb321e34a34","value":"special_tokens_map.json: 100%"}},"84d1bada50ab45c5910ac5848c16b215":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8601d892d7594fcfaa85989b5628ae12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8637e0ecee0b4736b6fe1387272c45d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86a5ac7a1e5e49a9a162eccbfe7aa57a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3204b4cd6b94e5dacca22cd16ec03cf","IPY_MODEL_1f0917d1bc354d4b82876af2c82054f1","IPY_MODEL_7ea7424c3fd34e6fac070c5628515d9a"],"layout":"IPY_MODEL_921949414d5a4b1992e49e7091ecaffe"}},"86a67b023579410eba8507b3ace03999":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_582f76ead4434254b45f3a76e04e4a5b","IPY_MODEL_a0f52f41c0324d17b09fb4c026084d2b","IPY_MODEL_ec459d0a3fa2482da4e1ba9c4c8c8d44"],"layout":"IPY_MODEL_30f40b4621f3483592803659a2dcd69e"}},"8713b6c14b9e4cbc938d83dc37228d72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88130d5880c64533b1833c5e715f64f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9591607919c04e5bad7b731581ff1b55","placeholder":"​","style":"IPY_MODEL_42869c54a0f2400489e424d665a65786","value":"Map: 100%"}},"88ffebcc68df4752aaa0bf3d6122fb67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89e9308837244f23bd0ffbccc8d1edf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_798f7065dbd24d3e87f56f81b7257028","IPY_MODEL_c7b3d7ae74704e819ac9d2d3a788fa43","IPY_MODEL_c56b029acad6444db02e3544aa30c8be"],"layout":"IPY_MODEL_3623a68450404578b8101d192733b28a"}},"8a0986e816fe4dde8784f56f7c6e78c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a4a272df7f84a8c8d7ce1f363ab9380":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ad507ce6eb74667a4e83f4015b26b9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8af247e84ce84feeb210fd136cc757f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b14a0330744442bab18a083a3c075a2b","placeholder":"​","style":"IPY_MODEL_db78338aedb44caea5e5ac0fbcf3414e","value":" 2/2 [00:31&lt;00:00, 14.51s/it]"}},"8b0cc59419ad4259a21e0f896753df02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c38cd0818e44f6b822d832d445a37ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d185b1d39ad41408664f2f11ded491b","max":18612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_795ca63d458a4d0b9702ba2fb5d96e26","value":18612}},"8cf935c737804215b0afdda328cf8e49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2643884db2a4bce9ea39fb448f3fd0c","IPY_MODEL_d028c04c4b774af5a811e20b561cc5d0","IPY_MODEL_586228e34da640df9c03fc45ce719d89"],"layout":"IPY_MODEL_b3aac3f465294263bd692aa8828207a2"}},"8d5709bce7c24395a0a63f5187c897d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e37820d4b0c4dc3b91746120bd03fe1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f2fd315636e4094b444d19f4a5cd900":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fbba0403e6e478d961cba143d1170ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce8dc0bd2fd548bc9e5b1fb41574ce2e","placeholder":"​","style":"IPY_MODEL_22b495d9e099437aa0c1267110f3ed9c","value":"config.json: 100%"}},"90acdd2e01904b47bbba42c1ee2f362d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90d9995e778e4ef1bbe47d25491046ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9555f37e85f84a7181ffb7a9ad93a660","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a389947562d34509b2604ba6e4ff8cb5","value":293}},"91c83715e20c47b5b313d0e7987c34b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c7c94003f5640e68ca0284794853a14","placeholder":"​","style":"IPY_MODEL_c299fcb24a084dd7b11e10aa6943f8e2","value":" 3.16k/3.16k [00:00&lt;00:00, 136kB/s]"}},"921949414d5a4b1992e49e7091ecaffe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9244adc0cbab47eea6eee0d025f9977f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88ffebcc68df4752aaa0bf3d6122fb67","max":18612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1786bf22999a4ee9aa8677308cb3509a","value":18612}},"928dc3cc448d4344bbe032598a54b524":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92d8eebb8fb44044a79bfef596791d9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92ea11c9f8e245c8a275c2ea447eb265":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93950d4174524a62a2811161f2606e58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de30c2d5c32a4baf8e653d93271d8b1e","placeholder":"​","style":"IPY_MODEL_03631a493fcf4a6e985d35962f2d4029","value":" 2/2 [00:03&lt;00:00,  1.60s/it]"}},"940061ed42524fbba9b0463e087347b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5f05adb92a14bc894a2945ced1039e4","placeholder":"​","style":"IPY_MODEL_bb7ee090dc204935a6f4f185b3424a7e","value":" 172/172 [00:00&lt;00:00, 3.40kB/s]"}},"9441db8efe2a4c1ba3a689a865433735":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9497a37dece34e7a8f7bda0fc2b6424f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94afa80f33844271bcdb3ff85470aab4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9528212df8b443dfbc9cce27997e4a21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"952c3e692f0e476b97906ec41cdf5107":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9555f37e85f84a7181ffb7a9ad93a660":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9591607919c04e5bad7b731581ff1b55":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"965e7bdf7f14435da6017acf8151d437":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0090c8a99d08434ab1a7fc08cbae07b8","placeholder":"​","style":"IPY_MODEL_e201ee097aaa4728bb133ff0f90607ff","value":" 2/2 [01:38&lt;00:00, 46.63s/it]"}},"976916bba18e4c4aba1291dbb6967724":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97c8bc734a10462c9f0549fde56de5fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4eea9777aa3a4fd294d1c960f0a67f3f","max":2669366920,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d5b567f4cee43c8aa1f419f88e5498e","value":2669366920}},"9887201b9b65496583ae96e82ae2b219":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98eaae214ef144a49786e2bb88d66e5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7de63db120a54bd4bf4244a91f0d6855","placeholder":"​","style":"IPY_MODEL_611b8d1ead824b9fad7a3a072208f39f","value":"Downloading shards: 100%"}},"9a535c4e2bb0415ebc31c6795356ea03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cc6fe3321304ec8a765b37a058c8cdc","placeholder":"​","style":"IPY_MODEL_472d2e329fe542dc898a237458d5686c","value":"model-00002-of-00002.safetensors: 100%"}},"9b0142584c6a45e896e4f819a9799f4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_266e4bbb79a64642bc174f3c7dad95d4","placeholder":"​","style":"IPY_MODEL_644047f844dc4f2fbaa678570c3b64c6","value":" 5.17k/5.17k [00:00&lt;00:00, 447kB/s]"}},"9c292b94cc39402591d119e9334ed9f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c6754e1bb824318b4780e0c7c5e6596":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9de99cacfcd34cf487fa610e2eca498d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d055c2365c8543999fd8b67128e023fb","placeholder":"​","style":"IPY_MODEL_69625e03e76d4d1ca841aada699f06d6","value":" 904/904 [00:00&lt;00:00, 64.9kB/s]"}},"9e0995b34528475e801f5c760354a6ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e489c8191b94b0fa95594620c882777":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ea905ae6cfb4669811d2b94c7ad61fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_57ea92df94984c9387e3a5224e41f258","IPY_MODEL_c2455d3323304a2d9dbd7acf48987a9c","IPY_MODEL_f8b6669600c54ea8ba0670ba20d5826e"],"layout":"IPY_MODEL_0c343b8036f84f4782454b5dd4cfea7c"}},"9eb8db21e0904bd0bc9291df5959b42b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9ef43b7c2e10411ab4b0af917c08c045":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_552424871d8c42388ccf191502baeff3","placeholder":"​","style":"IPY_MODEL_ad77f24f231a42b398905250e5cf60ec","value":"Map: 100%"}},"9f0ca1a4f5b14063af3d7d6465507a0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fb83425519745aeac90d61dc5f7b988":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4983e7b601d44417a8ed7e7f9f70745e","placeholder":"​","style":"IPY_MODEL_9c6754e1bb824318b4780e0c7c5e6596","value":"added_tokens.json: 100%"}},"a00df6a056c74b00a4690e7722adea52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0428c3b5946411e905de4c74fbc9aae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ea15c5bed54ca0940ff640b1c9fc06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0f52f41c0324d17b09fb4c026084d2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45abbb2acbab404191851c503a43f460","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1c2bd106a0f643dbb07d1db1964a8188","value":2}},"a102c215a46a40ee98a81995a8667f46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a149a880c08a4d66bc91a097273260d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1a92f6e80764f59a9e4d029d9e88b5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d99c995eb34b496390b56d1703ad42f1","max":17681,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45dcc7940a0a4fe5910b0b4e522eac80","value":17681}},"a2643884db2a4bce9ea39fb448f3fd0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5cfe48e2f34471c811382c53963cb9f","placeholder":"​","style":"IPY_MODEL_f36dca72edc74d32961acb428d426777","value":"training_args.bin: 100%"}},"a2d8655bc330432fb28022ec87141ef3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a389947562d34509b2604ba6e4ff8cb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4406159d03d42198a647c3f1285a938":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a444e6dd0cd847b48ccd86611d45ca10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4691e1563e54c1c9b4308bb169b5a5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4af29a883094a6a85de45dc582781df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4a98928460446019223c806ed7dd877","IPY_MODEL_06acfb56fc304e28a3113aab69aed66c","IPY_MODEL_3c603af8f4364fdcac2b09529293e18e"],"layout":"IPY_MODEL_47c2bde9bc01463ba8111be4b22fcdc3"}},"a547e8b53df447efb0018e2842642a0e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5e54c06a49041a69ff888315f5fc5db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a547e8b53df447efb0018e2842642a0e","max":18612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b460ae86ac64220a7b1ed3ed5e8a4bb","value":18612}},"a641fa1135014b67ac3d1c821d1d8485":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a68e22e32067465fa5103aea3b55116c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2958f961d7634a07b5c0b4adc1f3b5c0","max":16331,"min":0,"orientation":"horizontal","style":"IPY_MODEL_15d8a137d0364004975ceaee8d0ed8d4","value":16331}},"a69e15abea0948399df904140e86c422":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7bc5458b69c46f984170052e9fa023b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8dc4ab8a7a1450e8dbfc6e31bdcb202":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a91b926b1cc549899b2dbf7476712ee1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e02fa9a3ab90438183a625a4f0945680","placeholder":"​","style":"IPY_MODEL_ec8ecdda68ad472db17b6b810f1928cb","value":"special_tokens_map.json: 100%"}},"aadccbbb14dd4a90bc74053147de4502":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab2996afa82e401b83074052ddd2ef80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab55e751edb447c0915bc82923796061":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab92aa04785248888e7868b24815a675":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_36eb716a460442dd8e370c7b7cf1dd70","max":17842848,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a0ea15c5bed54ca0940ff640b1c9fc06","value":17842848}},"aba6c1eb379949589357685f68f25802":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56e31e9ebcbc452bb74f1374d345e2f9","placeholder":"​","style":"IPY_MODEL_cf4abab5ca614539b7b7de2bd3832362","value":" 500k/500k [00:00&lt;00:00, 82.6kB/s]"}},"ac384fc9d180441e9849a95e4242290f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac4d21b344a6453381b25688bd2e2a3b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7028fc49a88948e1a1b04e29ea7e66c6","max":11357076,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0fb088e83959437e833231b9e091df9f","value":11357076}},"ac656088aeb342dd8720aad020fe99ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6be6720aa1484075a81410d7a03839ca","placeholder":"​","style":"IPY_MODEL_5a7c8e3e4b1b4831ad66a8725f805edb","value":" 18612/18612 [00:01&lt;00:00, 13222.09 examples/s]"}},"ac98d431d47c44bda6819b3728bb5bbe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acb08bb2712d4d238c03eef1c15d5d98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92ea11c9f8e245c8a275c2ea447eb265","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5f66799fd7964508bfb690acecb8bf0d","value":499723}},"ad0eb07d04984e0f8f2213f5f8825e17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dddd30aeeac944c8a3c2dbe499204f82","placeholder":"​","style":"IPY_MODEL_dcdff0860c154d918f2b6680a38e4db3","value":" 293/293 [00:00&lt;00:00, 17.1kB/s]"}},"ad77f24f231a42b398905250e5cf60ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad7a422c25824360a3c7043102b0165a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2661b0440326407fb74cea4cd7b80f9b","placeholder":"​","style":"IPY_MODEL_58ef49074584496bb4e1b350cc073161","value":" 18612/18612 [00:02&lt;00:00, 6607.24 examples/s]"}},"ae7bad8c7f584355be59d4f04cd53c13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af0ec36b2cf04c69b670c02d55d66107":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_145fc3fb1e404b0abe6eba03a6e834c4","IPY_MODEL_a68e22e32067465fa5103aea3b55116c","IPY_MODEL_2f65a82bed7e4077943483bd9fe3c257"],"layout":"IPY_MODEL_11e74c6f08934ba39e54337dff2a5ecd"}},"af7ff044eddc406a910f5ee01ac910cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b08f4405cdb74c5f99c6027a2a1c7f54":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a444e6dd0cd847b48ccd86611d45ca10","placeholder":"​","style":"IPY_MODEL_301500418c7f4e50b2babdb337f91080","value":" 4.97G/4.97G [02:07&lt;00:00, 41.1MB/s]"}},"b110311825d940048a1d708649be4a27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b14a0330744442bab18a083a3c075a2b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2519736637a4722b58590d0283c806a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2f689bade764e0fac3f83a1e64b28ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b3aac3f465294263bd692aa8828207a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4791abae37842b4ad397d8577af3c88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4b95d28135b4c868330ddf3342c2b68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b50c9fe94fa54eab9862e6fb73d30634":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b66de8b9bea44665a353a2a1562f2b0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b677f4bde46c43a6ae7579a24fd219d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b67e610d5fc64bc49854bfa89db32ac6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4d83b08c4bb470ab4788a0eeb42e9dc","IPY_MODEL_6dde3ae85dc5423aae584d985e84fcd4","IPY_MODEL_7167d4aee8474b2985b54c5bed615079"],"layout":"IPY_MODEL_0028bc0c938b4d549d7971f43590fa05"}},"b70b814dcae0421c91507eab1e152f02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7196498aaeb41a0a410764ca41a5a80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc9c34450add4a979adecb2b2e2a31d9","placeholder":"​","style":"IPY_MODEL_d3ccbed2a01e42e6b51b5cd24f5049e2","value":" 18612/18612 [00:02&lt;00:00, 7846.24 examples/s]"}},"b73ceda5dcdd4434978323f0ac93a9d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_224e68aeff7940d4a7eafde48f3cab49","placeholder":"​","style":"IPY_MODEL_1759e4153c2c49b3adee58c5d20a5ae7","value":"generation_config.json: 100%"}},"b8676ea5c9074c7b88874aad7d447139":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b94caedc744941e38d2fe2e458d6728f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06062332a4c34d26ba5fa0a357b483b2","IPY_MODEL_0b04aa6337c54790812e567f93b07f25","IPY_MODEL_d99cda66ea8b4c9d8edd7678ec91608e"],"layout":"IPY_MODEL_b66de8b9bea44665a353a2a1562f2b0b"}},"b9fe743a8cf74c1697af07602b3a2d58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6930dff5bed438383463baa2e7b6e42","placeholder":"​","style":"IPY_MODEL_7dd25ab882d2482294bfd7765c1cf581","value":" 17681/17681 [00:02&lt;00:00, 7622.36 examples/s]"}},"ba5e9830d6394842bac9f1b40d803a45":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0428c3b5946411e905de4c74fbc9aae","placeholder":"​","style":"IPY_MODEL_54a7c113c9f34118843e761698b2d0e4","value":" 293/293 [00:00&lt;00:00, 26.7kB/s]"}},"ba946d03e1384bdf8ea13e8f61b730ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"babccb5d4beb4412954f694dc734bdc7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb612d41baf54c50914cd72a5b269e91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb7ee090dc204935a6f4f185b3424a7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbdccc1fc48b40a3b30f9512830c5083":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc9c34450add4a979adecb2b2e2a31d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd127c03b9524c31ac9e01c1fefb0de3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce222f64951245fbb6c62bf8986e115e","max":1844409,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ffdbe3a530cc4011b1873fcf51617120","value":1844409}},"bdb6be83dd114fb29b784fc160d3dd81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71b0e02999b94aa28075784e98c85da9","IPY_MODEL_ac4d21b344a6453381b25688bd2e2a3b","IPY_MODEL_f2638fafd3dd454c894c7b3799613a8e"],"layout":"IPY_MODEL_a7bc5458b69c46f984170052e9fa023b"}},"bdca6009505c4fe7b2e51b0432717ab8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be332042a5cc44d783547a0cb00003d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec9a23edeaa4dc88e37fa2a60c5236e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf09841951154f9d8a5c808da138b72f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0075b240b4849b4b48a500587f45b6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c02a3d798bf3479e93f7d55b0077db16":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c191734269044b829f385b7e7e07124a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a29804ee58d4d01903ae9d5d64e8ee5","IPY_MODEL_97c8bc734a10462c9f0549fde56de5fb","IPY_MODEL_c57073d4173a436a9981e3c708a8e678"],"layout":"IPY_MODEL_be332042a5cc44d783547a0cb00003d1"}},"c2455d3323304a2d9dbd7acf48987a9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5de4d24cb81f49728e12c04cd2575395","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1561787e0545497aaef43ce3f79d0e4f","value":2}},"c28beafc58d34b118dcd1f69ed1d44f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19f32e302284673b55aa1cf9a9d2694","max":18612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b76900c76f346f288d4a42e5a6a19c4","value":18612}},"c299fcb24a084dd7b11e10aa6943f8e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2a03890d9534f858d345e3ac6278fed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_296b7f23ba0c4b4a8e8ec49427152c5c","placeholder":"​","style":"IPY_MODEL_f1c0d758b4f1490eb5f38b8b3b0e2909","value":" 1.85M/1.85M [00:00&lt;00:00, 8.21MB/s]"}},"c37ce6058b5c4474bbb1d0d4147a377e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c454d78f75f443e6963e53e13a8837b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c52f0c3c7d614adea3e20364a1fe394f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c56b029acad6444db02e3544aa30c8be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f0b36c8ab604525928be5e720637ad0","placeholder":"​","style":"IPY_MODEL_d9aad0354e374cf0a0fa392abfd7d581","value":" 10.4k/10.4k [00:00&lt;00:00, 422kB/s]"}},"c57073d4173a436a9981e3c708a8e678":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7352f788860a4971b0c1cc467839fef7","placeholder":"​","style":"IPY_MODEL_cc0ba2d2ed284014aa00803a5ecaaa5d","value":" 2.67G/2.67G [01:06&lt;00:00, 32.8MB/s]"}},"c5f05adb92a14bc894a2945ced1039e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c635fed7bfd947f1a648c8935a043446":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_31d98dac63254877bbd6941992cc3c11","IPY_MODEL_ab92aa04785248888e7868b24815a675","IPY_MODEL_dcaf83f7486e4b6bad19908753fc2f4d"],"layout":"IPY_MODEL_f3133dc81aca4516bec96df796f471ee"}},"c6ea3f34f09d4af596beb3daba50c513":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c78767eec2b8424aa9f207541fceb477":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ef43b7c2e10411ab4b0af917c08c045","IPY_MODEL_9244adc0cbab47eea6eee0d025f9977f","IPY_MODEL_ac656088aeb342dd8720aad020fe99ea"],"layout":"IPY_MODEL_3c2a9dd5b94a4839842265e12c1080a8"}},"c7b3d7ae74704e819ac9d2d3a788fa43":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f2fd315636e4094b444d19f4a5cd900","max":10411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_040a12849797455c939e4bd85c9b39bd","value":10411}},"c7e7a08ec7a041bc9776a15026bfbc9e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c85751488586424994a55139743fe336":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8db4344bf6e4cfab30d54965659789e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cae95378c844430eaca461aacc056ce5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cba2a81b45294f60800b816d837efe8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc0ba2d2ed284014aa00803a5ecaaa5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd5773d98dcd48ada478251e5d8f667a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fec64180fae415bbc47f4e5fd85dbe2","max":16331,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8e37820d4b0c4dc3b91746120bd03fe1","value":16331}},"cdaf9b4376e8425181bc8db4cccef385":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce222f64951245fbb6c62bf8986e115e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce3c25872ea443ce8e54fd6241effddf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3449acde6d9c4d08a73e40c26905b14b","max":10411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab2996afa82e401b83074052ddd2ef80","value":10411}},"ce4b118e8b924f32a489dba39d3b6347":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf130d14d09e46659a081d0e53e3162e","max":172,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee90b463249e4d9ba5b44d3fb3e1eeb4","value":172}},"ce8dc0bd2fd548bc9e5b1fb41574ce2e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf130d14d09e46659a081d0e53e3162e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf4abab5ca614539b7b7de2bd3832362":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfc00687a8984631861d8ff1235ff4d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d028c04c4b774af5a811e20b561cc5d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3057cb40215747e39e46ba451f2a2faf","max":4984,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb8038b9c9ac4af080df60d99cc8e8f4","value":4984}},"d055c2365c8543999fd8b67128e023fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d07197cefa7b4715bee9f2a0d604bd42":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d0b422a1fbb84d208b12146c4f69b091":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14eab25342c4c05ba31a45744cd6a31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_512351ca43e3407cb2c1388c54f1ee4d","placeholder":"​","style":"IPY_MODEL_ff967ff68f1e4ba199e6a4df4b90a121","value":"config.json: 100%"}},"d19f32e302284673b55aa1cf9a9d2694":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2cbf277e211405799b46b9cf2dc4e73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d14eab25342c4c05ba31a45744cd6a31","IPY_MODEL_478a058d22194634a4df745e3cd9f478","IPY_MODEL_7c4fa902753048d9a50572a967c88a1b"],"layout":"IPY_MODEL_3fd63dfbf5fc4cc5a05cabfdfea85fd2"}},"d2cebab3787442528ce9c6d8b9acff43":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2d7b73ab765447fa79c2e81fc889f89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f125e8e4178b48deb071f4f17fcf7a96","IPY_MODEL_595d8af5740c4c93bd461a365cb7b4dd","IPY_MODEL_dc2a7664163143c6b95ca5cb5cb31762"],"layout":"IPY_MODEL_32f3c777dd5e4608a7c39c34549c3c8a"}},"d384c2f905e9484bb71918c6566d9490":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3a6a85e318d4d46a79b96c77dc410e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ccbed2a01e42e6b51b5cd24f5049e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d414908f8047408aaf31108c38d0be63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d521ef01918b4d1a95c2528855c08d8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4791abae37842b4ad397d8577af3c88","placeholder":"​","style":"IPY_MODEL_db15bc83eb3b4bdcb89d082e136593f7","value":" 18612/18612 [00:01&lt;00:00, 13289.66 examples/s]"}},"d59488087dd54981a35b946c258794de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3924ead7d1e149e2bed8266caa4add08","placeholder":"​","style":"IPY_MODEL_af7ff044eddc406a910f5ee01ac910cd","value":"tokenizer.json: 100%"}},"d5cfe48e2f34471c811382c53963cb9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d697dc926cdb4f48863aa7e198b37afc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6c2c3d36f7440b5b8199b3fc1acf16d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7fe81223ded4e66809a5be599dc9b58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3492c45c01084e1c8cfeeae95ed4599c","placeholder":"​","style":"IPY_MODEL_2aff1fedfb8b4e1f928f5ea74cd9edbe","value":" 1.84M/1.84M [00:00&lt;00:00, 4.44MB/s]"}},"d99c995eb34b496390b56d1703ad42f1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d99cda66ea8b4c9d8edd7678ec91608e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dee17f38a84b4c48b177d67143b4dd04","placeholder":"​","style":"IPY_MODEL_22b3ed00418d44338cdf745340fa18a3","value":" 5.65k/? [00:00&lt;00:00, 117kB/s]"}},"d9aad0354e374cf0a0fa392abfd7d581":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db15bc83eb3b4bdcb89d082e136593f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"db71310f4cd24148ac63b6b964154d78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db78338aedb44caea5e5ac0fbcf3414e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbb5ec51bd834c50bdbf1e711d384ec9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8263ffe9ced04628a0e0c185417ff6c9","placeholder":"​","style":"IPY_MODEL_9e489c8191b94b0fa95594620c882777","value":" 931/931 [00:00&lt;00:00, 7086.93 examples/s]"}},"dbc872ea3eb043c6bc92ca2c2ab77e19":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fdab3fbd6af40c3bd80341f1d17f9c0","placeholder":"​","style":"IPY_MODEL_ae7bad8c7f584355be59d4f04cd53c13","value":"Map: 100%"}},"dc2a7664163143c6b95ca5cb5cb31762":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5fe7f0767434e2c846b34e77517f582","placeholder":"​","style":"IPY_MODEL_ef2ac502a0a349db97d74d6b2f6b6330","value":" 500k/500k [00:00&lt;00:00, 17.6MB/s]"}},"dc3dfa5eedc44e27aaa3e29be3c77310":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcabb4a8e10f4d61bfc0d4d55d241d99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcaf83f7486e4b6bad19908753fc2f4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a6dade4fa4740d79bd9016261479c50","placeholder":"​","style":"IPY_MODEL_1246f9886bc84fca95c963560733e826","value":" 17.8M/17.8M [00:02&lt;00:00, 10.8MB/s]"}},"dcdff0860c154d918f2b6680a38e4db3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dddd30aeeac944c8a3c2dbe499204f82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de30c2d5c32a4baf8e653d93271d8b1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dedd3be211ba408eb4ea45225825702c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc0a167149bf4a8b99c2e48828d6dff7","IPY_MODEL_61108297e38343148ee2def1f649a652","IPY_MODEL_b08f4405cdb74c5f99c6027a2a1c7f54"],"layout":"IPY_MODEL_40d3efeaacef42e78467a6cc10868866"}},"dee17f38a84b4c48b177d67143b4dd04":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfa74756deaa4f99a060c1e2e346589c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_257f093d380e4d05b7252c53c3730755","placeholder":"​","style":"IPY_MODEL_c85751488586424994a55139743fe336","value":"Loading checkpoint shards: 100%"}},"dfdcc9ae18124b719591120c8c9a5533":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e02fa9a3ab90438183a625a4f0945680":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e0b30675733449b8b018368d16a6b499":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e201ee097aaa4728bb133ff0f90607ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e22ea0c1ae3145bf8d4a5967c9097bc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_118ed7a45ea145668dfb11b74d780f3b","placeholder":"​","style":"IPY_MODEL_bec9a23edeaa4dc88e37fa2a60c5236e","value":"tokenizer_config.json: 100%"}},"e3204b4cd6b94e5dacca22cd16ec03cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39cb0c878a624cb48a230807cee0ad7c","placeholder":"​","style":"IPY_MODEL_c0075b240b4849b4b48a500587f45b6f","value":"Downloading readme: 100%"}},"e3c20616b2f941c69b8ff983b9e3c192":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e3db7f9cb43f4aada76b72373afa5a44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae95378c844430eaca461aacc056ce5","placeholder":"​","style":"IPY_MODEL_81a32ff4365741c28c3c35ccbd4d7d6f","value":" 10.4k/10.4k [00:00&lt;00:00, 948kB/s]"}},"e3e3e92589484dbbb99c0a6cbdaa3d82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0b30675733449b8b018368d16a6b499","placeholder":"​","style":"IPY_MODEL_593fc5a4d40a4c05831e5bb4001a6d19","value":" 2.67G/2.67G [00:33&lt;00:00, 80.4MB/s]"}},"e4a58ae2b740445bb980b9639daad37e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4a98928460446019223c806ed7dd877":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55f08d2043b94ce499ee55b1871402ad","placeholder":"​","style":"IPY_MODEL_5e53398218a54804b69c805a6e95a37d","value":"Map: 100%"}},"e4ac020f037642299004abc08c5b7cbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e586ef1090d94c64837d249c395ed111":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5fe7f0767434e2c846b34e77517f582":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e68ed8ec991f40058924e637a63d0aca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6930dff5bed438383463baa2e7b6e42":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6e3cc38aceb49eb9a2cd497a0107718":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e82486323d3f4403a7c60f79d56bf4b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e8c2a4fd59b64995a3757cb321e34a34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ea12af5ea0f442ebb6b808ed5d397a73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e22ea0c1ae3145bf8d4a5967c9097bc5","IPY_MODEL_3f519139e1c74a6babe3fec272f6752a","IPY_MODEL_f21e917f42c04cabad20b007dd0a2fad"],"layout":"IPY_MODEL_d0b422a1fbb84d208b12146c4f69b091"}},"eb8038b9c9ac4af080df60d99cc8e8f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb86bd36bc8b4e4298157ea474e5029f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec022a08b3c9482f8cb300feb9a4033a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a535c4e2bb0415ebc31c6795356ea03","IPY_MODEL_80636b6081d14f1c875aa383bda1dc98","IPY_MODEL_e3e3e92589484dbbb99c0a6cbdaa3d82"],"layout":"IPY_MODEL_ab55e751edb447c0915bc82923796061"}},"ec459d0a3fa2482da4e1ba9c4c8c8d44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29ca7d61681e4c55abc27e59fce84a12","placeholder":"​","style":"IPY_MODEL_50999791713342138b63d2c414d246d9","value":" 2/2 [00:02&lt;00:00,  1.36s/it]"}},"ec57adf1c40f4859a4b3648bf7bcc1ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_635d6b6aacae4002a0af24f48f712a6a","IPY_MODEL_1d1be0fc03fb4b7080bea43436bd571c","IPY_MODEL_965e7bdf7f14435da6017acf8151d437"],"layout":"IPY_MODEL_a00df6a056c74b00a4690e7722adea52"}},"ec8ecdda68ad472db17b6b810f1928cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ecc3a536f91c4685905bcae0b53ef777":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdc855c3527746bfa5475013dba34632","max":447,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84d1bada50ab45c5910ac5848c16b215","value":447}},"ed363711b3794a39b7ead82558cf26f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee90b463249e4d9ba5b44d3fb3e1eeb4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eeede55ddd0e40e1a8fb308a4f3ad233":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef1fef6471af459aa4ac089be9724f00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef2ac502a0a349db97d74d6b2f6b6330":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efa656a63aad435e9bc6b28959520a6a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f033adb758544d1c89e842339b12dde0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0855c7022f54058abed8e08fa966d8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f125e8e4178b48deb071f4f17fcf7a96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ad507ce6eb74667a4e83f4015b26b9c","placeholder":"​","style":"IPY_MODEL_504b142157694a3a85cf1b8e0374022b","value":"tokenizer.model: 100%"}},"f1b620a4ccf84d2a99c0d0e3b4fc5ff6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c0d758b4f1490eb5f38b8b3b0e2909":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1dd590f35a64e968113caaacb3b4e80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1e220e8d5604b7d87c2345ff33840f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c54ba6b957d4bcaa6c6badabf37eec5","IPY_MODEL_5fb978c32e3e4492bb1e28996f32ef24","IPY_MODEL_029819fa8bf44099946ac08fcb2aadb7"],"layout":"IPY_MODEL_6627a90d4e05400abb2a8f2aff8fb085"}},"f21e917f42c04cabad20b007dd0a2fad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0fdcd532f6184ac4b6b6aeba8c54a82c","placeholder":"​","style":"IPY_MODEL_952c3e692f0e476b97906ec41cdf5107","value":" 3.17k/3.17k [00:00&lt;00:00, 275kB/s]"}},"f2638fafd3dd454c894c7b3799613a8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_928dc3cc448d4344bbe032598a54b524","placeholder":"​","style":"IPY_MODEL_171d95ec467c4c51806b6470fc45bf6d","value":" 11.4M/11.4M [00:00&lt;00:00, 26.7MB/s]"}},"f28291492eee448095cbe3633df992e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fd2efd511714c11b693acdf8599796d","max":293,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35f65873ac94477cbef2df06d4c68e10","value":293}},"f29cfcc949dc4de68f25d7f67215c33e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e4613669dd54cd685f8dd7d4cea1ced","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04a09e6c9ca64f25a3d4fbac1662f3ab","value":2}},"f3133dc81aca4516bec96df796f471ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f36dca72edc74d32961acb428d426777":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f40a2d75a321482996882eb22a31ac26":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e87a17ef2e9469690f28544a7ef736a","IPY_MODEL_f28291492eee448095cbe3633df992e6","IPY_MODEL_ad0eb07d04984e0f8f2213f5f8825e17"],"layout":"IPY_MODEL_a69e15abea0948399df904140e86c422"}},"f4b96f6c51eb46f085c07daffc54c6ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_317127b9c03d4a88879b71478f96cea0","placeholder":"​","style":"IPY_MODEL_6268d760b3ac43a69f115e65a790599a","value":"configuration_phi3.py: 100%"}},"f4d83b08c4bb470ab4788a0eeb42e9dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37136592e27d419b93a7b3bb65c8dab4","placeholder":"​","style":"IPY_MODEL_45f337c9a4ea45e39358a14198a47eec","value":"model-00001-of-00002.safetensors: 100%"}},"f50eeebaa04f42938928a83f49513718":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cba2a81b45294f60800b816d837efe8e","placeholder":"​","style":"IPY_MODEL_a149a880c08a4d66bc91a097273260d6","value":"tokenizer.model: 100%"}},"f5d5b93e40594822b9a2cc2912012761":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f755e0dc6e834025a4a0ff78eca1af7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fb83425519745aeac90d61dc5f7b988","IPY_MODEL_90d9995e778e4ef1bbe47d25491046ce","IPY_MODEL_ba5e9830d6394842bac9f1b40d803a45"],"layout":"IPY_MODEL_d3a6a85e318d4d46a79b96c77dc410e1"}},"f79bb7e41ae34c01802cf81d52572620":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7baa800a11c4ae9a84941f67868127d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f87526f1efa24f4ab2942c4b8d9dbc99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8b6669600c54ea8ba0670ba20d5826e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c9f5ee016da47108b6f8eb153b24332","placeholder":"​","style":"IPY_MODEL_fee7b2f1c26545ef88f2b51973b9e7a9","value":" 2/2 [00:32&lt;00:00, 15.41s/it]"}},"f8cb810011b34676988ff17d4dc258f4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc0a167149bf4a8b99c2e48828d6dff7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_794f1bbd82844a78bc4436a4fbd788e3","placeholder":"​","style":"IPY_MODEL_56446ad26c6d4343b74cf664f56c4b9a","value":"model-00001-of-00002.safetensors: 100%"}},"fdc855c3527746bfa5475013dba34632":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fee7b2f1c26545ef88f2b51973b9e7a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff967ff68f1e4ba199e6a4df4b90a121":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffdbe3a530cc4011b1873fcf51617120":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
